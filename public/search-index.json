[
  {
    "title": "Auth.jsとRuby on Railsによるユーザ管理",
    "summary": "だれも解説してくれないのでメモ",
    "tags": [
      "Next.js",
      "Ruby on Rails",
      "認証",
      "Auth.js"
    ],
    "slug": "ruby/auth-js-ror-user-management",
    "folder": "ruby",
    "content": "\n前回の続きです．\n[Auth.jsの基礎 (Google OAuthを使用)](https://techblog-notes.vercel.app/afdc23b5-ec55-4c5e-8763-6bc649124448)\n\n# JWT認証の導入\n\n---\n\n今回，Auth.jsにより取得したログイン情報をバックエンドに渡しユーザ管理する手法として以下のプロセスを要します．\n\n1. Googleの認証が成功するとAuth.jsがaccount.id_tokenを受け取る．このID トークンはGoogleが発行するJWTである．\n1. account.id_tokenはjwtコールバックで token.idTokenに保存する．\n1. セッションにIDトークンを保存する．\n1. セッションからIDトークンを取得し，`fetch()`を用いてバックエンドに送信．\n1. バックエンドでIDトークンを検証，成功後に初めてデータを処理できる．\n\nこのように，結構面倒な処理をする必要があります．(コード自体はそこまで書かない気がする)\n\n## 型定義ファイルを編集する\n\nAuth.jsでは，account.id_tokenは定義されているものの，tokenとsessionにid_tokenは定義されていません．しかしそれでもid_tokenを渡したいので，定義します．\n\n```ts\n// types/next-auth.d.ts\nimport \"next-auth/jwt\";\n\ndeclare module \"next-auth/jwt\" {\n  interface JWT {\n    idToken?: string;\n  }\n}\n\ndeclare module \"next-auth\" {\n  interface Session {\n    user: {\n      idToken?: string;\n    } & DefaultSession[\"user\"];\n  }\n}\n```\n\n> `session.idToken`でいいかなと思っていたけど，V5では`session.user.idToken`にすることが推奨されていたのでこのようにしてます．\n\n## コールバック関数を用意する\n\n```ts\nimport NextAuth from \"next-auth\";\nimport Google from \"next-auth/providers/google\";\n\nexport const { handlers, signIn, signOut, auth } = NextAuth({\n  providers: [Google],\n  callbacks: {\n    async jwt({ token, account }) {\n      if (account) {\n        token.idToken = account.id_token;\n      }\n\n      return token;\n    },\n    async session({ session, token }) {\n      session.user.idToken = token.idToken;\n\n      return session;\n    },\n  },\n});\n```\n\nこうすることで，`auth()`から`user.idToken`を取得することができるようになります．\n\n## バックエンドにIDトークンを渡す\n\nトークン情報はbodyではなくheaderに含めるのが一般的です．`http://localhost:3001/auth/google`に渡すように設定します．\n\n```tsx\nimport { auth } from \"@/auth\";\nimport { redirect } from \"next/navigation\";\nimport React from \"react\";\n\nexport default async function DashboardLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  const session = await auth();\n\n  if (session) {\n    const idToken = session.user.idToken;\n\n    if (idToken) {\n      await fetch(\"http://localhost:3001/auth/google\", {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n          Authorization: `Bearer ${idToken}`,\n        },\n      });\n    }\n  } else {\n    redirect(\"/signin\");\n  }\n\n  return <>{children}</>;\n}\n```\n\n# バックエンド処理\n\n---\n\n## プロジェクト作成\n\n```bash\nrails new backend --api -T\n```\n\n### gemのインストール\n\n今回使うgemは以下の通りです．\n\n```ruby\ngem 'rack-cors', require: 'rack/cors'\ngem \"google-id-token\"\ngem 'dotenv-rails'\n```\n\n`bundle install`を忘れずに実行しましょう\n\n### corsの設定\n\n`http://localhost:3000`を許可しましょう\n\n```ruby\n# config/initializers/cors.rb\nRails.application.config.middleware.insert_before 0, Rack::Cors do\n  allow do\n    origins \"http://localhost:3000\"\n\n    resource \"*\",\n      headers: :any,\n      methods: [:get, :post, :put, :patch, :delete, :options, :head]\n  end\nend\n```\n\n### ポートの修正\n\n3000番は既にフロント側で使用されているので，バックエンド側は3001番に設定します．\n\n```ruby\n# config/puma.rb\nport ENV.fetch(\"PORT\", 3001)\n```\n\n## モデルの作成\n\n`google_sub`はユーザーごとに一意なIDを示しており，IDトークンの検証時に取得できます(フロントエンドでも取得できる)．\n\n```bash\nrails generate model User google_sub:string name:string email:string picture:string\n```\n\n`rails db:migrate`を忘れずに実行しましょう\n\n### バリデーションを定義する\n\n作成した`User`モデルの`google_sub`と`email`について，それぞれ必須かつユニークな値にバリデートします．\n\n```ruby\nclass User < ApplicationRecord\n  validates :google_sub, presence: true, uniqueness: true\n  validates :email, presence: true, uniqueness: true\nend\n```\n\n## コントローラの作成\n\n```bash\nrails generate controller sessions\n```\n\n実行すると，`sessions_controller.rb`が生成されるので，そのファイルを編集していきます．\n\n```ruby\nclass SessionsController < ApplicationController\n  # ライブラリの読み込み\n  require \"google-id-token\"\n\n  def google_auth\n    auth_header = request.headers[\"Authorization\"]\n\n    # トークンが存在しない場合、または形式が不正な場合，unauthorizedエラーを返す\n    unless auth_header&.start_with?(\"Bearer \")\n      return render json: { error: \"Unauthorized\" }, status: :unauthorized\n    end\n\n    # AuthorizationヘッダーからIDトークンを取り出す\n    token = auth_header.split(\"Bearer \").last\n\n    # トークン検証\n    begin\n      # IDトークンを検証するためのバリデータを作成\n      validator = GoogleIDToken::Validator.new\n      payload = validator.check(token, ENV[\"GOOGLE_CLIENT_ID\"])\n\n      sub = payload[\"sub\"]\n      email = payload[\"email\"]\n      name = payload[\"name\"]\n      picture = payload[\"picture\"]\n\n      # ユーザが見つかれば更新，見つからなければ作成\n      user = User.find_or_create_by(google_sub: sub) do |u|\n        u.name = name\n        u.email = email\n        u.picture = picture\n      end\n\n      render json: { message: \"Login successful\", user: user }\n    rescue StandardError => e\n      Rails.logger.error \"Google Auth Error: #{e.message}\"\n\n      render json: { error: \"Invalid ID token\" }, status: :unauthorized\n    end\n  end\nend\n```\n\n### ルーティングの設定\n\n`auth/google`にアクセスしたときに`SessionsController`クラスの`google_auth`メソッドが実行されるようにルーティングします．\n\n```ruby\nRails.application.routes.draw do\n  # Define your application routes per the DSL in https://guides.rubyonrails.org/routing.html\n\n  # Reveal health status on /up that returns 200 if the app boots with no exceptions, otherwise 500.\n  # Can be used by load balancers and uptime monitors to verify that the app is live.\n  get \"up\" => \"rails/health#show\", as: :rails_health_check\n\n  # Defines the root path route (\"/\")\n  # root \"posts#index\"\n\n  post \"auth/google\", to: \"sessions#google_auth\"\nend\n```\n\n# テスト\n\n実際に`http://localhost:3000`にアクセスし，アカウント作成，ログイン，ログアウトを検証してみましょう．想定通りの挙動がされれば成功です．\n",
    "createdAt": "2025-07-21T07:23:48.459Z",
    "updatedAt": "2025-07-21T07:23:48.459Z"
  },
  {
    "title": "Auth.jsの基礎 (Google OAuthを使用)",
    "summary": "最新のAuth.jsの使い方をメモ",
    "tags": [
      "Next.js",
      "認証",
      "Auth.js"
    ],
    "slug": "Next.js/auth-js-tutorial",
    "folder": "Next.js",
    "content": "\n# バージョン\n\n---\n\n```json\n\"next\": \"15.1.7\",\n\"next-auth\": \"^5.0.0-beta.25\",\n\"react\": \"^19.0.0\",\n\"react-dom\": \"^19.0.0\"\n```\n\n# プロジェクト作成\n\n---\n\nApp routerを使っていきます．\n\n```bash\n$ npx create-next-app@latest\n✔ What is your project named? … frontend\n✔ Would you like to use TypeScript? … Yes\n✔ Would you like to use ESLint? … Yes\n✔ Would you like to use Tailwind CSS? … Yes\n✔ Would you like your code inside a `src/` directory? … No\n✔ Would you like to use App Router? (recommended) … Yes\n✔ Would you like to use Turbopack for `next dev`? … Yes\n✔ Would you like to customize the import alias (`@/*` by default)? … No\n```\n\n## Auth.jsの設定\n\n公式サイトのやり方に則ります．\n[Auth.js | Installation](https://authjs.dev/getting-started/installation?framework=next-js)\n\n### パッケージのインストール\n\n```bash\nnpm install next-auth@beta\n```\n\n### シークレットキーの作成\n\nライブラリがトークンやメール認証用のハッシュを暗号化するために使用するランダムな値を生成し，自動で`.env`あるいは`.env.local`に保存されます．\n\n```bash\n$ npx auth secret\n📝 Created [プロジェクトの場所].env.local with `AUTH_SECRET`.\n```\n\n# アプリの下準備\n\n---\n\n## `Auth.ts`の作成\n\nここでは使用したい認証プロバイダの指定やコールバックの設定などができます．ここでは単純にgoogleのプロバイダのみを使用します．\n\n```ts\n// ./auth.ts\nimport NextAuth from \"next-auth\";\nimport Google from \"next-auth/providers/google\";\n\nexport const { handlers, signIn, signOut, auth } = NextAuth({\n  providers: [Google],\n});\n```\n\n## `routes.ts`の作成\n\n今後セッション管理用の関数を使うために，あらかじめルーティングを設定する必要があります．\n\n```ts\n// ./app/api/auth/[...nextauth]/route.ts\nimport { handlers } from \"@/auth\"; // Referring to the auth.ts we just created\nexport const { GET, POST } = handlers;\n```\n\nこれを設定すると以下のエンドポイントが自動で作成されます\n\n- `/api/auth/signin`（サインイン）\n- `/api/auth/signout`（サインアウト）\n- `/api/auth/session`（セッション情報取得）\n- `/api/auth/callback/:provider`（OAuth コールバック）\n- `/api/auth/csrf`（CSRF トークン取得）\n\nこれらが作成されることにより適切にAuth.jsが用意した関数を使用することができるようになります．\n\n## GoogleのOAuthを使う\n\nGoogle Cloudからプロジェクトを作成し，クライアントIDとシークレットキーを取得する必要があります\nhttps://console.cloud.google.com/\n\n### 認証情報の作成\n\n`ナビゲーションメニュー > APIとサービス > 認証情報`に移動し，`認証情報を作成`します．種類は OAuth クライアント ID を選択してください．\n\n### クライアントIDの設定\n\nOAuth クライアント ID の作成は以下のように設定してください．\n\n- アプリケーションの種類 ... ウェブアプリケーション\n- 名前 ... 任意の名前\n- 承認済みの JavaScript 生成元 ... http://localhost:3000\n- 承認済みのリダイレクト URI ... http://localhost:3000/api/auth/callback/google\n\n> 同意画面を作成していない場合は，事前に作成することを促されます．また作成後，サイトを再読み込みする必要があります．\n\n### `.env.local`の編集\n\nOAuth クライアント IDの作成がうまくいくと，クライアント ID とクライアントシークレットを取得できます．これらを`.env.local`に追加しておきます．\n\n```env\nAUTH_GOOGLE_ID={CLIENT_ID}\nAUTH_GOOGLE_SECRET={CLIENT_SECRET}\n```\n\n# 実装\n\n---\n\n## signin/signoutコンポーネントの作成\n\n### `components/signin.tsx`\n\n今回は，サインインしたのちに`/dashboard`にリダイレクトするようにします．\n\n```tsx\nimport { signIn } from \"@/auth\";\n\nexport default function SignIn() {\n  return (\n    <form\n      action={async () => {\n        \"use server\";\n        await signIn(\"google\", { redirectTo: \"/dashboard\" });\n      }}\n    >\n      <button\n        type=\"submit\"\n        className=\"w-full bg-blue-500 text-white py-2 px-4 rounded hover:bg-blue-600\"\n      >\n        Sign in with Google\n      </button>\n    </form>\n  );\n}\n```\n\n### `components/signout.tsx`\n\n```tsx\nimport { signOut } from \"@/auth\";\n\nexport function SignOut() {\n  return (\n    <form\n      action={async () => {\n        \"use server\";\n        await signOut({ redirectTo: \"/\" });\n      }}\n    >\n      <button\n        type=\"submit\"\n        className=\"w-full bg-red-500 text-white py-2 px-4 rounded hover:bg-red-600\"\n      >\n        Sign Out\n      </button>\n    </form>\n  );\n}\n```\n\n## ログイン専用ページの設定\n\n`/dashboard`以下の階層ではログインしないと入れないような仕組みにします．`auth()`からセッション情報を取得し，その内容で`signin`ページにリダイレクトするか，そのままdashboardページを開くか分岐させます．そのために`/dashboard/layout.tsx`を以下のように編集します．\n\n```tsx\nimport { auth } from \"@/auth\";\nimport { redirect } from \"next/navigation\";\nimport React from \"react\";\n\nexport default async function DashboardLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  const session = await auth();\n\n  if (!session) {\n    redirect(\"/signin\");\n  }\n\n  return <>{children}</>;\n}\n```\n\n## ページコンポーネントでの使用\n\n### `app/signin/page.tsx`\n\n```tsx\nimport SignIn from \"@/components/signin\";\n\nexport default function SignInPage() {\n  return (\n    <div className=\"flex items-center justify-center min-h-screen bg-gray-100\">\n      <div className=\"bg-white p-8 rounded shadow-md w-full max-w-md\">\n        <h1 className=\"text-2xl font-bold mb-6 text-center\">Sign In</h1>\n        <SignIn />\n      </div>\n    </div>\n  );\n}\n```\n\n### `app/dashboard/page.tsx`\n\n```tsx\nimport { SignOut } from \"@/components/sign-out\";\n\nexport default function DashboardPage() {\n  return (\n    <div className=\"flex flex-col items-center justify-center min-h-screen bg-gray-100\">\n      <div className=\"bg-white p-8 rounded shadow-md w-full max-w-2xl\">\n        <h1 className=\"text-3xl font-bold mb-6 text-center\">Dashboard</h1>\n        <p className=\"mb-4 text-center\">Welcome to your dashboard!</p>\n        <div className=\"flex justify-center\">\n          <SignOut />\n        </div>\n      </div>\n    </div>\n  );\n}\n```\n\n# テスト\n\n---\n\n- http://localhost:3000\n- http://localhost:3000/signin\n- http://localhost:3000/dashboard\n\nこれらのページを開いて，それぞれの挙動を確認しましょう．\n\n次回は，バックエンドとの統合について解説していきます．\n[Auth.jsとRuby on Railsによるユーザ管理](https://techblog-notes.vercel.app/174f1269-0c19-419b-a9f5-09a691e2f342)\n",
    "createdAt": "2025-07-21T07:23:48.457Z",
    "updatedAt": "2025-07-21T07:23:48.458Z"
  },
  {
    "title": "Consideration of a Generative Method Using a Gaussian Mixture Model",
    "summary": "We constructed a basic generative model using a Gaussian Mixture Model (GMM).",
    "tags": [
      "python",
      "Machine Learning",
      "Data Science",
      "Mathematical Optimization"
    ],
    "slug": "Generative-AI/GMM-gen-ai",
    "folder": "Generative-AI",
    "content": "\n# Gaussian Mixture Model (GMM)\n\n- A clustering method.\n- Can also be used as a generative model.\n- Represents a given dataset as a combination of multiple Gaussian distributions.\n- Provides a probability density function, which explains its use as a generative model.\n- Can automatically determine the number of clusters.\n- Reveals the prior distribution of explanatory variable X (latent variable).\n\n## Gaussian Distribution (can be visualized as a graph in a two-dimensional space of x and y)\n\n$$\nN(x|\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right\\}\n$$\n\n## Multivariate Normal Distribution (Can be viewed as a graph in three or more dimensions such as x, y, z...)\n\n$$\nN(\\mathbf x|\\mathbf\\mu,\\Sigma)=\\frac{1}{(2\\pi)^\\frac{m}{2}}\\frac{1}{|\\Sigma|^{\\frac{1}{2}}}\\exp\\left\\{-\\frac{1}{2}(\\mathbf x-\\mathbf\\mu)^T\\Sigma^{-1}(\\mathbf x-\\mathbf\\mu)\\right\\}\\quad\\left(\\mathbf x:\nRandom~variable~vector,\\mathbf\\mu:Average~vector,\\Sigma:Covariance~matrix\\right)\n$$\n\n## Mixture of Gaussian Distribution (Multiple peaks are formed)\n\n$$\np(\\mathbf x)=\\sum_{k=1}^n\\pi_kN(\\mathbf x|\\mu_k,\\Sigma_k)\\quad\\left(n:n ~Gaussian~distributions,k:k-th~Gaussian~distribution,\\pi_k:Mixture~coefficient\\left(Weight~of~each~Gaussian~distribution,\\sum_{k=1}^n\\pi_k=1\\right)\\right)\n$$\n\nReference: https://datachemeng.com/wp-content/uploads/gaussianmixturemodel.pdf\n\n# Prior distribution of Mixture Gaussian Distribution\n\nThe prior distribution here is the distribution of \"which cluster a variable belongs to after receiving it.\" If we define the latent variable as $\\mathbf z$, then $\\mathbf z$ is\n\n- A vector (i.e., a matrix) with a one-hot vector that is 1 in one cluster and 0 in the others.\n- If there is no information about the sample, the probability that $\\mathbf z_k=1$ is set to follow the mixture coefficient.\n  $$\n  p(\\mathbf z_k=1)=\\pi_k\n  $$\n\nIf this is not introduced, the area will not be 1 in the mixture Gaussian distribution (it is obvious that the sum of probabilities will exceed 1 if simply added).\n\n## Finding the prior distribution\n\nUsing Bayes' theorem, the probability that a sample $\\mathbf x$ will be $z_k=1$ given is\n\n$$\np(z_k=1|\\mathbf x)=\\frac{p(z_k=1)p(\\mathbf x|z_k=1)}{\\sum_{i=1}^np(z_k=1)p(\\mathbf x|z_i=1)}=\\frac{\\pi_kp(\\mathbf x|z_k=1)}{\\sum_{i=1}^n\\pi_ip(\\mathbf x|z_i=1)}=\\frac{\\pi_kN(\\mathbf x|\\mu_k,\\Sigma_k)}{\\sum_{i=1}^n\\pi_iN(\\mathbf x|\\mu_i,\\Sigma_i)}\n$$\n\nFrom this,\n\n$$\nk^\\star=\\arg\\max_kp(z_k=1|\\mathbf x)\n$$\n\nBy doing so, the cluster at a certain point $\\mathbf x$ can be estimated.\n\n# Creating a Mixture Gaussian Distribution\n\n## Definition of probability density function\n\n```py\n# Multivariate normal distribution\ndef gaussian_densty(x, mu, sigma): # (1, n), (1, n), (n, n)\n  diff = x - mu\n  sigma_inv = np.linalg.inv(sigma)\n  sigma_det = np.linalg.det(sigma)\n  z = np.exp(-np.dot(diff.T, np.dot(sigma_inv, diff)) / 2)\n\n  return z / np.sqrt(np.power(2*np.pi, len(mu)) * sigma_det) # (1, n)\n\n# Mixture Gaussian distribution\ndef mixture_gaussian_densty(x, mu_list, sigma_list, pi_list): # (1, n), (k, n), (k, n, n), (1, k)\n  z = 0\n  for i in range(len(pi_list)):\n    z += pi_list[i] * gaussian_densty(x, mu_list[i], sigma_list[i])\n  return z # (1, n)\n```\n\n> Note that only the probability density function has been created, so the corresponding code is required to sample it.\n\n## Using NumPy's Official Multivariate Normal Distribution\n\n```py\n# Generate samples from a multivariate normal distribution\ndef sample_multivariate_gaussian(mu, sigma, num_samples=1):\n    return np.random.multivariate_normal(mu, sigma, num_samples)\n\n# Generate samples from a mixture Gaussian distribution\ndef sample_mixture_gaussian(mu_list, sigma_list, pi_list, num_samples=100):\n    samples = []\n    num_clusters = len(pi_list)\n\n    # Determine the number of samples in each cluster\n    cluster_sizes = np.random.multinomial(num_samples, pi_list) # Randomly determine the number of samples in each cluster using the mixture coefficients\n\n    for i in range(num_clusters):\n        # Generate samples for each cluster\n        cluster_samples = sample_multivariate_gaussian(mu_list[i], sigma_list[i], cluster_sizes[i])\n        samples.append(cluster_samples)\n\n    # Combine the samples and return them\n    return np.vstack(samples)\n```\n\n## Preparing the data\n\n```py\n# Prepare sample data\n# Create a Gaussian mixture distribution with random variable X = [x0, x1], Mu = [mu0, mu1], and latent variable Z = [z0, z1, z2].\n\n# Cluster 0\nmu0 = np.array([0, -0.5])\nsigma0 = np.array([[1.0, 0], [0, 1.0]])\n# Cluster 1\nmu1 = np.array([2.5, 2])\nsigma1 = np.array([[0.5, 0.3], [0.3, 0.7]])\n\n# Cluster 2\nmu2 = np.array([-2, 1.5])\nsigma2 = np.array([[1.2, 0.2], [0.2, 0.4]])\n\n# Combine data\nmu_list = [mu0, mu1, mu2]\nsigma_list = [sigma0, sigma1, sigma2]\npi_list = [0.45, 0.25, 0.3]\n\n# Number of sample data points\nNUM_DATA = 500\n\n# Generate samples from the Gaussian mixture distribution\nsamples = sample_mixture_gaussian(mu_list, sigma_list, pi_list, num_samples=NUM_DATA)\n\nsamples[:10]\n```\n\n## Plotting the Gaussian Mixture Distribution\n\n```py\ndef plot_mixture_gaussian(mu_list, sigma_list, pi_list, samples=None, figsize=(8,6)):\n    x_range = np.linspace(-5, 5, 100)\n    y_range = np.linspace(-5, 5, 100)\n    X, Y = np.meshgrid(x_range, y_range)\n    Z = np.zeros((len(x_range), len(y_range)))\n\n    # Calculate the probability density for each coordinate\n    for i in range(len(x_range)):\n        for j in range(len(y_range)):\n            x = np.array([x_range[i], y_range[j]])\n            Z[i, j] = mixture_gaussian_densty(x, mu_list, sigma_list, pi_list)\n\n    plt.figure(figsize=figsize)\n    if samples is not None:\n        plt.scatter(samples[:, 1], samples[:, 0], color='red', s=10, label='Samples')\n    plt.contour(X, Y, Z, cmap='viridis')\n    plt.colorbar(label='Density')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Mixture Gaussian Distribution')\n    plt.show()\n\nplot_mixture_gaussian(mu_list, sigma_list, pi_list, samples)\n```\n\n# Estimating Clusters from Samples\n\n`To be considered later`\n\n# Estimating Parameters of the Mixture Gaussian Distribution from Samples\n\n## Maximum Likelihood Estimation\n\n\"Likelihood maximization\" is one of the methods to estimate the distribution from the sample data.\n\n$$\nLikelihood~function:{\\cal L}(\\theta;\\mathbf x)=\\prod_{i=1}^nP(x_i;\\theta),\\quad Maximum~likelihood~estimator:\\theta^\\star=\\arg\\max_\\theta{\\cal L}(\\theta;\\mathbf x)\\quad(n:Number~of~samples)\n$$\n\nReference: https://cochineal19.hatenablog.com/entry/2021/11/08/003751\n\n## Define the log likelihood function\n\nIt's hard to calculate the likelihood function directly because it's a product of many probabilities. Therefore, it is common to use the log likelihood function.\n\nThere is no effect on the maximum value of the function because the logarithm is a monotonically increasing function.\n\n$$\n{\\cal L}(\\mu,\\Sigma,\\pi;\\mathbf x)=\\prod_{i=1}^np(\\mathbf x;\\mu,\\Sigma,\\pi)=\\prod_{i=1}^n\\sum_{k=1}^n\\pi_kN(\\mathbf x|\\mu_k,\\Sigma_k)\\\\\\to\\log{\\cal L}(\\mu,\\Sigma,\\pi;\\mathbf x)=\\log\\prod_{i=1}^n\\sum_{k=1}^n\\pi_kN(\\mathbf x|\\mu_k,\\Sigma_k)=\\sum_{i=1}^n\\log\\sum_{k=1}^n\\pi_kN(\\mathbf x|\\mu_k,\\Sigma_k)\n$$\n\n```py\ndef log_likelihood(mu_list, sigma_list, pi_list, sample):\n  log_likelihood = 0\n  for i in range(len(sample)):\n    log_likelihood += np.log(mixture_gaussian_densty(sample[i], mu_list, sigma_list, pi_list))\n\n  return log_likelihood\n```\n\n## Defining the Burden Rate\n\nSince we need to find the prior distribution \\( p(z|x) \\) of \\( p(x|z) \\), the prior probability of each cluster for a given data point \\( \\mathbf{x_i} \\) is expressed as follows:\n\n$$\np_{\\mu,\\Sigma,\\pi}(z_{ik}=1|\\mathbf{x_i}) = \\frac{\\pi_k{\\cal N}(\\mathbf{x_i};\\mu_k,\\Sigma_k)}{\\sum_{j=1}^K \\pi_j {\\cal N}(\\mathbf{x_i};\\mu_j,\\Sigma_j)} \\equiv \\gamma(z_{ik})\n$$\n\nIntuitively, we are calculating the probability that the distribution of each cluster fits the given data point.\n\n```py\ndef responsibility(data, mu_list, sigma_list, pi_list):\n    gamma = np.zeros((len(data), len(pi_list)))\n    for i in range(len(data)):\n        for j in range(len(pi_list)):\n            gamma[i, j] = pi_list[j] * gaussian_density(data[i], mu_list[j], sigma_list[j])\n        gamma[i] /= np.sum(gamma[i])\n    return gamma\n```\n\n### Classifying Using the Burden Rate\n\nTo perform classification, we need to find:\n\n$$\nz^\\star = \\argmax_{z_{ik}} \\gamma(z_{ik})\n$$\n\nThis gives us the cluster with the highest responsibility for each data point.\n\n```python\ndf = pd.DataFrame(samples[:, [1, 0]], columns=['x', 'y'])\ngamma = responsibility(samples, mu_list, sigma_list, pi_list)\ndf['gamma0'] = gamma[:, 0]\ndf['gamma1'] = gamma[:, 1]\ndf['gamma2'] = gamma[:, 2]\ndf['z_star'] = df[['gamma0', 'gamma1', 'gamma2']].idxmax(axis=1)\n\nx_range = np.linspace(-5, 5, 100)\ny_range = np.linspace(-5, 5, 100)\nX, Y = np.meshgrid(x_range, y_range)\nZ = np.zeros((len(x_range), len(y_range)))\n\n# Calculate probability density for each coordinate\nfor i in range(len(x_range)):\n    for j in range(len(y_range)):\n        x = np.array([x_range[i], y_range[j]])\n        Z[i, j] = mixture_gaussian_density(x, mu_list, sigma_list, pi_list)\n\nsns.scatterplot(x='x', y='y', hue='z_star', data=df, palette='viridis')\nplt.contour(X, Y, Z, cmap='viridis')\nplt.colorbar(label='Density')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Mixture Gaussian Distribution')\nplt.show()\n```\n\n## Learning\n\nTo maximize the log-likelihood, we need to solve:\n\n$$\n\\argmax_{\\mu,\\Sigma,\\pi} \\log {\\cal L}(\\mu, \\Sigma, \\pi; \\mathbf{x}) = \\argmax_{\\mu,\\Sigma,\\pi} \\sum_{i=1}^n \\log \\sum_{k=1}^K \\pi_k N(\\mathbf{x} | \\mu_k, \\Sigma_k)\n$$\n\nIn this case, the log-sum part makes it difficult to solve analytically → We optimize it using the Expectation-Maximization (EM) algorithm.\n\n### Initialize the parameters\n\nSet randomly\n\n### E-Step\n\nCalculate the responsibility for each data point at the current step:\n\n$$\np_{\\mu,\\Sigma,\\pi}(z_{ik}=1|\\mathbf x_i)=\\frac{\\pi_k{\\cal N}(\\mathbf x_i;\\mu_k,\\Sigma_k)}{\\sum_{j=1}^K\\pi_j{\\cal N}(\\mathbf x_i;\\mu_j,\\Sigma_j)}\\equiv\\gamma(z_{ik})\n$$\n\n### M-Step\n\nUpdate the parameters to maximize the likelihood using the responsibilities:\n\n$$\n\\begin{aligned}\n&\\frac{\\partial{\\cal L}}{\\partial\\mu_k}=0\\to\\mu_k=\\frac{1}{N_k}\\sum_{i=1}^n\\gamma(z_{ik})\\mathbf x_i\\\\\n&\\frac{\\partial{\\cal L}}{\\partial\\Sigma_k}=0\\to\\Sigma_k=\\frac{1}{N_k}\\sum_{i=1}^n\\gamma(z_{ik})(\\mathbf x_i-\\mu_k)(\\mathbf x_i-\\mu_k)^T\n\\end{aligned}\n\\quad\\left(N_k=\\sum_{i=1}^n\\gamma(z_{ik})\\right)\n$$\n\nFor $\\pi_k$, since $\\sum_{k=1}^K\\pi_k=1$, we use the Lagrange multiplier method to maximize the likelihood:\n\n$$\n\\frac{\\partial G}{\\partial\\pi_k}=0\\to\\pi_k=\\frac{N_k}{\\sum_{k=1}^KN_k}\\quad\\left(G={\\cal L}+\\lambda\\left(\\sum_{k=1}^K\\pi_k-1\\right)\\right)\n$$\n\n### Convergence Condition\n\nIf the change in the likelihood meets a predefined threshold $\\epsilon$:\n\n$$\n{\\cal L}_{new}-{\\cal L}_{old}<\\epsilon\n$$\n\nthen stop the iterations; otherwise, repeat the EM steps.\n\n```python\n# Number of clusters (You can use methods to find the optimal number)\nK = 3\n\n# Initialize random mean vectors (2D)\nmu_list = [np.random.randn(2) for _ in range(K)]\n\n# Initialize random covariance matrices (2x2)\nsigma_list = []\nfor _ in range(K):\n    A = np.random.randn(2, 2)\n    sigma = np.dot(A, A.T)  # Create symmetric and positive definite matrices\n    sigma_list.append(sigma)\n\n# Initialize random mixing coefficients and normalize\npi_list = np.random.rand(K)\npi_list = pi_list / np.sum(pi_list)\n\n# Display the results\nprint(\"mu_list:\", mu_list)\nprint(\"sigma_list:\", sigma_list)\nprint(\"pi_list:\", pi_list)\n\nn_iter = 0\n\nlikely = log_likelihood(mu_list, sigma_list, pi_list, samples) / NUM_DATA\nprint('Iteration: {0}, log_likelihood: {1}'.format(n_iter, likely))\nplot_mixture_gaussian(mu_list, sigma_list, pi_list, samples, figsize=(4,3))\n\nth = 0.0001\n\nwhile True:\n  n_iter += 1\n\n  # E-Step\n  gamma = responsibility(samples, mu_list, sigma_list, pi_list)\n  n_k = np.sum(gamma, axis=0)\n\n  # M-Step\n\n  # Update pi\n  pi_list_next = (n_k / n_k.sum()).tolist()\n\n  # Update mu\n  mu_list_next = list(((samples.T @ gamma) / n_k).T)\n\n  # Update Sigma\n  sigma_list_next = []\n  for k in range(len(pi_list)):\n    sigma_k = np.zeros_like(sigma_list[k], dtype=float)\n    for i in range(len(samples)):\n      sigma_k += gamma[i, k] * np.matmul(\n          (samples[i] - mu_list[k]).reshape(-1, 1),\n          (samples[i] - mu_list[k]).reshape(1, -1)\n      )\n\n    sigma_list_next.append(sigma_k/n_k[k])\n\n  # Why deepcopy here? (Possibly due to reference issues)\n  # Also, why is 'next' converted to regular lists for all?\n  mu_list = copy.deepcopy(mu_list_next)\n  sigma_list = copy.deepcopy(sigma_list_next)\n  pi_list = copy.deepcopy(pi_list_next)\n\n  # Convergence condition\n  likely_before = likely\n  likely = log_likelihood(mu_list, sigma_list, pi_list, samples) / NUM_DATA\n  print('Iteration: {0}, log_likelihood: {1}'.format(n_iter, likely))\n  plot_mixture_gaussian(mu_list, sigma_list, pi_list, samples, figsize=(4,3))\n\n  delta = likely - likely_before\n  if delta < th:\n    break\n\n# Display results\nprint(\"mu_list:\", mu_list)\nprint(\"sigma_list:\", sigma_list)\nprint(\"pi_list:\", pi_list)\n```\n",
    "createdAt": "2025-07-21T07:23:48.457Z",
    "updatedAt": "2025-07-21T07:23:48.457Z"
  },
  {
    "title": "CSSの基礎",
    "summary": "HTMLをかっこいいデザインにする！",
    "tags": [
      "Web",
      "CSS",
      "HTML",
      "基礎"
    ],
    "slug": "html-css/basic-css",
    "folder": "html-css",
    "content": "\n# コードを書くための準備\n\n---\n\n## 開発環境がない場合\n\n1. ブラウザで _code pen_ と検索\n   [CodePen: Online Code Editor and Front End Web Developer ...](https://codepen.io/)\n1. 一番上のサイトを開く\n1. 左側にある「Start Coding」を押す\n1. htmlとcssを試すことができる！\n\n# HTMLとは\n\n1. **Hyper Text Markup Language**の略\n1. 文章を書きウェブサイトに上げることができる\n1. 「タグ」によって文字に役割を与えることができる\n1. デザインを変えたり，動きを与えることはHTMLだけではほぼ不可能\n\n```HTML\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>My First HTML</title>\n  </head>\n  <body>\n    <h1>My First Heading</h1>\n    <p>My first paragraph.</p>\n    <a href=\"#\">This is a link</a>\n  </body>\n</html>\n```\n\n## タグの種類\n\n| タグ            | 概要                                             |\n| --------------- | ------------------------------------------------ |\n| `<html></html>` | htmlの外殻                                       |\n| `<head></head>` | ウェブサイトのタイトルや文字コードなど決める場所 |\n| `<body></body>` | サイトの内容を書く場所                           |\n| `<h1></h1>`     | 見出し                                           |\n\nほかにもめちゃくちゃある！\n\n# CSSとは\n\n---\n\n1. **Cascading Style Sheets** の略\n1. HTMLにデザインを指定できる\n\n# ボックスモデルを知ろう！\n\n---\n\n## WEBページはブロックの集まり\n\n### ボックスモデルとは？\n\nHTMLの要素はすべて四角形の領域で構成されているという考え方\n\n### ページの構造\n\nWEBサイトはボックスを並べたり，格納したり，重ねているだけ\n\n### ブロックとインライン\n\nボックスはブロックボックスとインラインボックスに分けられる (詳しくは別の回で)\n\n## 開発者ツールでページの構造を見てみよう！\n\n1. webページを開く\n   [https://google.com](https://google.com)\n1. `f12`キーを押す\n1. ごちゃごちゃした画面が出てきたら成功！\n\n## 明示的にボックスをつくろう！\n\n`<div>`タグは子要素をグループ化してくれるよ！\n\n```HTML\n<!DOCTYPE html>\n<html lang=\"ja\">\n\n  <head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>○○テック講座</title>\n  </head>\n\n  <body>\n\n    <div>\n      <h1>○○テック講座</h1>\n      <p>Webサイトをつくろう！</p>\n    </div>\n\n    <div>\n      <h2>活動内容</h2>\n      <div>\n        <div>\n          <p>1. HTMLとCSSの基本を学ぶ</p>\n          <p>2. レスポンシブデザインを作成する</p>\n        </div>\n        <div>\n          <p>3. JavaScriptを使ったインタラクティブな機能を実装する</p>\n          <p>4. GitとGitHubの使い方を習得する</p>\n        </div>\n      </div>\n      <div>\n        <div>\n          <p>5. Rubyを学び、Webアプリケーションを作成する</p>\n          <p>6. チーム開発を体験する</p>\n        </div>\n        <div>\n          <p>7. ポートフォリオを作成する</p>\n          <p>8. もくもく会を開催する</p>\n        </div>\n    </div>\n\n    <div>\n      <div>\n        <h3>チームメンバー</h3>\n        <div>\n          <p>メンバー1: 山田太郎</p>\n          <p>メンバー2: 佐藤花子</p>\n        </div>\n        <div>\n          <p>メンバー3: 鈴木一郎</p>\n          <p>メンバー4: 中村幸子</p>\n        </div>\n      </div>\n      <div>\n        <h3>お問い合わせ</h3>\n        <div>\n          <p>メール: contact@example.com</p>\n          <p>電話: 03-1234-5678</p>\n        </div>\n      </div>\n    </div>\n\n  </body>\n\n</html>\n```\n\n開発者ツールで以下の二点を確認しよう！\n\n- divタグは普通目には見えない\n- divタグによってグループ化されている\n\n# 要素に名前をつけよう！\n\n---\n\n## 要素に名前をつけるって？？\n\n要素を並べるときに，\n\n- 「同じタグを区別できるようにしたい」\n- 「他とは違う要素だと示したい」\n- 「要素をグループに分けたい」\n- 「名前をつけて読みやすくしたい」\n\nなどの場合に，名前を付けます．つけた名前は，CSSやJavaScriptで使うことができます．その要素だけが持つ「id」と所属グループを示す「class」を指定することができます．\n\n```html\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>My First HTML</title>\n  </head>\n  <body>\n    <div id=\"title\">\n      {/*idを指定*/}\n      <h1>My First HTML</h1>\n      <p>Welcome to my first HTML page.</p>\n    </div>\n    <div id=\"foods\" class=\"menu\">\n      {/*idとclassを指定*/}\n      <h2>My Favorite Foods</h2>\n      <ul>\n        <li>Pizza</li>\n        <li>Ice Cream</li>\n        <li>Chocolate</li>\n      </ul>\n    </div>\n    <div id=\"movies\" class=\"menu\">\n      {/*idとclassを指定*/}\n      <h2>My Favorite Movies</h2>\n      <ol>\n        <li>Star Wars</li>\n        <li>Indiana Jones</li>\n        <li>Back to the Future</li>\n      </ol>\n    </div>\n  </body>\n</html>\n```\n\n## idとclassの違い\n\n### class\n\n```html\n<要素名 class=“クラス名”>\n```\n\nほかの要素にも同じクラス名をつけてよい．グループ化をするのが主な目的\n\n### id\n\n```html\n<要素名 id=“id”>\n```\n\nclassとは違い一意の値でなければならないという規則がある\n\n## 各要素に名前をつけよう\n\n```html\n<!DOCTYPE html>\n<html lang=\"ja\">\n\n  <head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>○○テック講座</title>\n    <link rel=\"stylesheet\" href=\"stylesheet.css\">\n  </head>\n\n  <body>\n\n    <div id=\"header\">\n      <h1>○○テック講座</h1>\n      <p>Webサイトをつくろう！</p>\n    </div>\n\n    <div id=\"activities\">\n      <h2>活動内容</h2>\n      <div id=\"first-semister\" class=\"activity-list\">\n        <div>\n          <p>1. HTMLとCSSの基本を学ぶ</p>\n          <p>2. レスポンシブデザインを作成する</p>\n        </div>\n        <div>\n          <p>3. JavaScriptを使ったインタラクティブな機能を実装する</p>\n          <p>4. GitとGitHubの使い方を習得する</p>\n        </div>\n      </div>\n      <div id=\"second-semister\" class=\"activity-list\">\n        <div>\n          <p>5. Rubyを学び、Webアプリケーションを作成する</p>\n          <p>6. チーム開発を体験する</p>\n        </div>\n        <div>\n          <p>7. ポートフォリオを作成する</p>\n          <p>8. もくもく会を開催する</p>\n        </div>\n    </div>\n\n    <div id=\"team-contact\">\n      <div class=\"team-section\">\n        <h3>チームメンバー</h3>\n        <div>\n          <p>メンバー1: 山田太郎</p>\n          <p>メンバー2: 佐藤花子</p>\n        </div>\n        <div>\n          <p>メンバー3: 鈴木一郎</p>\n          <p>メンバー4: 中村幸子</p>\n        </div>\n      </div>\n      <div class=\"contact-section\">\n        <h3>お問い合わせ</h3>\n        <div>\n          <p>メール: contact@example.com</p>\n          <p>電話: 03-1234-5678</p>\n        </div>\n      </div>\n    </div>\n\n  </body>\n\n</html>\n```\n\nできあがったらLive-serverでサイトを立ち上げ，f12で探索しよう！\n開発者ツールで以下の一点を確認しよう！\n\n- 「elements」タブに表示される各要素に名前が設定されている\n\n# CSSの書き方\n\n---\n\n## 三種類の書き方\n\n### インラインスタイル\n\n特定の要素に対して直接スタイルを指定する手法\n\n直感的だが，同じコードを何度も書く必要がある場合が存在する\n\n### 内部スタイルシート\n\nHTMLファイルの中にCSSを書く欄を設け，セレクタによってスタイルを割り当てる手法．\n\n外部ファイルがいらないが，ほかのページでコードの再利用ができない\n\n### 外部スタイルシート\n\nCSSを記述するファイルを用意し，セレクタによってスタイルを割り当てる手法．\n\nスタイルの共通化ができ，管理もしやすい\n\n## 基本文法\n\n1. セレクタで対象の要素を指定する\n1. プロパティで設定したいスタイルを指定する\n1. バリューでスタイルの数値を適用する\n\n## セレクタによる要素の指定方法例\n\n| セレクタ                      | 構文例                 | 概要                                   |\n| ----------------------------- | ---------------------- | -------------------------------------- |\n| 要素セレクタ                  | `div`                  | 指定のタグを持つ要素に適用             |\n| クラスセレクタ                | `.hogeHope`            | 指定のクラスを持つ要素に適用           |\n| IDセレクタ                    | `#fuga_fuga`           | 指定のIDを持つ要素に適用               |\n| IDセレクタ and クラスセレクタ | `#fuga_fuga .hogeHope` | 親要素が指定された中の指定クラスに適用 |\n| 要素セレクタ or 要素セレクタ  | `div, h1`              | 複数種類のタグに適用                   |\n\nほかにもたくさんのセレクト手法があるよ！\n\n## プロパティの例\n\n| グループ     | プロパティ         | 概要                               |\n| ------------ | ------------------ | ---------------------------------- |\n| テキスト関連 | `color`            | テキストの色を変更する             |\n|              | `font-size`        | テキストのサイズを変更する         |\n|              | `text-align`       | 左揃え、中央揃え、右揃えを指定する |\n| ボックス関連 | `padding`          | ボックス内側の余白の幅を指定する   |\n|              | `margin`           | ボックス外側の余白の幅を指定する   |\n|              | `border`           | ボックスの枠線を設定する           |\n| 背景関連     | `background-color` | 背景色を変更する                   |\n| 配置関連     | `display`          | 横並びにしたり縦並びにしたりする   |\n\nほかにもたくさんのプロパティがあるよ！\n\n## バリューの例\n\n| グループ | バリュー例       | 概要                                                   |\n| -------- | ---------------- | ------------------------------------------------------ |\n| サイズ   | `1024px`         | 1ピクセル=0.26mm                                       |\n|          | `16rem`          | 1rem=ルートの要素のテキストサイズ（推奨）              |\n|          | `100vw, 100vh`   | 100vw=横幅のサイズ、100vh=縦幅のサイズ                 |\n| 色       | `red`            | 名前                                                   |\n|          | `#ff0000`        | 16進数                                                 |\n|          | `rgb(255, 0, 0)` | rgb表現                                                |\n| その他   | `flex`           | `display: flex`のように使う。子要素を横並びにできる    |\n| 配置関連 | `none`           | `border: none`のように使う。枠線を取り消すことができる |\n\nほかにもたくさんのバリューがあるよ！\n\n# CSSを適用する一連の流れ\n\n一旦整理しよう\n\n---\n\n## 1. index.htmlを書く\n\n1. head部分など基盤を作る\n1. body内に表示する内容を書く\n1. 適宜classやidを要素に与える\n1. 今回はさっき作ったhtmlファイルを使っちゃおう！\n\n## 2. cssファイルを置く，index.htmlでcssファイルを指定する\n\n1. index.htmlと同じ場所に「stylesheet.css」を配置！\n1. 次に，index.htmlファイルを開く\n1. `<head>`内に`<link rel=“stylesheet” href=“stylesheet.css”>`を追加！\n\n```html\n<head>\n  <meta charset=\"UTF-8\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n  <title>○○テック講座</title>\n  <link rel=\"stylesheet\" href=\"stylesheet.css\" />\n</head>\n```\n\nこれでhtmlファイルとcssをつなげることができた！\n\n## 3. cssコードを書く\n\n1.  セレクタを使って適用する要素を指定する\n1.  プロパティを書き，デザインする\n1.  セレクタ×プロパティの組を並べていく\n\nひとまずbody要素にcssを適用して，どのようにデザインが変わるか確認してみよう！\n\n```css\nbody {\n  font-family: Arial, sans-serif; /*フォントを指定*/\n  line-height: 1.6; /*行間を1.6倍に*/\n  margin: 0; /*ページの外側の余白を0に*/\n  padding: 0; /*ページの内側の余白を0に*/\n  background-color: #f9f9f9; /*背景色を指定*/\n  color: #333; /*文字色を指定*/\n}\n```\n\n> CSSは覚えようとすると頭爆発します．実践あるのみ！\n\n# 4. 演習\n\n説明していないセレクタやプロパティなどがたくさん出てくるのでぜひ調べながら書いてください！\n\n---\n\n## 現時点のhtmlコード\n\n```html\n<!DOCTYPE html>\n<html lang=\"ja\">\n\n  <head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>○○テック講座</title>\n    <link rel=\"stylesheet\" href=\"stylesheet.css\">\n  </head>\n\n  <body>\n\n    <div id=\"header\">\n      <h1>○○テック講座</h1>\n      <p>Webサイトをつくろう！</p>\n    </div>\n\n    <div id=\"activities\">\n      <h2>活動内容</h2>\n      <div id=\"first-semister\" class=\"activity-list\">\n        <div>\n          <p>1. HTMLとCSSの基本を学ぶ</p>\n          <p>2. レスポンシブデザインを作成する</p>\n        </div>\n        <div>\n          <p>3. JavaScriptを使ったインタラクティブな機能を実装する</p>\n          <p>4. GitとGitHubの使い方を習得する</p>\n        </div>\n      </div>\n      <div id=\"second-semister\" class=\"activity-list\">\n        <div>\n          <p>5. Rubyを学び、Webアプリケーションを作成する</p>\n          <p>6. チーム開発を体験する</p>\n        </div>\n        <div>\n          <p>7. ポートフォリオを作成する</p>\n          <p>8. もくもく会を開催する</p>\n        </div>\n    </div>\n\n    <div id=\"team-contact\">\n      <div class=\"team-section\">\n        <h3>チームメンバー</h3>\n        <div>\n          <p>メンバー1: 山田太郎</p>\n          <p>メンバー2: 佐藤花子</p>\n        </div>\n        <div>\n          <p>メンバー3: 鈴木一郎</p>\n          <p>メンバー4: 中村幸子</p>\n        </div>\n      </div>\n      <div class=\"contact-section\">\n        <h3>お問い合わせ</h3>\n        <div>\n          <p>メール: contact@example.com</p>\n          <p>電話: 03-1234-5678</p>\n        </div>\n      </div>\n    </div>\n\n  </body>\n\n</html>\n```\n\n## タグに対するスタイリング\n\n各タグに対し適用\n\n```CSS\nbody {\n  font-family: Arial, sans-serif; /*フォントを指定*/\n  line-height: 1.6; /*行間を1.6倍に*/\n  margin: 0; /*ページの外側の余白を0に*/\n  padding: 0; /*ページの内側の余白を0に*/\n  background-color: #f9f9f9; /*背景色を指定*/\n  color: #333; /*文字色を指定*/\n}\n\ndiv {\n  padding: 20px; /*要素の内側の余白を20pxに*/\n  max-width: 800px; /*要素の最大幅を800pxに*/\n  margin: 20px auto; /*要素を中央寄せに*/\n  background-color: #fff; /*背景色を指定*/\n  border-radius: 8px; /*角丸を8pxに*/\n  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1) /*影を指定*/;\n}\n\nh1, h2, h3 { /*h1, h2, h3タグを指定*/\n  color: #444; /*見出しの文字色を指定*/\n}\n\nh1 {\n  font-size: 2.5em; /*見出しの文字サイズを2.5emに*/\n  margin-bottom: 10px; /*見出しの下の余白を10pxに*/\n}\n\nh2 {\n  font-size: 1.8em; /*見出しの文字サイズを1.8emに*/\n  margin-top: 20px; /*見出しの上の余白を20pxに*/\n  border-bottom: 2px solid #e1e1e1; /*見出しの下に2pxの線を引く*/\n  padding-bottom: 5px; /*見出しの下の余白を5pxに*/\n}\n\nh3 {\n  font-size: 1.5em; /*見出しの文字サイズを1.5emに*/\n  margin-top: 15px; /*見出しの上の余白を15pxに*/\n}\n```\n\n## idに対するスタイリング\n\n各idやそれに付随するクラス，タグに対し適用\n\n```css\n#header {\n  text-align: center; /*テキストを中央寄せに*/\n}\n\n#header p {\n  /*親要素のidがheaderであるpタグを指定*/\n  font-size: 1.2em; /*文字サイズを1.2emに*/\n  color: #555; /*文字色を指定*/\n  margin-top: 5px; /*上の余白を5pxに*/\n}\n\n#activities {\n  margin-top: 30px; /*上の余白を30pxに*/\n}\n\n#activities .activity-list div {\n  /* 親要素のidがactivitiesで、クラスがactivity-listのdivタグを指定 */\n  margin-bottom: 15px; /*下の余白を15pxに*/\n}\n\n#activities .activity-list p {\n  /* 親要素のidがactivitiesで、クラスがactivity-listのpタグを指定 */\n  padding-left: 15px; /*左の余白を15pxに*/\n  text-indent: -15px; /*テキストを左に15pxずらす*/\n  list-style: inside disc; /*リストのマーカーを指定*/\n}\n\n#team-contact {\n  /*idがteam-contactの要素を指定*/\n  display: flex; /*要素を横並びに*/\n  flex-wrap: wrap; /*要素を折り返し表示*/\n  gap: 20px; /*要素間の間隔を20pxに*/\n}\n```\n\n## クラスに対するスタイリング\n\n各クラスやそれに付随するタグに対し適用\n\n```css\n.team-section,\n.contact-section {\n  /*クラスがteam-section、contact-sectionの要素を指定*/\n  flex: 1; /*要素を均等に広げる*/\n  min-width: 200px; /*要素の最小幅を200pxに*/\n}\n\n.team-section div,\n.contact-section div {\n  /*クラスがteam-section、contact-sectionのdivタグを指定*/\n  margin-bottom: 10px; /*下の余白を10pxに*/\n}\n\n.team-section p,\n.contact-section p {\n  /*クラスがteam-section、contact-sectionのpタグを指定*/\n  margin: 8px 0; /*上下の余白を8pxに*/\n}\n\n.contact-section {\n  background-color: #eef6f9; /*背景色を指定*/\n  border-left: 4px solid #0aa; /*左側に4pxの線を引く*/\n}\n```\n\n> ひとつのブロックを設定するごとに，どのようにデザインが変わったか確認してみましょう\n>\n> \\\n> コメントは書いても書かなくてもよいです\n\n完成したら確認しましょう！\n\n# まとめ\n\nとりあえず\n\n1. `index.html`を作りタグを駆使して文章を書く\n1. `head`内に`<link rel=\"stylesheet\" href=\"stylesheet.css\">`を追加する\n1. 同じディレクトリに`stylesheet.css`を作る\n1. `stylesheet.css`でデザインを指定する\n\nこのプロセスさえわかれば十分です！お疲れさまでした！\n",
    "createdAt": "2025-07-21T07:23:48.458Z",
    "updatedAt": "2025-07-21T07:23:48.459Z"
  },
  {
    "title": "GitHub・Next.js・Vercel・Markdownで作る技術ブログ",
    "summary": "GitHub連携とMarkdown管理で、自分専用の技術ブログを構築する手順を解説。Next.js・Tailwind・Vercelを使って、コードと記事を統合管理できる開発者向けブログを作ります。",
    "tags": [
      "Next.js",
      "Markdown",
      "Vercel",
      "GitHub",
      "技術ブログ"
    ],
    "slug": "Next.js/techblog-making",
    "folder": "Next.js",
    "content": "\n## 🧭 1. はじめに\n\n個人の学習記録や技術メモをまとめるとき、\n「**QiitaやZennに投稿するほどじゃないけど、きちんと形に残したい**」\nそんな場面は多いと思います。\n\nこの記事では、**GitHub・Next.js・Vercel・Markdown** の4つを組み合わせて、\n**自分専用の技術ブログサイト**をゼロから構築する方法を紹介します。\n\n---\n\n### 🔧 本記事のゴール\n\n完成形は、こんな特徴を持つシンプルな技術ブログです：\n\n- 記事はすべて **Markdownファイル** (`content/` ディレクトリ内)\n- 自動で **記事一覧・検索・タグ機能** が生成される\n- デプロイは **Vercel連携だけで自動反映**\n- デザインは **Tailwind CSS** + **ダークモード対応**\n- ソースコードはすべて **GitHubで管理**\n\n実際のイメージとしては、ZennやTechBlogのような\n「**自分の知識を積み重ねていくストック型ブログ**」を想定しています。\n\n---\n\n### 🧰 使用技術と構成\n\n| 技術                         | 用途                   | 補足                                 |\n| ---------------------------- | ---------------------- | ------------------------------------ |\n| **Next.js 14 (App Router)**  | サイト本体の実装       | ルーティング・ビルド・SEO対応        |\n| **Markdown + gray-matter**   | 記事データの管理       | タイトルやタグをFrontmatterで定義    |\n| **Tailwind CSS + shadcn/ui** | UIデザイン             | コンポーネントとダークモード対応     |\n| **Fuse.js**                  | 記事検索               | `search-index.json` に基づく全文検索 |\n| **Vercel**                   | デプロイ・ホスティング | GitHub連携で自動更新                 |\n| **GitHub**                   | ソースコード管理       | mainブランチにpushで即反映           |\n\n---\n\n### 💡 なぜMarkdownで書くのか？\n\nMarkdownを使う最大のメリットは、**「開発環境と同じリズムで書ける」** ことです。\nVSCodeやNeovimなど自分のエディタで記事を書き、Git commitで履歴を残し、\npushするだけで自動的にサイトが更新されます。\n\nCMSや管理画面を用意する必要もなく、\n「**エンジニアが自分の思考をコードと同じように管理できる**」のが魅力です。\n\n---\n\n### 🚀 対象読者\n\n- 自分の技術ブログを **無料で・簡単に・長く運用したい人**\n- Next.js / React / Tailwind の基本がわかる人\n- CMSを使わず、**Markdown中心の静的ブログ**を作りたい人\n\n---\n\n### 📦 完成イメージ\n\n構築後は以下のような流れで更新できます：\n\n```bash\n# 1. 新しい記事を作成\n$ touch content/articles/nextjs-intro.md\n\n# 2. Markdownで記事を書く\n# ---\n# title: \"Next.jsの基本\"\n# tags: [\"Next.js\", \"React\"]\n# summary: \"Next.jsの基礎をまとめました。\"\n# ---\n\n# 3. commit & push\n$ git add .\n$ git commit -m \"Add new article\"\n$ git push origin main\n```\n\nすると、Vercelが自動でデプロイして\nあなたのブログに新しい記事がすぐ反映されます。\n\n---\n\n## 🏗️ 2. 全体構成の概要\n\nこの章では、**ブログ全体の構成**と**データの流れ**を整理します。\n本サイト「**techblog**」は、以下の4つの技術でシンプルに構成されています：\n\n- **GitHub**：ソースコードと記事を一元管理\n- **Next.js**：静的ブログを生成・表示するWebアプリ\n- **Markdown**：記事データを扱う軽量マークアップ言語\n- **Vercel**：デプロイとホスティング（CI/CD一体型）\n\n---\n\n### 🔄 全体のアーキテクチャ\n\n```mermaid\ngraph LR\n    A[📄 Markdownファイル<br/>（content/）] -->|gray-matterで解析| B[🧩 Next.js ビルド処理]\n    B -->|記事データをJSON化| C[🗂️ search-index.json]\n    C -->|Fuse.jsで全文検索| D[🔍 検索UI（Next.js）]\n    B -->|静的HTML生成| E[🌐 Vercel]\n    F[💻 GitHubリポジトリ] -->|push時に自動ビルド| E\n    E -->|公開URLに反映| G[👤 ユーザーが閲覧]\n    A -->|変更検知| H[🧠 watch-search-index.ts]\n    H -->|再生成| C\n```\n\n> `watch-search-index.ts` がローカル開発中の**ホットリロード**を実現。\n> Markdownファイルを更新すると、即座に `search-index.json` が再生成され、\n> Next.js のHMR（Hot Module Replacement）によってブラウザが自動更新されます。\n\n---\n\n### 🧱 コンポーネント構成の全体像\n\nNext.jsを中心に、「**静的サイト生成（SSG）＋クライアント検索＋ホットリロード**」で構築しています。\nこの設計により、バックエンドを持たずに**軽量で即時反映されるブログ環境**を実現しています。\n\n| 層                              | 役割                                     | 主なフォルダ / ファイル                                   |\n| ------------------------------- | ---------------------------------------- | --------------------------------------------------------- |\n| **Presentation (UI層)**         | ユーザー向けのUI（Tailwind / shadcn/ui） | `/app`, `/components`, `/features`                        |\n| **Content (データ層)**          | Markdown記事とメタ情報を扱う             | `/content`, `/scripts/generate-search-index.ts`           |\n| **Watcher (開発補助層)**        | Markdown変更を検知しインデックスを再生成 | `/scripts/watch-search-index.ts`, `/lib/force-refresh.ts` |\n| **Infrastructure (デプロイ層)** | GitHub & Vercel によるCI/CD              | GitHubリポジトリ, Vercel連携設定                          |\n| **Utility層**                   | 共通関数や型定義、検索機能               | `/lib`, `/features/searchResults`                         |\n\n---\n\n### 💡 設計方針のポイント\n\n1. **データ管理はファイル単位（Gitで完結）**\n   記事は `content/` ディレクトリ配下のMarkdownとして管理。\n   バージョン管理やレビュー履歴がGit上で追跡でき、履歴がそのまま資産になる。\n\n2. **Next.jsのSSGでSEOと表示速度を両立**\n   ビルド時に静的HTMLを生成するため、表示が速く、検索エンジンにも強い。\n\n3. **Fuse.jsによるクライアントサイド検索**\n   記事メタ情報を `search-index.json` にまとめ、ブラウザ内で全文検索を実現。\n   外部APIやDBを使わず、軽量かつメンテナンス性が高い。\n\n4. **ホットリロード対応で即時反映**\n   `watch-search-index.ts` がMarkdownの変更を監視し、\n   自動でインデックスを再生成・再ビルド。\n   記事を保存した瞬間にプレビューへ反映される。\n\n5. **Vercelによる自動デプロイ**\n   GitHubにpushするだけで、Vercelがビルドから公開まで自動化。\n   ローカル環境と本番環境の差異が生まれにくい構成。\n\n---\n\n### 📊 実際の処理フロー\n\n```mermaid\nflowchart TD\n    subgraph Local[\"ローカル開発環境\"]\n        M[✍️ Markdown記事作成<br/>content/*.md]\n        W[👀 watch-search-index.tsで変更監視]\n        S[🧠 generate-search-index.ts<br/>→ search-index.json再生成]\n        R[⚡ force-refresh.ts更新でNext.js HMR発火]\n        N[⚛️ ブラウザで自動リロード]\n    end\n\n    subgraph Remote[\"本番環境（Vercel）\"]\n        G[📦 GitHub push]\n        B[⚙️ Vercelビルド<br/>Next.js SSG生成]\n        H[🌍 公開サイト（静的HTML）]\n    end\n\n    M --> W --> S --> R --> N\n    N --> G --> B --> H\n```\n\n---\n\n### 🧩 ディレクトリ構成（抜粋）\n\n```bash\ntechblog/\n├── app/                      # Next.js App Router構成\n│   ├── page.tsx              # トップページ\n│   └── articles/[slug]/      # 記事ページ\n├── content/                  # Markdown記事を配置\n│   └── sample.md\n├── features/searchResults/   # 検索機能（Fuse.js）\n├── lib/                      # 共通関数・設定\n│   ├── utils.ts\n│   ├── constants.ts\n│   └── force-refresh.ts      # HMRトリガーファイル\n├── scripts/                  # ビルド・監視スクリプト\n│   ├── generate-search-index.ts\n│   ├── watch-search-index.ts\n│   └── generate-sitemap.ts\n├── public/                   # 公開ファイル群（favicon, sitemap）\n└── tailwind.config.ts\n```\n\n---\n\n### 🔍 この構成で得られるメリット\n\n- **完全なバックエンドレス構成**で動作\n- 記事を保存した瞬間に自動更新される**快適な開発体験**\n- GitHub連携により、**記事の変更がそのまま履歴管理**になる\n- **Vercelの自動デプロイ**によって常に最新状態を公開\n- **Markdownベースの柔軟な拡張性**（Zenn風・ポートフォリオ化などにも応用可能）\n\n---\n\n次章では、`gray-matter` と `react-markdown` を使って\nMarkdownファイルをHTMLとしてレンダリングし、\n「ファイルを追加するだけで記事ページが生成される」仕組みを実装していきます。\n\n---\n\n## ⚙️ 3. プロジェクトのセットアップ\n\nここからは、実際に **Next.js + TypeScript + Tailwind CSS** を使って\nブログを動かすための開発環境を構築していきます。\n\n---\n\n### 🧩 3.1 プロジェクトの作成\n\nまずは、Next.jsのプロジェクトを作成します。\n今回は TypeScript を前提にした構成です。\n\n```bash\n# Next.jsの新規プロジェクトを作成\nnpx create-next-app@latest techblog --typescript\n```\n\nセットアップ時の選択肢は次のように回答します：\n\n| 質問                                                  | 推奨回答         |\n| ----------------------------------------------------- | ---------------- |\n| Would you like to use ESLint?                         | ✅ Yes           |\n| Would you like to use Tailwind CSS?                   | ✅ Yes           |\n| Would you like to use src/ directory?                 | 任意（好みでOK） |\n| Use App Router (recommended)?                         | ✅ Yes           |\n| Would you like to customize the default import alias? | ✅ Yes → `@/*`   |\n\n---\n\n### 🧱 3.2 ディレクトリ構成を整理\n\n作成後の構成をベースに、後で使用するフォルダを追加します。\n\n```bash\ncd techblog\nmkdir -p content scripts features lib\n```\n\n最終的に以下のような構成を目指します👇\n\n```bash\ntechblog/\n├── app/                     # Next.js App Router構成\n│   ├── layout.tsx\n│   └── page.tsx\n├── content/                 # Markdown記事を格納\n│   └── sample.md\n├── features/                # 検索などの機能モジュール\n├── lib/                     # 共通関数・設定\n├── public/                  # 画像・検索indexなど\n├── scripts/                 # ビルド時スクリプト\n├── tailwind.config.ts\n└── tsconfig.json\n```\n\n---\n\n### 💅 3.3 Tailwind CSS 設定\n\nTailwindは `create-next-app` で自動設定されますが、\nテーマ拡張を少し調整しておくと便利です。\n`tailwind.config.ts` を次のように編集します：\n\n```ts\nimport type { Config } from \"tailwindcss\";\n\nconst config: Config = {\n  darkMode: [\"class\"],\n  content: [\n    \"./app/**/*.{ts,tsx}\",\n    \"./components/**/*.{ts,tsx}\",\n    \"./features/**/*.{ts,tsx}\",\n    \"./content/**/*.{md,mdx}\",\n  ],\n  theme: {\n    extend: {\n      colors: {\n        background: \"hsl(var(--background))\",\n        foreground: \"hsl(var(--foreground))\",\n      },\n    },\n  },\n  plugins: [],\n};\n\nexport default config;\n```\n\nこの設定により、Markdown由来のコンテンツにもTailwindが適用されます。\n（後で `react-markdown` で記事をHTML化するために必要です）\n\n---\n\n### 🧰 3.4 開発時に便利なライブラリを追加\n\n```bash\nnpm install gray-matter react-markdown remark-gfm rehype-highlight rehype-raw fuse.js\nnpm install --save-dev eslint-plugin-simple-import-sort prettier-plugin-tailwindcss\n```\n\n| パッケージ                      | 役割                                           |\n| ------------------------------- | ---------------------------------------------- |\n| **gray-matter**                 | MarkdownのFrontmatter（title, tagsなど）を解析 |\n| **react-markdown**              | MarkdownをReactコンポーネントに変換            |\n| **remark-gfm**                  | GFM（表・チェックリストなど）対応              |\n| **rehype-highlight**            | コードブロックのシンタックスハイライト         |\n| **rehype-raw**                  | HTMLタグを安全に解釈                           |\n| **fuse.js**                     | フロントエンド検索用ライブラリ                 |\n| **prettier-plugin-tailwindcss** | Tailwindクラスの自動整列                       |\n\n---\n\n### 🧪 3.5 ESLintとPrettierの統合\n\nコード品質と整形ルールを統一して、保守性を高めます。\n`.eslintrc.json` の例は以下の通りです。\n\n```json\n{\n  \"extends\": [\n    \"next/core-web-vitals\",\n    \"eslint:recommended\",\n    \"plugin:prettier/recommended\"\n  ],\n  \"plugins\": [\"simple-import-sort\"],\n  \"rules\": {\n    \"simple-import-sort/imports\": \"error\",\n    \"simple-import-sort/exports\": \"error\"\n  }\n}\n```\n\n---\n\n### 🧱 3.6 Markdownテスト用のサンプルを追加\n\n`content/hello-world.md` を作成：\n\n````md\n---\ntitle: \"Hello World\"\nsummary: \"初めてのMarkdown記事です\"\ntags: [\"Next.js\", \"Markdown\"]\n---\n\n# Hello World 👋\n\nこれはテックブログの最初の記事です。  \nコードブロックもOK。\n\n```ts\nconsole.log(\"Hello from Markdown!\");\n```\n````\n\n---\n\n### 🚀 3.7 開発サーバを起動\n\n依存関係をインストールしたら、開発サーバを起動します。\n\n```bash\nnpm install\nnpm run dev\n```\n\nブラウザで [http://localhost:3000](http://localhost:3000) にアクセスし、\nNext.jsの初期ページが表示されればOKです。\n\n---\n\n### 📈 3.8 セットアップの流れ（Mermaid）\n\n```mermaid\nflowchart TD\n    A[🧱 create-next-appで生成] --> B[⚙️ TypeScript + Tailwind構成]\n    B --> C[📝 content/ にMarkdown記事作成]\n    C --> D[🧩 gray-matterでFrontmatter解析]\n    D --> E[⚛️ react-markdownでレンダリング]\n    E --> F[🌐 localhost:3000でプレビュー]\n```\n\n---\n\n### 🎯 ここまでで得られること\n\n- 自分のブログを **完全にローカルで管理できる基盤** が整う\n- **デザイン（Tailwind）・記事構造（Markdown）・コード品質（ESLint）** が統一\n- 今後の章で実装する **検索機能・ホットリロード・自動デプロイ** に備えた構成が完成\n\n---\n\n次章では、`gray-matter` と `react-markdown` を使って\nMarkdownファイルをHTMLとしてレンダリングし、\n記事を追加するだけで自動的にページが生成される仕組みを実装していきます。\n\n---\n\n## 📝 4. Markdownコンテンツの構築\n\nここからは、実際に `content/` 配下の Markdown ファイルを読み込み、\n**記事一覧や記事ページを自動生成** する仕組みを実装していきます。\n\nさらに、開発中に記事を編集すると即時反映されるよう、\n**ホットリロード対応** の仕組みも組み込みます。\n\n---\n\n### 🧩 4.1 Markdownの読み込み\n\nまずは、Markdownを読み取って記事データに変換する関数を作ります。\n`gray-matter` を使って Frontmatter（タイトル・タグなど）を解析します。\n\n`lib/articles.ts`：\n\n```ts\nimport fs from \"fs\";\nimport path from \"path\";\nimport matter from \"gray-matter\";\n\nconst CONTENT_DIR = path.join(process.cwd(), \"content\");\n\n/**\n * 記事一覧を取得\n */\nexport function getAllArticles() {\n  const files = fs.readdirSync(CONTENT_DIR);\n\n  return files\n    .filter((file) => file.endsWith(\".md\"))\n    .map((file) => {\n      const filePath = path.join(CONTENT_DIR, file);\n      const content = fs.readFileSync(filePath, \"utf-8\");\n      const { data, content: body } = matter(content);\n\n      return {\n        slug: file.replace(/\\.md$/, \"\"),\n        title: data.title || \"Untitled\",\n        summary: data.summary || \"\",\n        tags: data.tags || [],\n        date: data.date || \"\",\n        content: body,\n      };\n    });\n}\n\n/**\n * 特定記事を取得\n */\nexport function getArticleBySlug(slug: string) {\n  const filePath = path.join(CONTENT_DIR, `${slug}.md`);\n  const content = fs.readFileSync(filePath, \"utf-8\");\n  const { data, content: body } = matter(content);\n\n  return {\n    slug,\n    title: data.title || \"Untitled\",\n    summary: data.summary || \"\",\n    tags: data.tags || [],\n    date: data.date || \"\",\n    content: body,\n  };\n}\n```\n\n---\n\n### ⚛️ 4.2 MarkdownをHTMLに変換して表示\n\n次に、`react-markdown` を使ってHTMLとしてレンダリングします。\nコードブロックのハイライトも `rehype-highlight` で対応します。\n\n`app/articles/[slug]/page.tsx`：\n\n```tsx\nimport { getArticleBySlug, getAllArticles } from \"@/lib/articles\";\nimport ReactMarkdown from \"react-markdown\";\nimport rehypeHighlight from \"rehype-highlight\";\nimport remarkGfm from \"remark-gfm\";\n\ntype Props = {\n  params: { slug: string };\n};\n\nexport async function generateStaticParams() {\n  const articles = getAllArticles();\n  return articles.map((article) => ({ slug: article.slug }));\n}\n\nexport default function ArticlePage({ params }: Props) {\n  const article = getArticleBySlug(params.slug);\n\n  return (\n    <article className=\"prose dark:prose-invert mx-auto p-8\">\n      <h1>{article.title}</h1>\n      <p className=\"text-sm text-gray-500\">{article.summary}</p>\n\n      <ReactMarkdown\n        remarkPlugins={[remarkGfm]}\n        rehypePlugins={[rehypeHighlight]}\n      >\n        {article.content}\n      </ReactMarkdown>\n    </article>\n  );\n}\n```\n\nこれで `content/hello-world.md` が\n自動的に `/articles/hello-world` として表示されるようになります。\n\n---\n\n### 🗂️ 4.3 記事一覧ページの生成\n\nトップページなどで一覧を表示したい場合は、\n同じく `getAllArticles()` を使って一覧を作ります。\n\n`app/page.tsx`：\n\n```tsx\nimport Link from \"next/link\";\nimport { getAllArticles } from \"@/lib/articles\";\n\nexport default function HomePage() {\n  const articles = getAllArticles();\n\n  return (\n    <main className=\"max-w-3xl mx-auto p-8\">\n      <h1 className=\"text-3xl font-bold mb-6\">📚 Articles</h1>\n\n      <ul className=\"space-y-6\">\n        {articles.map((article) => (\n          <li key={article.slug}>\n            <Link\n              href={`/articles/${article.slug}`}\n              className=\"block group hover:opacity-80 transition\"\n            >\n              <h2 className=\"text-xl font-semibold\">{article.title}</h2>\n              <p className=\"text-gray-500\">{article.summary}</p>\n              <div className=\"mt-1 flex gap-2\">\n                {article.tags.map((tag: string) => (\n                  <span\n                    key={tag}\n                    className=\"text-sm bg-gray-100 dark:bg-gray-800 rounded px-2 py-0.5\"\n                  >\n                    #{tag}\n                  </span>\n                ))}\n              </div>\n            </Link>\n          </li>\n        ))}\n      </ul>\n    </main>\n  );\n}\n```\n\n---\n\n### 🔄 4.4 ホットリロードの仕組み\n\n開発中にMarkdownを変更したとき、\n即座にNext.js側のプレビューへ反映させるために\n**`watch-search-index.ts`** というスクリプトを使います。\n\n`scripts/watch-search-index.ts`：\n\n```ts\nimport chokidar from \"chokidar\";\nimport fs from \"fs\";\nimport path from \"path\";\nimport matter from \"gray-matter\";\n\nconst contentDir = path.join(process.cwd(), \"content\");\nconst indexPath = path.join(process.cwd(), \"public\", \"search-index.json\");\n\nfunction generateSearchIndex() {\n  const files = fs.readdirSync(contentDir).filter((f) => f.endsWith(\".md\"));\n  const index = files.map((file) => {\n    const filePath = path.join(contentDir, file);\n    const raw = fs.readFileSync(filePath, \"utf-8\");\n    const { data, content } = matter(raw);\n    return {\n      slug: file.replace(/\\.md$/, \"\"),\n      title: data.title || \"\",\n      summary: data.summary || \"\",\n      tags: data.tags || [],\n      content,\n    };\n  });\n\n  fs.writeFileSync(indexPath, JSON.stringify(index, null, 2));\n  triggerRerender();\n}\n\nfunction triggerRerender() {\n  const refreshFile = path.join(process.cwd(), \"lib\", \"force-refresh.ts\");\n  fs.writeFileSync(\n    refreshFile,\n    `// refreshed at ${new Date().toISOString()}\\n`,\n  );\n  console.log(\"🔁 search-index regenerated & HMR triggered\");\n}\n\nchokidar\n  .watch(contentDir, { ignoreInitial: true })\n  .on(\"add\", generateSearchIndex)\n  .on(\"change\", generateSearchIndex)\n  .on(\"unlink\", generateSearchIndex);\n\nconsole.log(\"👀 Watching Markdown files...\");\ngenerateSearchIndex();\n```\n\nこのスクリプトを別ターミナルで起動しておくと、\nMarkdownの追加・変更がリアルタイムで反映されます👇\n\n```bash\nnpx tsx scripts/watch-search-index.ts\n```\n\n---\n\n### ⚙️ 4.5 自動起動の設定（package.json）\n\n`package.json` にスクリプトを追加して、\n開発時にNext.jsとウォッチャーを同時に起動できるようにします。\n\n```json\n{\n  \"scripts\": {\n    \"dev\": \"concurrently \\\"next dev\\\" \\\"npx tsx scripts/watch-search-index.ts\\\"\"\n  },\n  \"devDependencies\": {\n    \"concurrently\": \"^8.2.2\"\n  }\n}\n```\n\n```bash\nnpm install --save-dev concurrently\n```\n\nこれで、以下のコマンドを実行すればOKです。\n\n```bash\nnpm run dev\n```\n\n→ Next.jsサーバーとウォッチャーが並行で動作し、\nMarkdownを保存した瞬間にブラウザが自動更新されます。\n\n---\n\n### 📊 4.6 フロー全体のイメージ\n\n```mermaid\nflowchart TD\n    A[✍️ content/*.mdを編集] --> B[👀 watch-search-index.tsが変更検知]\n    B --> C[🧠 gray-matterで再解析]\n    C --> D[🗂️ search-index.jsonを再生成]\n    D --> E[⚡ force-refresh.ts更新でHMR発火]\n    E --> F[🖥️ ブラウザが自動更新]\n```\n\n---\n\n### 🎯 まとめ\n\n- `gray-matter` で Markdown のメタ情報を解析\n- `react-markdown` で記事をHTMLとして表示\n- `watch-search-index.ts` により、記事を保存した瞬間にUIへ反映\n- バックエンドなしで「編集 → 即反映」の開発体験を実現\n\n---\n\n## 🔍 5. 記事データのインデックス化\n\nここでは、Markdownで書かれた記事データを\n**検索しやすい形式（インデックス）に変換する処理**を実装します。\n\nNext.jsのビルド時に `content/` 以下のすべてのMarkdownを解析し、\n`public/search-index.json` にまとめて出力します。\nこのファイルは、後で実装する全文検索機能（Fuse.js）で使用します。\n\n---\n\n### 🧠 5.1 インデックス生成の目的\n\n- サイト上の記事を**即座に検索できるようにする**\n- クライアントサイドで検索を完結させ、**バックエンド不要**にする\n- Vercel上でも**静的ファイルとして配信可能**にする\n\nつまり、インデックスは「軽量な検索用データベース」として機能します。\n\n---\n\n### 🗂️ 5.2 スクリプトの作成\n\n次のスクリプトを `scripts/generate-search-index.ts` に追加します。\nこれは **ビルド時** や **watcher起動時** に自動実行される処理です。\n\n```ts\nimport fs from \"fs\";\nimport path from \"path\";\nimport matter from \"gray-matter\";\n\nconst CONTENT_DIR = path.join(process.cwd(), \"content\");\nconst OUTPUT_FILE = path.join(process.cwd(), \"public\", \"search-index.json\");\n\nfunction generateSearchIndex() {\n  const files = fs.readdirSync(CONTENT_DIR).filter((f) => f.endsWith(\".md\"));\n  const articles = files.map((file) => {\n    const filePath = path.join(CONTENT_DIR, file);\n    const raw = fs.readFileSync(filePath, \"utf-8\");\n    const { data, content } = matter(raw);\n\n    return {\n      slug: file.replace(/\\.md$/, \"\"),\n      title: data.title || \"Untitled\",\n      summary: data.summary || \"\",\n      tags: data.tags || [],\n      date: data.date || \"\",\n      content,\n    };\n  });\n\n  fs.writeFileSync(OUTPUT_FILE, JSON.stringify(articles, null, 2));\n  console.log(`✅ search-index.json generated (${articles.length} articles)`);\n}\n\ngenerateSearchIndex();\n```\n\n---\n\n### ⚙️ 5.3 npmスクリプトに追加\n\nこのスクリプトを簡単に実行できるよう、`package.json` に登録しておきます。\n\n```json\n{\n  \"scripts\": {\n    \"build:index\": \"npx tsx scripts/generate-search-index.ts\"\n  }\n}\n```\n\n実行例：\n\n```bash\nnpm run build:index\n```\n\n`public/search-index.json` が生成されれば成功です。\n\n---\n\n### 📦 5.4 生成されるデータの構造\n\n生成された `search-index.json` は次のような構造になります：\n\n```json\n[\n  {\n    \"slug\": \"hello-world\",\n    \"title\": \"Hello World\",\n    \"summary\": \"初めてのMarkdown記事です\",\n    \"tags\": [\"Next.js\", \"Markdown\"],\n    \"date\": \"2025-10-01\",\n    \"content\": \"# Hello World 👋 ...\"\n  }\n]\n```\n\nこのファイルを使えば、クライアント側で `title` や `tags`、`content` を対象に\nFuse.jsで柔軟な検索を実行できるようになります。\n\n---\n\n### 🧩 5.5 Next.jsとの連携（自動生成）\n\n`search-index.json` は、**開発時・ビルド時のどちらでも自動生成**できるようにします。\n\n`next.config.mjs` に以下を追加します：\n\n```js\n// next.config.mjs\nimport { execSync } from \"child_process\";\n\nconst config = {\n  webpack: (config) => {\n    // ビルド前にインデックスを生成\n    execSync(\"npm run build:index\", { stdio: \"inherit\" });\n    return config;\n  },\n};\n\nexport default config;\n```\n\nこれで `npm run build` を実行すると、\n自動的に `search-index.json` が作られ、\n常に最新の状態でビルドが行われるようになります。\n\n---\n\n### 📈 5.6 処理フローのイメージ\n\n```mermaid\nflowchart TD\n    A[📄 content/*.md] --> B[gray-matterで解析]\n    B --> C[🗂️ JSON化 → search-index.json生成]\n    C --> D[💾 public/ に保存]\n    D --> E[🔍 Fuse.jsで利用]\n```\n\n---\n\n### 💡 5.7 インデックス方式の設計意図\n\n| 項目               | 方針                       | 理由                                     |\n| ------------------ | -------------------------- | ---------------------------------------- |\n| **保存場所**       | `public/search-index.json` | クライアントサイドで直接取得できる       |\n| **更新タイミング** | ビルド時・watcher起動時    | ローカル開発と本番デプロイの両方をカバー |\n| **形式**           | フラットなJSON配列         | Fuse.jsが最適に処理できる構造            |\n| **依存関係**       | gray-matter                | MarkdownのFrontmatter解析が簡単で高速    |\n\n---\n\n### 🎯 インデックス化まとめ\n\n- `content/` 内のMarkdownを解析して **search-index.json** を自動生成\n- **バックエンド不要**で、検索用データベースをフロントに埋め込める\n- Next.jsビルド時にも自動生成されるため、**常に最新の状態を維持**\n\n---\n\n次章では、この `search-index.json` をクライアントサイドで読み込み、\n**Fuse.jsを用いた全文検索機能** を実装していきます。\n\n---\n\n## 📰 6. 記事ページと一覧ページの実装\n\nこれまでに構築した\n\n- Markdownの読み込み（`lib/articles.ts`）\n- 記事データのインデックス化（`search-index.json`）\n\nをもとに、**記事一覧ページ**と**記事詳細ページ**を実装していきます。\nこれで、ブログとしての基本的な閲覧機能が完成します。\n\n---\n\n### 🗂️ 6.1 記事一覧ページ\n\nトップページでは、`getAllArticles()` で取得した記事一覧を\nタイトル・概要・タグ付きで表示します。\n\n`app/page.tsx`：\n\n```tsx\nimport Link from \"next/link\";\nimport { getAllArticles } from \"@/lib/articles\";\n\nexport default function HomePage() {\n  const articles = getAllArticles();\n\n  return (\n    <main className=\"max-w-3xl mx-auto p-8\">\n      <h1 className=\"text-3xl font-bold mb-8\">📚 Articles</h1>\n\n      <ul className=\"space-y-6\">\n        {articles.map((article) => (\n          <li key={article.slug}>\n            <Link\n              href={`/articles/${article.slug}`}\n              className=\"block group hover:opacity-80 transition\"\n            >\n              <h2 className=\"text-xl font-semibold group-hover:underline\">\n                {article.title}\n              </h2>\n              {article.summary && (\n                <p className=\"text-gray-500 dark:text-gray-400 mt-1\">\n                  {article.summary}\n                </p>\n              )}\n              {article.tags?.length > 0 && (\n                <div className=\"mt-2 flex flex-wrap gap-2\">\n                  {article.tags.map((tag: string) => (\n                    <span\n                      key={tag}\n                      className=\"text-sm bg-gray-100 dark:bg-gray-800 text-gray-700 dark:text-gray-300 rounded px-2 py-0.5\"\n                    >\n                      #{tag}\n                    </span>\n                  ))}\n                </div>\n              )}\n            </Link>\n          </li>\n        ))}\n      </ul>\n    </main>\n  );\n}\n```\n\nこのページでは、`/content` 配下のMarkdownファイルが\n自動的に記事一覧として表示されます。\n\n---\n\n### 📄 6.2 記事ページ\n\n個別記事ページでは、`slug`（ファイル名）をもとに\nMarkdownを読み込み、`react-markdown` でHTMLとして描画します。\n\n`app/articles/[slug]/page.tsx`：\n\n```tsx\nimport { getAllArticles, getArticleBySlug } from \"@/lib/articles\";\nimport ReactMarkdown from \"react-markdown\";\nimport rehypeHighlight from \"rehype-highlight\";\nimport remarkGfm from \"remark-gfm\";\n\ntype Props = {\n  params: { slug: string };\n};\n\nexport async function generateStaticParams() {\n  const articles = getAllArticles();\n  return articles.map((article) => ({ slug: article.slug }));\n}\n\nexport default function ArticlePage({ params }: Props) {\n  const article = getArticleBySlug(params.slug);\n\n  return (\n    <article className=\"prose dark:prose-invert mx-auto p-8\">\n      <h1>{article.title}</h1>\n      {article.date && (\n        <p className=\"text-sm text-gray-500 mb-4\">{article.date}</p>\n      )}\n\n      <ReactMarkdown\n        remarkPlugins={[remarkGfm]}\n        rehypePlugins={[rehypeHighlight]}\n      >\n        {article.content}\n      </ReactMarkdown>\n\n      {article.tags?.length > 0 && (\n        <div className=\"mt-6 flex flex-wrap gap-2\">\n          {article.tags.map((tag: string) => (\n            <span\n              key={tag}\n              className=\"text-sm bg-gray-100 dark:bg-gray-800 text-gray-700 dark:text-gray-300 rounded px-2 py-0.5\"\n            >\n              #{tag}\n            </span>\n          ))}\n        </div>\n      )}\n    </article>\n  );\n}\n```\n\nポイント：\n\n- **`generateStaticParams()`** により、記事をSSG（静的生成）\n- **`rehype-highlight`** でコードブロックのハイライト対応\n- **`remark-gfm`** で表やリスト、リンクなどの拡張Markdown構文を有効化\n\n---\n\n### 🧱 6.3 レイアウト構成の統一\n\n共通レイアウトを `app/layout.tsx` に設定しておくと、\nどのページでもヘッダーやテーマが統一されます。\n\n`app/layout.tsx`：\n\n```tsx\nimport \"./globals.css\";\nimport { Inter } from \"next/font/google\";\n\nconst inter = Inter({ subsets: [\"latin\"] });\n\nexport const metadata = {\n  title: \"techblog\",\n  description: \"個人の技術ブログサイト\",\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"ja\" className=\"dark\">\n      <body className={`${inter.className} bg-background text-foreground`}>\n        <header className=\"p-4 border-b border-gray-200 dark:border-gray-700\">\n          <h1 className=\"text-2xl font-semibold\">techblog</h1>\n        </header>\n        <main>{children}</main>\n      </body>\n    </html>\n  );\n}\n```\n\nこのように、**シンプルで軽量なUI** にしておくと、\n後で `shadcn/ui` などを導入しても拡張しやすくなります。\n\n---\n\n### 🌐 6.4 ページのルーティング構造\n\nNext.jsのApp Routerでは、\nフォルダ構成そのものがルーティングとして機能します。\n\n```bash\napp/\n├── page.tsx               # 一覧ページ（/）\n└── articles/\n    └── [slug]/\n        └── page.tsx       # 記事ページ（/articles/[slug]）\n```\n\nつまり、`content/hello-world.md` は\n自動的に `/articles/hello-world` として表示されます。\n\n---\n\n### 📈 6.5 フロー図（Mermaid）\n\n```mermaid\nflowchart TD\n    a[\"📄 content/*.md\"] --> b[\"🧠 getAllArticles() で一覧生成\"]\n    a --> c[\"📚 getArticleBySlug() で個別取得\"]\n    b --> d[\"🏠 /page.tsx → 一覧ページ\"]\n    c --> e[\"📰 /articles/[slug]/page.tsx → 記事ページ\"]\n    d --> f[\"🌐 Next.js SSGビルド\"]\n    e --> f\n```\n\n---\n\n### 🎯 ページ作成まとめ\n\n- 記事一覧と詳細ページのルーティングをApp Routerで自動生成\n- Markdownを `gray-matter` + `react-markdown` でHTML化\n- コードハイライト・タグ表示・日付などのメタ情報も表示可能\n- SSG（静的生成）により、高速かつSEOに強いブログ構成が完成\n\n---\n\n## 🎨 7. UIデザインとテーマ\n\nこの章では、**Tailwind CSS** と **shadcn/ui** を用いた\nUIデザインの構築とテーマ（ライト／ダークモード対応）を実装します。\n\n---\n\n### 🌈 7.1 デザイン方針\n\n本ブログは「**読みやすく・整っていて・壊れにくいUI**」を重視しています。\n特に次の3点を設計の柱としました。\n\n1. **余白と文字サイズの統一** — Tailwindのユーティリティで全体のバランスを揃える\n2. **コンポーネント分離** — 記事カード・タグ・ボタンなどを再利用可能に\n3. **ダークモード対応** — `class` ベースの切り替えで統一感を維持\n\n---\n\n### 💅 7.2 Tailwind CSS のテーマ拡張\n\n`tailwind.config.ts` にテーマ変数を定義しておくと、\nデザイン変更やテーマ切り替えがスムーズになります。\n\n```ts\nimport type { Config } from \"tailwindcss\";\n\nconst config: Config = {\n  darkMode: [\"class\"],\n  theme: {\n    extend: {\n      colors: {\n        background: \"hsl(var(--background))\",\n        foreground: \"hsl(var(--foreground))\",\n        primary: \"hsl(var(--primary))\",\n        secondary: \"hsl(var(--secondary))\",\n        muted: \"hsl(var(--muted))\",\n      },\n      fontFamily: {\n        sans: [\"Inter\", \"system-ui\", \"sans-serif\"],\n      },\n    },\n  },\n  plugins: [],\n};\n\nexport default config;\n```\n\n---\n\n### 🧩 7.3 shadcn/ui の導入\n\nTailwindベースのUIコンポーネント集である [**shadcn/ui**](https://ui.shadcn.com/) を導入します。\nこれにより、ボタンやカードなどを高品質なデザインで統一できます。\n\n```bash\nnpx shadcn-ui@latest init\nnpx shadcn-ui@latest add button card badge input\n```\n\n追加したコンポーネントは `/components/ui/` に配置されます。\n例として `Button` コンポーネントを活用したシンプルな例👇\n\n```tsx\nimport { Button } from \"@/components/ui/button\";\n\nexport default function Example() {\n  return (\n    <div className=\"p-6\">\n      <Button variant=\"default\">記事を読む</Button>\n    </div>\n  );\n}\n```\n\n---\n\n### 🌙 7.4 ダークモード対応\n\n`class` ベースのテーマ切り替えを採用します。\n`next-themes` を導入して、ライト／ダークの状態を管理しましょう。\n\n```bash\nnpm install next-themes\n```\n\n`app/providers.tsx` に設定を追加：\n\n```tsx\n\"use client\";\nimport { ThemeProvider } from \"next-themes\";\n\nexport function Providers({ children }: { children: React.ReactNode }) {\n  return (\n    <ThemeProvider attribute=\"class\" defaultTheme=\"system\" enableSystem>\n      {children}\n    </ThemeProvider>\n  );\n}\n```\n\nそして `app/layout.tsx` でラップします👇\n\n```tsx\nimport \"./globals.css\";\nimport { Providers } from \"./providers\";\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"ja\" suppressHydrationWarning>\n      <body className=\"bg-background text-foreground transition-colors\">\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}\n```\n\nこれで、OSテーマに合わせて自動で切り替わるようになります。\n任意で、ナビゲーションバーに「テーマトグルボタン」を追加すると便利です。\n\n---\n\n### 🧠 7.5 記事レイアウトのデザイン例\n\nMarkdown記事を`react-markdown`でレンダリングするとき、\n要素ごとにTailwindクラスを指定してスタイルを統一できます。\n\n```tsx\nimport ReactMarkdown from \"react-markdown\";\n\nexport default function ArticleContent({ content }: { content: string }) {\n  return (\n    <article className=\"prose dark:prose-invert max-w-none\">\n      <ReactMarkdown>{content}</ReactMarkdown>\n    </article>\n  );\n}\n```\n\n`@tailwindcss/typography` プラグインを利用すれば、\n見出しやリンクのデフォルトスタイルも整います👇\n\n```bash\nnpm install @tailwindcss/typography\n```\n\n`tailwind.config.ts` に追加：\n\n```ts\nplugins: [require(\"@tailwindcss/typography\")],\n```\n\n---\n\n### 🧭 7.6 UI設計の全体像\n\n```mermaid\nflowchart TD\n    A[\"🧩 shadcn/ui コンポーネント\"] --> B[\"🎨 Tailwindテーマ変数\"]\n    B --> C[\"🌗 next-themes によるダークモード制御\"]\n    C --> D[\"📰 Markdown記事のスタイル統一\"]\n    D --> E[\"✨ 一貫したUXとデザイン再利用\"]\n```\n\n---\n\n### 🪶 7.7 まとめ\n\n- **Tailwind + shadcn/ui** でデザイン基盤を確立\n- **next-themes** によりダークモードを自然に実装\n- **@tailwindcss/typography** でMarkdownを美しく整形\n\nここまでで、ブログ全体の見た目とテーマが完成しました。\n次章では、**Fuse.jsを使った検索機能**を追加していきます。\n\n---\n\n## 🚀 8. サイトの公開\n\nここまでで、Markdown記事をもとに動作する技術ブログが完成しました。\n最後に、**Vercelを使ってインターネット上に公開**しましょう。\n\nVercelはNext.js開発元が提供するホスティングサービスで、\nGitHubと連携するだけで **ビルド → デプロイ → 公開** がすべて自動化されます。\n\n---\n\n### 🌐 8.1 GitHub へのプッシュ\n\nまず、作成したブログをGitHubにアップロードします。\n\n```bash\n# Gitリポジトリを初期化\ngit init\ngit add .\ngit commit -m \"Initial commit: techblog\"\n\n# GitHubのリポジトリを作成（例）\ngh repo create techblog --public --source=. --remote=origin\n\n# プッシュ\ngit push -u origin main\n```\n\nこれでGitHub上にコードがアップされました。\nVercelはこのリポジトリを監視して、自動的に更新を反映してくれます。\n\n---\n\n### ☁️ 8.2 Vercel にデプロイ\n\n[Vercel Dashboard](https://vercel.com/) にアクセスし、\nGitHubアカウントでログインします。\n\n1. 「**New Project**」をクリック\n2. 「**Import Git Repository**」で `techblog` を選択\n3. Framework は自動で **Next.js** が検出されます\n4. Build Command を次のように変更👇\n\n   ```bash\n   npm run postbuild && npm run build\n   ```\n\n5. Output Directory は自動設定（`/.next`）\n6. Deploy ボタンをクリック\n\n数分後、`https://techblog.vercel.app` のようなURLで公開されます 🎉\n\n---\n\n### 🔄 8.3 自動デプロイ（CI/CD）\n\nVercelは、**GitHubのmainブランチにpushされるたび**に以下を自動実行します。\n\n1. `npm install`\n2. `npm run postbuild`（記事インデックス・サイトマップ生成）\n3. `npm run build`（Next.js静的ビルド）\n4. デプロイ＆公開\n\nつまり、Markdownを追加してcommit → pushするだけで、\nサイトが自動的に更新されます。\n\n```bash\n# 記事追加例\necho \"---\\ntitle: '新しい記事'\\n---\\n本文...\" > content/new-post.md\ngit add .\ngit commit -m \"Add new post\"\ngit push origin main\n```\n\n数十秒後にはVercelが自動で再ビルドし、新しい記事が公開されます。\n\n---\n\n### ⚡ 8.4 ホットリロードとローカル開発\n\nローカルでは次のコマンドで開発できます。\n\n```bash\nnpm run dev\n```\n\nこのスクリプトでは、`next dev` と同時に\n`scripts/watch-search-index.ts` が実行され、\n**Markdownの変更を監視しながら `search-index.json` を自動更新**します。\n\nこれにより、記事の追加・編集が即座に反映され、\n開発中のホットリロード体験が格段に快適になります。\n\n> 🔍 `watch-search-index.ts` は `fs.watch` で `content/` ディレクトリを監視し、\n> 記事変更時に `generate-search-index.ts` を再実行しています。\n> → ローカルでは即時反映、本番では `postbuild` で再生成。\n\n---\n\n### 🧱 8.5 package.json のスクリプト設定\n\n最終的な `package.json` のスクリプト定義は以下の通りです：\n\n```json\n{\n  \"scripts\": {\n    \"dev\": \"npx concurrently -k -n \\\"next,watch\\\" -c \\\"cyan,magenta\\\" \\\"next dev\\\" \\\"npx tsx scripts/watch-search-index.ts\\\"\",\n    \"build\": \"next build\",\n    \"start\": \"next start\",\n    \"lint\": \"next lint\",\n    \"generate:search\": \"tsx scripts/generate-search-index.ts\",\n    \"generate:sitemap\": \"tsx scripts/generate-sitemap.ts\",\n    \"postbuild\": \"npm run generate:search && npm run generate:sitemap\"\n  }\n}\n```\n\n| スクリプト           | 説明                                           |\n| -------------------- | ---------------------------------------------- |\n| **dev**              | Next.jsサーバー＋記事ウォッチャーを同時起動    |\n| **postbuild**        | ビルド前に検索インデックスとサイトマップを生成 |\n| **generate:search**  | `search-index.json` を生成（Fuse.js用）        |\n| **generate:sitemap** | 検索エンジン向けの `sitemap.xml` を生成        |\n| **build**            | Next.js本体をビルド（SSG）                     |\n\n---\n\n### 📊 8.6 デプロイの流れまとめ\n\n```mermaid\nflowchart TD\n    A[\"📝 Markdown追加<br/>git commit & push\"] --> B[\"☁️ GitHubに反映\"]\n    B --> C[\"⚙️ Vercelが自動ビルド開始\"]\n    C --> D[\"🧠 npm run postbuild<br/>(検索・サイトマップ生成)\"]\n    D --> E[\"🏗️ npm run build<br/>(Next.jsビルド)\"]\n    E --> F[\"🌍 公開サイトが更新\"]\n```\n\n---\n\n### ✅ 8.7 公開後の運用ポイント\n\n- Markdownを追加 → push で即反映\n- ローカルでは `npm run dev` でホットリロード付き開発\n- `postbuild` によって、記事一覧とsitemapが常に最新に保たれる\n\n---\n\n### 🪶 まとめ\n\n- GitHubとVercel連携で**完全自動デプロイ**\n- `postbuild` により**ビルド時に記事データを自動生成**\n- ローカルでは `watch-search-index.ts` による**リアルタイム更新**\n\nこれで、「書く → push → 公開」の理想的なワークフローが完成しました 🚀\n\n---\n\n## 🔍 9. 検索とSEO対策\n\nこの章では、**ユーザーが目的の記事を探しやすくし、検索エンジンにも最適化されたブログ**に仕上げるための仕組みを整えます。\n\nここまでで `search-index.json` や `generate-sitemap.ts` はすでに登場していますが、\nそれらをSEO・検索体験の観点からまとめて最適化していきます。\n\n---\n\n### 🔡 9.1 検索機能の改善 (Fuse.js)\n\n検索機能は、`Fuse.js` を使った**クライアントサイド全文検索**で実装されています。\nブラウザ上で `search-index.json` を読み込み、\nユーザーが検索ボックスに入力したキーワードに応じて即座に絞り込みを行います。\n\n```ts\nimport Fuse from \"fuse.js\";\n\nconst fuse = new Fuse(articles, {\n  keys: [\"title\", \"summary\", \"tags\", \"content\"],\n  threshold: 0.3,\n});\n\nexport const searchArticles = (query: string) => {\n  return query ? fuse.search(query).map((res) => res.item) : articles;\n};\n```\n\n#### 🧠 Fuse.jsの特徴\n\n- サーバー不要で軽量（CDN対応も可能）\n- タイトル・タグ・本文など複数フィールドを横断検索\n- `threshold` で曖昧検索の度合いを調整できる\n  → 例：0.3 なら「Next」でも「Next.js」にマッチ\n\n#### 🚀 運用フロー\n\n1. 開発中は `watch-search-index.ts` によりホットリロード対応\n2. 本番では `postbuild` により `search-index.json` を再生成\n3. フロントエンドで `Fuse.js` が検索結果を即時反映\n\n---\n\n### 🌐 9.2 サイトマップ生成 (`generate-sitemap.ts`)\n\n検索エンジン（Google, Bingなど）が記事を正しくクロールできるように、\n`scripts/generate-sitemap.ts` で自動生成するサイトマップを用意します。\n\n```ts\nimport fs from \"fs\";\nimport path from \"path\";\n\nconst BASE_URL = \"https://techblog.vercel.app\";\nconst contentDir = path.join(process.cwd(), \"content\");\n\nconst generateSitemap = () => {\n  const files = fs.readdirSync(contentDir);\n  const urls = files\n    .filter((file) => file.endsWith(\".md\"))\n    .map((file) => {\n      const slug = file.replace(/\\.md$/, \"\");\n      return `<url><loc>${BASE_URL}/articles/${slug}</loc></url>`;\n    });\n\n  const xml = `<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n  <urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n  ${urls.join(\"\\n\")}\n  </urlset>`;\n\n  fs.writeFileSync(\"public/sitemap.xml\", xml);\n  console.log(\"✅ sitemap.xml generated\");\n};\n\ngenerateSitemap();\n```\n\nこれにより、**デプロイ時に常に最新記事のURLを含むsitemap.xml**が生成されます。\nGoogle Search Console に登録すれば、SEO効果を最大化できます。\n\n---\n\n### 🪞 9.3 メタデータとOGP設定\n\nNext.js App Routerでは、`app/layout.tsx` や各ページで\n`metadata` オブジェクトを使ってメタ情報を定義できます。\n\n```ts\nexport const metadata = {\n  title: \"TechBlog – 技術ブログ\",\n  description: \"GitHub・Next.js・Vercel・Markdownで作る個人技術ブログ\",\n  openGraph: {\n    title: \"TechBlog\",\n    description: \"エンジニアのためのMarkdownベース技術ブログ\",\n    url: \"https://techblog.vercel.app\",\n    siteName: \"TechBlog\",\n    images: [\"/ogp.png\"],\n    locale: \"ja_JP\",\n    type: \"website\",\n  },\n};\n```\n\nこれにより：\n\n- Google 検索結果で適切なタイトルと説明文が表示される\n- SNS（X, Facebook, Discordなど）での共有時に**OGP画像と説明が自動表示**\n\n> 💡 画像は `/public/ogp.png` に配置。\n> 記事ごとに個別のOGP画像を生成したい場合は `next/og` API や `@vercel/og` を利用可能です。\n\n---\n\n### 🤖 9.4 robots.txt と Search Console\n\nSEO対策として、クロール設定を明示する `robots.txt` を `public/` に配置します。\n\n```txt\nUser-agent: *\nAllow: /\nSitemap: https://techblog.vercel.app/sitemap.xml\n```\n\nあわせて、Google Search Console に\n`https://techblog.vercel.app/sitemap.xml` を登録しておくと良いです。\nこれで記事のクロールが自動化され、検索反映も早まります。\n\n---\n\n### 📈 9.5 Analytics 連携（任意）\n\nアクセス解析を行いたい場合は、\n`Vercel Analytics` または `Google Analytics` を導入します。\n\n例：`next/script` を使った GA 設定\n\n```tsx\nimport Script from \"next/script\";\n\nexport default function Analytics() {\n  return (\n    <Script\n      async\n      src={`https://www.googletagmanager.com/gtag/js?id=${process.env.NEXT_PUBLIC_GA_ID}`}\n    />\n  );\n}\n```\n\n`.env` に以下を追加：\n\n```env\nNEXT_PUBLIC_GA_ID=G-XXXXXXX\n```\n\n---\n\n### 🧭 9.6 検索・SEO構成のまとめ\n\n```mermaid\nflowchart TD\n    A[\"🧩 Markdown 記事\"] --> B[\"🧠 search-index.json<br/>（Fuse.js 用）\"]\n    A --> C[\"🌍 sitemap.xml<br/>（SEO 用）\"]\n    B --> D[\"🔍 クライアント検索（Fuse.js）\"]\n    C --> E[\"🤖 Google 検索エンジン\"]\n    D --> F[\"👤 ユーザーが記事を探す\"]\n    E --> F\n```\n\n---\n\n### ✅ まとめ\n\n- `Fuse.js` による**即時検索**でUXを最適化\n- `generate-sitemap.ts` により**クロール精度を自動管理**\n- メタ情報・OGP・robots.txtで**SEOを強化**\n- `postbuild`で全データを自動生成する構成で**運用コストゼロ**\n\nこれで、**「人にも検索エンジンにも優しいブログ」**が完成です。\n\n---\n\n## 🧩 10. 今後の発展\n\nこのブログは、**「Markdownで記事を書く → push → 自動公開」**というシンプルな構成を重視しています。\nここからさらに発展させることで、より高度な知識共有プラットフォームへ進化させることができます。\n\n---\n\n### 🗂️ 10.1 CMSの導入（Contentlayer / Notion / microCMS）\n\nMarkdown運用は軽量で便利ですが、記事数が増えると管理が煩雑になります。\n将来的には**CMS（Content Management System）**を導入して、\n記事データを外部から管理することも可能です。\n\n| 手法             | 特徴                                                |\n| ---------------- | --------------------------------------------------- |\n| **Contentlayer** | Markdownを型安全に扱える。Next.jsと統合性が高い。   |\n| **Notion API**   | NotionをそのままCMS化。執筆体験が快適。             |\n| **microCMS**     | 日本語対応のヘッドレスCMS。非エンジニアも編集可能。 |\n\nこれらを使えば、**非開発者でも記事を追加・編集**できるようになります。\n\n---\n\n### 💬 10.2 コメント機能やリアクションの追加\n\n読者との交流を生むために、以下のような仕組みを追加できます。\n\n- **Giscus**（GitHub Discussionsを利用したコメント）\n- **Utterances**（GitHub Issues連携）\n- **自作API＋Supabase** で軽量コメント機能を構築\n\nこれにより、ブログが一方通行ではなく**コミュニティ的な場**へ発展します。\n\n---\n\n### 📰 10.3 RSSフィード・メール購読\n\n新着記事を自動配信したい場合は、RSSやニュースレター機能を追加します。\n\n- `scripts/generate-rss.ts` で `rss.xml` を生成\n- Vercel Cron で定期更新\n- `buttondown.email` や `ConvertKit` を使ってメール購読を提供\n\nこれにより、**読者が定期的に最新記事を受け取れる仕組み**を作れます。\n\n---\n\n### 📊 10.4 アクセス解析・人気記事ランキング\n\n人気記事を分析したい場合は、以下の方法が有効です。\n\n| 手法                                   | 説明                           |\n| -------------------------------------- | ------------------------------ |\n| **Vercel Analytics**                   | 設定不要でPVを簡易解析         |\n| **Google Analytics 4**                 | 詳細な流入経路・行動分析が可能 |\n| **自作カウンター（Supabase / Redis）** | ページ別PVをリアルタイム集計   |\n\nランキングページや「よく読まれている記事」セクションを自動生成するのもおすすめです。\n\n---\n\n### 🎨 10.5 デザインリニューアル・UX強化\n\nUI/UXの面では、次のような改良も可能です。\n\n- **`shadcn/ui`** によるモダンで統一感のあるコンポーネント設計\n- **Framer Motion** を使ったトランジションやアニメーション追加\n- **テーマ拡張（フォント・カラー・レイアウト）**\n- **記事内目次（Table of Contents）** の自動生成\n\n> デザイン刷新を通して、**「読まれる」ブログから「使われる」メディアへ**進化できます。\n\n---\n\n### 🧱 10.6 ビルド高速化とパフォーマンス最適化\n\n記事数が増えるとSSGビルドに時間がかかるため、\n以下の最適化を検討します。\n\n- **`next/cache`** や **ISR (Incremental Static Regeneration)** の活用\n- **分割ビルド（部分再生成）** の導入\n- **画像最適化（next/image + CDN）**\n- **preload / prefetch戦略** の見直し\n\nこれにより、大規模化してもスケーラブルに運用できます。\n\n---\n\n### 🧠 10.7 AI要約・推薦機能\n\n今後は、**生成AIを活用して記事をより賢く届ける**ことも可能です。\n\n- LLMを使った **「この記事の要約」** 機能\n- 類似記事を自動提案する **レコメンドエンジン**\n- ChatGPT APIやLangChainを用いた **知識ベース化**\n\n> Markdown記事をベクトルDBに埋め込み、\n> 「過去の記事から関連テーマを探すAIナビゲーション」も実現できます。\n\n---\n\n### 🚀 10.8 今後の展望まとめ\n\n```mermaid\nflowchart TD\n    A[\"📝 現状: Markdownベース技術ブログ\"] --> B[\"🗂️ CMS統合（Contentlayer, Notion, microCMS）\"]\n    A --> C[\"💬 コメント・RSS・解析機能の追加\"]\n    A --> D[\"🎨 UI刷新 & アニメーション\"]\n    B --> E[\"🧠 AI要約・レコメンド機能\"]\n    C --> E\n    D --> E\n    E --> F[\"🌍 完成: 拡張型パーソナルナレッジブログ\"]\n```\n\n---\n\n### ✅ 10.9 まとめ\n\n- 現在の構成（Markdown × Next.js × Vercel）は**最小構成として理想的**\n- 将来的にCMS・AI・解析を組み合わせることで**継続的な進化が可能**\n- コードも記事もGitで管理できるため、**拡張性・透明性・再現性が高い**\n\nこのプロジェクトは、**「学びのストックを形に残すためのベース」**として、\nそのままプロダクト開発・ナレッジプラットフォームへ発展させることもできます。\n\n---\n\n## 🧭 11. まとめ\n\nここまでで、**GitHub・Next.js・Vercel・Markdown** を組み合わせた\n開発者向けの技術ブログの構築手順を一通り解説してきました。\n\nこの仕組みの最大の特徴は、\n**「コードと記事を同じGitで管理し、pushだけで公開できる」** という点にあります。\n\n---\n\n### ✅ 今回作ったブログの特徴\n\n| 項目            | 内容                                                           |\n| --------------- | -------------------------------------------------------------- |\n| 🧩 **技術構成** | Next.js（App Router） + Tailwind CSS + TypeScript              |\n| 📝 **記事管理** | Markdown + gray-matter でメタ情報を扱う                        |\n| 🔍 **検索機能** | Fuse.js によるクライアントサイド全文検索                       |\n| 🧠 **自動生成** | `postbuild` で `search-index.json` と `sitemap.xml` を自動生成 |\n| 🚀 **デプロイ** | GitHub → Vercel で push 即デプロイ（CI/CD構成）                |\n| 🎨 **UI設計**   | Tailwind + shadcn/ui + next-themes でダークモード対応          |\n\nこのように、**バックエンドレスで完結する静的ブログ**ながら、\n更新性・拡張性・パフォーマンスをすべて両立できています。\n\n---\n\n### 💡 この構成の魅力\n\n- Markdownなので、**VSCodeやNeovimでそのまま執筆可能**\n- 記事の更新＝Git commitで履歴が残る\n- `Fuse.js` 検索・`sitemap.xml`・`metadata` でSEO対策も万全\n- チームでも個人でも、**再現性の高いワークフロー**を維持できる\n\n> CMSを使わず、**エンジニアらしいブログ運営を極めたい人**に最適な構成です。\n\n---\n\n### 🚀 今後の展開\n\n本記事で紹介した構成は、\n個人ブログだけでなく**チームのナレッジ共有サイト**にも応用できます。\n\n- `Notion API` や `Contentlayer` でCMS化\n- `Supabase` や `Giscus` でコメント機能を追加\n- `@vercel/og` で記事ごとのOGP画像を自動生成\n- AI要約・レコメンド機能を組み込む\n\n→ こうした発展もすべて、**この基盤の上に積み上げるだけ**で実現可能です。\n\n---\n\n### ✍️ 最後に\n\nエンジニアにとって「書くこと」は、\n知識の整理であり、学びの再利用です。\n\n**GitHubで管理し、Next.jsで表示し、Vercelで届ける。**\nそれだけで、あなたの学びは「資産」に変わります。\n\nぜひ、この記事をきっかけに\n**自分だけの技術ブログ**を作り、知識を積み上げていきましょう。\n\n---\n\n📦 ソースコード構成例やビルドスクリプトの詳細は、\n本文の各章（特に 5章〜8章）を参考にしてください。\n\nあなたの手で構築したブログが、\n「学びを発信する最高のアウトプット環境」になるはずです。 🚀\n",
    "createdAt": "2025-10-04T15:53:36.991Z",
    "updatedAt": "2025-10-04T15:53:36.991Z"
  },
  {
    "title": "Go × Next.js × OpenAPIでAPIクライアントを自動生成する",
    "summary": "Swagger → OpenAPI → Orval → React Query までを自動化し、バックエンドの更新が即フロントに反映される仕組みを構築する。Docker Composeで開発・本番環境を完全分離した構成も紹介。",
    "tags": [
      "Go",
      "Next.js",
      "OpenAPI",
      "Docker",
      "TypeScript"
    ],
    "slug": "Next.js/api-client-automation",
    "folder": "Next.js",
    "content": "\n## はじめに\n\n最近のWebアプリ開発では、**バックエンドとフロントエンドを分離した構成（SPA + API）**が一般的になっています。\n特に **Go（Fiberなど）でREST APIを構築し、Next.jsでフロントエンドを実装する**ケースは多いでしょう。\n\nしかし、この構成でよく直面するのが\n\n> 「API仕様を変更したら、フロント側の型も全部直すのが面倒」\n> 「エンドポイントの名前やレスポンス構造がずれてバグる」\n\nといった、**API仕様のズレによる開発コスト**です。\n\n---\n\n### 本記事の目的\n\nこの記事では、Goで構築したAPIサーバーから **Swagger（OpenAPI）定義を自動生成し、Next.js側でその定義をもとに型付きAPIクライアントを自動生成する**仕組みを構築します。\n\nこれにより\n\n- **バックエンドの更新に追従してフロントが自動で更新される**\n- **通信層が完全に型安全になる**\n- **APIクライアントの記述が不要になる（React Query対応）**\n\nという、保守性と開発効率の高い開発環境を実現します。\n\n---\n\n### 使用する技術スタック\n\n| レイヤー     | 技術                  | 役割                                    |\n| ------------ | --------------------- | --------------------------------------- |\n| **Backend**  | Go (Fiber)            | REST APIサーバー                        |\n|              | swaggo/swag           | GoコードからSwagger(OpenAPI v2)生成     |\n|              | openapi-generator-cli | Swagger v2 → OpenAPI v3 変換            |\n| **Frontend** | Next.js (TypeScript)  | ReactベースのSPA                        |\n|              | Orval                 | OpenAPI v3から型付きAPIクライアント生成 |\n|              | Axios                 | API通信の実体クライアント               |\n|              | React Query           | データフェッチ・キャッシュ管理          |\n| **Infra**    | Docker / Makefile     | 環境構築・自動生成パイプライン          |\n\n---\n\n### 全体のフロー\n\n本記事で実装する自動化パイプラインは以下のように動作します：\n\n```mermaid\ngraph TD\n    A[\"Goソースコード＋Swagコメント\"]\n        -->|make gen-swagger-v2| B[\"swagger.yaml/json生成 (OAS2)\"]\n    B -->|make gen-openapi-v3| C[\"OpenAPI v3に変換\"]\n    C -->|make gen-client| D[\"Next.js用APIクライアント生成\"]\n    D --> E[\"Next.jsで型安全な useQuery / useMutation 呼び出し\"]\n```\n\nすべての生成処理は `Makefile` と `Docker` によって自動化されるため、\n開発者は **コマンド一発でAPIとフロントエンドの同期を保てる**ようになります。\n\n---\n\n### 完成イメージ\n\n最終的には、以下のような構成になります。\n\n```tree\nbackend/\n ├─ cmd/server/main.go\n ├─ internal/\n ├─ docs/\n │   ├─ swagger.yaml\n │   ├─ swagger.json\n │   └─ v3/\n │        ├─ openapi.yaml\n │        └─ openapi.json\nfrontend/\n ├─ src/api/__generated__/      ← orvalが生成\n ├─ src/api/customAxios.ts\n ├─ src/api/orval.config.ts\n ├─ package.json\nMakefile\n```\n\nこの仕組みを整えておけば、**API設計の変更が即座にNext.js側へ反映される**ため、\nAPIとフロントの仕様不整合を根本的に防ぐことができます。\n\n## 2. バックエンド（Go + Fiber）のSwagger生成\n\n本章では、GoのAPIサーバーに対して **Swaggerドキュメントを自動生成する仕組み** を構築します。\nSwagger（OpenAPI v2）はAPI仕様書のフォーマットであり、これを生成しておくことで後のクライアント自動生成に繋げられます。\n\n---\n\n### 2.1 Swaggoとは？\n\n[Swaggo](https://github.com/swaggo/swag) は、Goのソースコードに埋め込まれたコメントから自動的にSwagger（OpenAPI v2）仕様を生成するツールです。\n`swag init` コマンドを実行すると、指定したエントリーポイント（例：`cmd/server/main.go`）からコメントを解析し、`docs/` ディレクトリに `swagger.yaml` と `swagger.json` を出力します。\n\n---\n\n### 2.2 Swaggerコメントの書き方\n\nSwaggoは**関数コメントの形式**を解析します。\n以下は `handler/test_handler.go` に定義されたAPIの例です。\n\n```go\n// Create\n//\n// @Summary  Create a new test\n// @Description Creates a test record and returns it\n// @Tags   tests\n// @Produce  json\n// @Success  200 {object} TestResponse\n// @Failure  500 {object} map[string]string\n// @Router   /tests [post]\nfunc (h *TestHandler) Create(c *fiber.Ctx) error {\n test, err := h.uc.CreateTest(c.Context())\n if err != nil {\n  return c.Status(500).JSON(fiber.Map{\"error\": err.Error()})\n }\n return c.JSON(test)\n}\n```\n\n- `@Summary` … 短い概要\n- `@Description` … 詳細な説明\n- `@Tags` … APIをグループ化するタグ名\n- `@Produce` … レスポンス形式\n- `@Success`, `@Failure` … ステータスコードとレスポンス型\n- `@Router` … エンドポイントのパスとメソッド\n\nSwaggoはこれらのコメントを読み取って、自動的にエンドポイントを定義してくれます。\n\n---\n\n### 2.3 API全体のメタ情報\n\nSwaggerドキュメントのメタ情報（タイトル・バージョン・セキュリティなど）は、`main.go` に記述します。\n\n```go\n// @title      API\n// @version     1.0\n// @description    This is the API documentation for the application.\n// @host      localhost\n// @BasePath     /api\n// @schemes     http\n// @securityDefinitions.apikey ApiKeyAuth\n// @in       header\n// @name      Authorization\n```\n\nこれにより、生成される `swagger.yaml` に以下のようなトップレベル情報が自動挿入されます。\n\n```yaml\ninfo:\n  title: API\n  version: \"1.0\"\n  description: This is the API documentation for the application.\nhost: localhost\nbasePath: /api\nschemes:\n  - http\nsecurityDefinitions:\n  ApiKeyAuth:\n    type: apiKey\n    in: header\n    name: Authorization\n```\n\n---\n\n### 2.4 Swagコマンドの実行\n\n通常であればローカルに `swag` をインストールして以下のように実行します：\n\n```bash\ngo install github.com/swaggo/swag/cmd/swag@latest\nswag init -g cmd/server/main.go --parseDependency\n```\n\n- `-g`：エントリーポイント（`main.go`）を指定\n- `--parseDependency`：依存パッケージ（handlerなど）も含めて解析するオプション\n\nこれにより、`backend/docs` ディレクトリに以下のファイルが生成されます：\n\n```tree\nbackend/docs/\n ├─ docs.go\n ├─ swagger.json\n └─ swagger.yaml\n```\n\n---\n\n### 2.5 Docker + Makefileでの自動化\n\nローカル環境に `swag` を入れたくない場合は、Dockerでワンショット実行できます。\n以下のMakefileタスクを使えば、どの環境でも同一コマンドで生成可能です。\n\n```makefile\n.PHONY: gen-swagger-v2\ngen-swagger-v2:\n @echo \"[OAS2] Generate swagger.yaml & swagger.json\"\n docker run --rm -v $(PWD)/backend:/app -w /app golang:1.25-alpine \\\n   sh -c \"go install github.com/swaggo/swag/cmd/swag@latest && \\\n   swag fmt && \\\n   swag init -g cmd/server/main.go --parseDependency\"\n```\n\n実行コマンド：\n\n```bash\nmake gen-swagger-v2\n```\n\nこれにより、Dockerコンテナ内でSwaggoが実行され、`backend/docs` に `swagger.yaml` と `swagger.json` が生成されます。\n\n---\n\n### 2.6 生成結果の確認\n\n生成後は、`backend/docs/swagger.yaml` を開くと、以下のようなAPI定義が自動で出力されているはずです：\n\n```yaml\npaths:\n  /tests:\n    get:\n      tags:\n        - tests\n      summary: List all tests\n      description: Returns all test records\n      responses:\n        \"200\":\n          description: OK\n          schema:\n            type: array\n            items:\n              $ref: \"#/definitions/TestResponse\"\n```\n\n---\n\n## 3. Swagger v2 → OpenAPI v3 への変換\n\nSwaggoが生成する `swagger.yaml` / `swagger.json` は **OpenAPI v2（= Swagger 2.0）** 形式です。\nしかし、後述する **Orval**（フロントエンド側のAPIクライアント自動生成ツール）は **OpenAPI v3** にのみ対応しています。\n\nそのため本章では、**Swagger v2 → OpenAPI v3 の変換パイプライン**を構築します。\n\n---\n\n### 3.1 OpenAPI Generatorとは？\n\n[OpenAPI Generator](https://openapi-generator.tech/) は、OpenAPI仕様書から多言語クライアント・サーバーコード・ドキュメントなどを自動生成するツールです。\n実はこのツールには、**仕様変換（v2 → v3）**の機能も含まれています。\n\n```bash\nopenapi-generator-cli generate \\\n  -i swagger.yaml \\\n  -g openapi-yaml \\\n  -o ./v3\n```\n\n- `-i`: 入力ファイル (`swagger.yaml`)\n- `-g`: 出力形式（ここでは `openapi-yaml` または `openapi`）\n- `-o`: 出力ディレクトリ\n- `--minimal-update`: 既存ファイルがある場合に差分のみ更新する\n\nこのコマンドを実行すると、Swagger 2.0形式のYAMLを解析し、OpenAPI 3.0準拠の定義ファイルを生成してくれます。\n\n---\n\n### 3.2 Dockerで実行する理由\n\nOpenAPI GeneratorはJavaベースのツールであり、ローカルで実行するにはJava環境が必要です。\nしかし、開発チーム全員にJavaを入れるのは現実的ではありません。\n\nそこで今回は、**公式Dockerイメージ `openapitools/openapi-generator-cli`** を使って変換を行います。\nDockerであればどの環境でも同一バージョンで再現でき、CI/CDにも組み込みやすくなります。\n\n---\n\n### 3.3 Makefileでの自動変換設定\n\n以下の `gen-openapi-v3` タスクをMakefileに追加します。\n\n```makefile\n.PHONY: gen-openapi-v3\ngen-openapi-v3:\n @echo \"[OAS3] Convert swagger.yaml → openapi.yaml\"\n docker run --rm -v $(PWD)/backend/docs:/work openapitools/openapi-generator-cli:latest-release \\\n   generate -i /work/swagger.yaml -o /work/v3 -g openapi-yaml --minimal-update\n\n @echo \"[OAS3] Convert swagger.json → openapi.json\"\n docker run --rm -v $(PWD)/backend/docs:/work openapitools/openapi-generator-cli:latest-release \\\n   generate -s -i /work/swagger.json -o /work/v3/openapi -g openapi --minimal-update\n\n @echo \"[Cleanup]\"\n docker run --rm -v $(PWD)/backend/docs/v3:/work golang:1.21-alpine \\\n   sh -c \"mv /work/openapi/openapi.yaml /work && mv /work/openapi/openapi.json /work && rm -rf /work/openapi\"\n```\n\n実行コマンド：\n\n```bash\nmake gen-openapi-v3\n```\n\n実行結果：\n\n```bash\n[OAS3] Convert swagger.yaml → openapi.yaml\n[OAS3] Convert swagger.json → openapi.json\n[Cleanup]\n```\n\n生成後の構成は以下のようになります。\n\n```tree\nbackend/docs/\n ├─ swagger.yaml         ← Swaggo生成 (v2)\n ├─ swagger.json         ← Swaggo生成 (v2)\n └─ v3/\n     ├─ openapi.yaml     ← OpenAPI Generatorで変換 (v3)\n     └─ openapi.json     ← OpenAPI Generatorで変換 (v3)\n```\n\n---\n\n### 3.4 実際に変換された差分例\n\n変換後のYAMLを開くと、`swagger: \"2.0\"` が `openapi: 3.0.1` に変わり、定義スキーマの構造も新形式に置き換わります。\n\n#### 変換前（Swagger 2.0）\n\n```yaml\nswagger: \"2.0\"\ninfo:\n  title: API\npaths:\n  /tests:\n    get:\n      produces:\n        - application/json\n      responses:\n        200:\n          schema:\n            type: array\n            items:\n              $ref: \"#/definitions/TestResponse\"\n```\n\n#### 変換後（OpenAPI 3.0）\n\n```yaml\nopenapi: 3.0.1\ninfo:\n  title: API\npaths:\n  /tests:\n    get:\n      responses:\n        200:\n          description: OK\n          content:\n            application/json:\n              schema:\n                type: array\n                items:\n                  $ref: \"#/components/schemas/TestResponse\"\ncomponents:\n  schemas:\n    TestResponse:\n      type: object\n      properties:\n        id:\n          type: integer\n```\n\nOpenAPI 3.0では `produces` / `consumes` の代わりに `content` フィールドが導入され、\nスキーマ定義も `definitions` → `components.schemas` に整理されているのが分かります。\n\n---\n\n### 3.5 OAS3変換のメリット\n\nOpenAPI v3へ変換することで、以下の利点が得られます。\n\n| 項目                           | 説明                                                  |\n| ------------------------------ | ----------------------------------------------------- |\n| **最新仕様への対応**           | OpenAPI v3はJSON Schema互換で、より厳密な型定義が可能 |\n| **ツールエコシステムの拡張性** | Orval・Stoplightなど最新ツール群がv3に準拠            |\n| **型生成の精度向上**           | NullableやOneOfなど複雑なスキーマを正確に表現できる   |\n| **将来的な拡張性**             | gRPC GatewayやGraphQLとの連携にも発展可能             |\n\n---\n\n### 3.6 一連の流れをおさらい\n\nここまでで、Goのソースコードから次のような流れが完成しました：\n\n```mermaid\nflowchart TD\n    A[\"Goソースコード\\n(Fiber + Swagコメント)\"]\n        --> B[\"make gen-swagger-v2\\n→ swagger.yaml / swagger.json (OAS2)\"]\n        --> C[\"make gen-openapi-v3\\n→ openapi.yaml / openapi.json (OAS3)\"]\n```\n\nこのOpenAPI v3定義を使えば、次章で **Next.js側のAPIクライアントを自動生成** できます。\n\n---\n\n## 4. フロントエンド（Next.js）側のクライアント生成\n\n前章までで、バックエンドから **OpenAPI v3形式** の仕様書が自動生成できるようになりました。\nここからは、その仕様をもとに **Next.js（TypeScript）側で型安全なAPIクライアントを自動生成** していきます。\n\n使用するのは、OpenAPIクライアント生成ツール **Orval** です。\n\n---\n\n### 4.1 Orvalとは？\n\n[Orval](https://orval.dev/) は、OpenAPI仕様から**型付きのフロントエンドAPIクライアントを自動生成**するツールです。\n生成されるコードはTypeScriptで、AxiosやReact Queryといった主要ライブラリと統合できます。\n\n#### Orvalを使うメリット\n\n| 項目                | 内容                                                            |\n| ------------------- | --------------------------------------------------------------- |\n| **型安全なAPI通信** | OpenAPIのスキーマに基づいてリクエスト・レスポンスを完全に型付け |\n| **React Query連携** | `useGetUsersQuery()` など、即使えるカスタムフックを自動生成     |\n| **自動更新**        | OpenAPI仕様が変わるたびに再生成するだけで常に最新化             |\n| **開発効率**        | フロント側でAPIロジックを書く必要がなくなる                     |\n\n---\n\n### 4.2 必要ライブラリの導入\n\nまず、フロントエンドプロジェクトに以下をインストールします。\n\n```bash\npnpm add orval -D\npnpm add axios\npnpm add @tanstack/react-query@4\n```\n\n- `orval`：APIクライアント自動生成ツール\n- `axios`：HTTPクライアント（Orvalが内部で利用）\n- `@tanstack/react-query`：データフェッチ管理ライブラリ（v4を指定）\n\n---\n\n### 4.3 orval.config.ts の設定\n\nOrvalの設定ファイルを `frontend/orval.config.ts` に作成します。\nこのファイルで、入力するOpenAPI定義と出力先の構造を定義します。\n\n```ts\nimport { defineConfig } from \"orval\";\n\nexport default defineConfig({\n  stepOfficialWebsite: {\n    input: \"../backend/docs/v3/openapi.yaml\",\n    output: {\n      target: \"./src/api/__generated__/\",\n      schemas: \"./src/api/__generated__/schemas\",\n      client: \"react-query\",\n      mode: \"tags-split\",\n      override: {\n        mutator: {\n          path: \"./src/api/customAxios.ts\",\n          name: \"customAxios\",\n          default: true,\n        },\n        query: {\n          useQuery: true,\n          usePrefetch: true,\n        },\n      },\n    },\n  },\n});\n```\n\n#### 各設定の解説\n\n| フィールド         | 意味                                                   |\n| ------------------ | ------------------------------------------------------ |\n| `input`            | 変換元のOpenAPIファイル（相対パスで指定）              |\n| `target`           | 自動生成コードの出力先ディレクトリ                     |\n| `schemas`          | スキーマ型定義の出力先                                 |\n| `client`           | 使用するHTTPクライアント（`react-query`を指定）        |\n| `mode`             | 出力分割モード（`tags-split`はタグ単位でファイル分割） |\n| `override.mutator` | Axios設定をカスタマイズするファイルを指定              |\n| `override.query`   | React Query用のオプションを指定                        |\n\n---\n\n### 4.4 カスタムAxiosクライアントの実装\n\nAPI呼び出し時の `baseURL` やログ処理を統一するために、`customAxios.ts` を定義します。\nOrvalは `mutator` 経由でこのAxiosインスタンスを利用します。\n\n```ts\nimport axios, { AxiosRequestConfig, AxiosError } from \"axios\";\n\nconst isServer = typeof window === \"undefined\";\n\nconst customAxios = async <T = unknown>(\n  config: AxiosRequestConfig,\n  options?: AxiosRequestConfig,\n): Promise<T> => {\n  const instance = axios.create({\n    baseURL: isServer ? \"http://backend:8080\" : \"/api\",\n  });\n\n  try {\n    const res = await instance.request({\n      ...config,\n      ...options,\n      headers: {\n        ...config.headers,\n        ...options?.headers,\n      },\n    });\n\n    return res.data;\n  } catch (err) {\n    const error = err as AxiosError;\n\n    if (isServer) {\n      console.error(\"Failed to request:\", {\n        url: config.url,\n        method: config.method,\n        status: error.response?.status,\n        data: error.response?.data,\n      });\n    }\n\n    throw error;\n  }\n};\n\nexport default customAxios;\n```\n\n#### 💡ポイント\n\n- SSR環境（Next.jsのサーバー側）では `http://backend:8080` を使用\n- CSR環境（ブラウザ）では `/api` にプロキシ\n- 例外発生時にはレスポンスをログ出力\n\n---\n\n### 4.5 package.json にスクリプト追加\n\nOrvalをnpmスクリプトから呼び出せるように設定します。\n\n```json\n{\n  \"scripts\": {\n    \"dev\": \"next dev --turbopack\",\n    \"build\": \"next build --turbopack\",\n    \"start\": \"next start\",\n    \"lint\": \"eslint\",\n    \"gen:client\": \"orval --config orval.config.ts\"\n  }\n}\n```\n\nこれで、次のコマンドを実行すればクライアントを自動生成できます。\n\n```bash\npnpm run gen:client\n```\n\n---\n\n### 4.6 Makefileによる自動化\n\nさらに、バックエンドと同様にMakefileで統合タスクを用意します。\n\n```makefile\n.PHONY: gen-client\ngen-client:\n @echo \"[Clean] Remove old generated client\"\n rm -rf frontend/src/api/__generated__\n @echo \"[Generate] Running npm run gen:client\"\n cd frontend && npm run gen:client\n```\n\nコマンド一発で古いクライアントを削除 → 再生成まで実行可能です。\n\n```bash\nmake gen-client\n```\n\n---\n\n### 4.7 生成結果の確認\n\nコマンド実行後、以下のような構成が生成されます。\n\n```tree\nfrontend/\n ├─ src/api/\n │   ├─ __generated__/        ← 自動生成コード\n │   │   ├─ schemas/\n │   │   │   └─ TestResponse.ts\n │   │   ├─ tests/\n │   │   │   ├─ useGetTestsQuery.ts\n │   │   │   └─ useCreateTestMutation.ts\n │   │   └─ index.ts\n │   ├─ customAxios.ts\n │   └─ orval.config.ts\n```\n\n生成された関数・フック例：\n\n```ts\nimport {\n  useGetTestsQuery,\n  useCreateTestMutation,\n} from \"@/api/__generated__/tests\";\n\n// 一覧取得\nconst { data } = useGetTestsQuery();\n\n// 新規作成\nconst { mutate } = useCreateTestMutation();\nmutate({ ...payload });\n```\n\nこれで、フロントエンドは**完全型安全かつ自動同期されたAPI呼び出し環境**を得られます。\n\n---\n\n### 4.8 開発フロー全体の統合\n\nここまでの工程をMakefileにまとめると、以下のような一連の自動化パイプラインが完成します：\n\n```bash\nmake gen-swagger-v2   # GoからSwagger (v2) 生成\nmake gen-openapi-v3   # OpenAPI v3に変換\nmake gen-client       # Next.js側クライアント自動生成\n```\n\nこれらを順に実行することで、**バックエンドの変更がフロントエンドまで自動で反映される**ようになります。\n\n---\n\n### ✅ まとめ\n\n| ステップ         | ツール            | 出力                        |\n| ---------------- | ----------------- | --------------------------- |\n| Goコメント解析   | Swaggo            | swagger.yaml / swagger.json |\n| 仕様変換         | OpenAPI Generator | openapi.yaml / openapi.json |\n| クライアント生成 | Orval             | TypeScript APIクライアント  |\n\nこれにより、「API仕様を直したらフロントが壊れる」というよくある問題を根本的に防ぎつつ、**開発速度と品質を両立**できます。\n\n## 5. React Queryとの統合\n\nOrvalは、OpenAPI仕様から**Axios + React QueryベースのAPIクライアント**を自動生成します。\nこの仕組みを活かすことで、Next.jsのフロントエンドは「手書きのAPI呼び出し」から解放され、**完全に型安全なデータフェッチ層**を実現できます。\n\n---\n\n### 5.1 React Queryとは？\n\n[React Query（@tanstack/react-query）](https://tanstack.com/query/v4/docs/framework/react/overview) は、\nデータフェッチ・キャッシュ・エラーハンドリング・再取得などを自動で管理してくれるライブラリです。\n\n#### 💡 これまでの問題点\n\n従来の`useEffect`＋`axios`構成では：\n\n- ローディング状態やエラー処理を毎回書く必要がある\n- データキャッシュが効かないため無駄な再フェッチが発生\n- 並列リクエストや再取得の制御が煩雑\n\n#### ✅ React Queryを使うと\n\n- `useQuery` / `useMutation` だけでデータ取得・更新が完結\n- キャッシュ・リトライ・再フェッチなどを自動管理\n- フロント側の「状態管理」を大幅に削減できる\n\n---\n\n### 5.2 OrvalによるReact Queryフック生成\n\n`orval.config.ts` で `client: \"react-query\"` を指定しているため、\n`pnpm run gen:client` を実行すると自動的にReact Query対応のフックが生成されます。\n\n#### 生成例\n\n```tree\nfrontend/src/api/__generated__/tests/\n ├─ useGetTestsQuery.ts\n ├─ useCreateTestMutation.ts\n └─ index.ts\n```\n\nこれらのフックをそのままReactコンポーネントで呼び出せます。\n\n---\n\n### 5.3 QueryClientのセットアップ\n\nまず、アプリ全体でReact Queryを有効にするため、\nNext.jsの`_app.tsx`（または`layout.tsx`）で`QueryClientProvider`を設定します。\n\n```tsx\n// src/pages/_app.tsx\nimport { QueryClient, QueryClientProvider } from \"@tanstack/react-query\";\nimport { ReactQueryDevtools } from \"@tanstack/react-query-devtools\";\nimport type { AppProps } from \"next/app\";\n\nconst queryClient = new QueryClient();\n\nexport default function App({ Component, pageProps }: AppProps) {\n  return (\n    <QueryClientProvider client={queryClient}>\n      <Component {...pageProps} />\n      <ReactQueryDevtools initialIsOpen={false} />\n    </QueryClientProvider>\n  );\n}\n```\n\nこれで全ページから自動生成フックが使えるようになります。\n\n---\n\n### 5.4 取得処理の例：`useGetTestsQuery`\n\nOrvalが自動生成する `useGetTestsQuery` は、\n`GET /tests` エンドポイントに対応した型安全なフェッチ関数です。\n\n```tsx\n// src/pages/tests.tsx\nimport { useGetTestsQuery } from \"@/api/__generated__/tests\";\n\nexport default function TestsPage() {\n  const { data, isLoading, isError } = useGetTestsQuery();\n\n  if (isLoading) return <p>Loading...</p>;\n  if (isError) return <p>Failed to load data.</p>;\n\n  return (\n    <div>\n      <h1>Tests</h1>\n      <ul>{data?.map((item) => <li key={item.id}>ID: {item.id}</li>)}</ul>\n    </div>\n  );\n}\n```\n\n#### Docker構成の特徴\n\n- `data` の型は自動的に `TestResponse[]` と推論される\n- `isLoading`, `isError` などの状態も標準提供\n- バックエンドの変更に追従して型が即座に更新\n\n---\n\n### 5.5 登録処理の例：`useCreateTestMutation`\n\nPOSTエンドポイント（`/tests [post]`）に対応するのが `useCreateTestMutation`。\nミューテーション（更新系処理）はReact Queryの`mutate`を使って実行します。\n\n```tsx\n// src/pages/create-test.tsx\nimport { useState } from \"react\";\nimport { useCreateTestMutation } from \"@/api/__generated__/tests\";\n\nexport default function CreateTestPage() {\n  const [text, setText] = useState(\"\");\n  const mutation = useCreateTestMutation();\n\n  const handleSubmit = () => {\n    mutation.mutate(\n      { name: text }, // 入力データ\n      {\n        onSuccess: (data) => alert(`Created! ID: ${data.id}`),\n        onError: (err) => alert(\"Failed: \" + err),\n      },\n    );\n  };\n\n  return (\n    <div>\n      <h1>Create Test</h1>\n      <input value={text} onChange={(e) => setText(e.target.value)} />\n      <button onClick={handleSubmit} disabled={mutation.isLoading}>\n        {mutation.isLoading ? \"Submitting...\" : \"Submit\"}\n      </button>\n    </div>\n  );\n}\n```\n\n#### ポイント\n\n- `mutate` はPromiseではなくコールバックベースで扱う\n- 状態変化（`isLoading`, `isSuccess`, `isError`）を自動管理\n- 成功時にキャッシュを自動で更新する設定も可能\n\n---\n\n### 5.6 データキャッシュと再フェッチ\n\nReact Queryの最大の強みは、**自動キャッシュと再フェッチ制御**です。\nOrval生成フックも内部的に `useQuery` を利用しているため、キャッシュが自動で効きます。\n\n```tsx\nconst { data } = useGetTestsQuery(undefined, {\n  staleTime: 1000 * 60 * 5, // 5分間キャッシュ有効\n});\n```\n\n- `staleTime`：データを再取得せずキャッシュを使う期間\n- `refetchOnWindowFocus`：フォーカス時に再フェッチするか（デフォルトtrue）\n- `enabled`：条件付きフェッチを制御\n\nこれらのオプションはOrval経由でもそのまま利用可能です。\n\n---\n\n### 5.7 Orvalのプリフェッチ機能\n\n`orval.config.ts` の `usePrefetch: true` により、\n`usePrefetchGetTestsQuery()` のような**事前取得用関数**も自動生成されます。\n\n```tsx\nconst prefetch = usePrefetchGetTestsQuery();\n\nuseEffect(() => {\n  prefetch(); // ページ遷移前にデータをキャッシュ\n}, []);\n```\n\nこれにより、ページ遷移時にすでにデータがキャッシュされており、**瞬時に表示**できるようになります。\n\n---\n\n### 5.8 React Query Devtools でのデバッグ\n\n開発中は [React Query Devtools](https://tanstack.com/query/v4/docs/devtools) を有効にすると便利です。\nキャッシュの状態やフェッチ履歴を可視化できます。\n\n```tsx\nimport { ReactQueryDevtools } from \"@tanstack/react-query-devtools\";\n\n// _app.tsx 内に追加済み\n<ReactQueryDevtools initialIsOpen={false} />;\n```\n\nブラウザ右下に Devtools が表示され、APIキャッシュの挙動をリアルタイムで確認可能です。\n\n---\n\n### まとめ：トラブルシューティングガイド\n\n| 要素                      | 内容                                            |\n| ------------------------- | ----------------------------------------------- |\n| **クエリ系API**           | `useGetXxxQuery()` で自動キャッシュ付きフェッチ |\n| **ミューテーション系API** | `useCreateXxxMutation()` でPOST/PUT/DELETE操作  |\n| **型定義**                | OpenAPIスキーマから自動生成（変更にも即追従）   |\n| **React Query統合**       | キャッシュ・リトライ・状態管理が自動化          |\n\nこれで、**バックエンド → OpenAPI → Orval → React Query → UI**\nという、理想的なフル自動型安全データフローが完成しました。\n\n---\n\n## 6. Docker Composeでの連携実行\n\nここまでで、\n\n- Go（Fiber）でAPIサーバーを構築し\n- Swagger → OpenAPI → Orval で自動クライアントを生成し\n- Next.js でReact Queryを使ってデータを扱う\n  という仕組みを完成させました。\n\nこの章では、**Docker Composeで「開発環境」と「本番環境」を明確に分離しつつ連携動作させる構成**を紹介します。\n\n---\n\n### 6.1 全体構成図\n\nアプリは以下の4サービスで構成されています。\n\n```mermaid\ngraph TD\n    F[\"frontend\"] --> N[\"nginx\"]\n    N --> B[\"backend\"]\n    B --> D[\"db (PostgreSQL)\"]\n```\n\n- **frontend**：Next.js（TypeScript）\n- **backend**：Go（Fiber）\n- **db**：PostgreSQL\n- **nginx**：リバースプロキシ（フロント・バックの統合）\n\n---\n\n### 6.2 開発環境（docker-compose.dev.yml）\n\n開発環境では、**ホットリロード・同期マウント・軽量再ビルド**を重視した構成です。\n\n```yaml\nversion: \"3.9\"\n\nx-common: &common\n  restart: unless-stopped\n  networks:\n    - app-network\n\nservices:\n  backend:\n    <<: *common\n    build:\n      context: ..\n      dockerfile: deploy/docker/backend/Dockerfile.dev\n    volumes:\n      - ../backend:/app\n      - go_mod_cache:/go/pkg/mod\n    ports:\n      - \"8080:8080\"\n    env_file:\n      - .env.dev\n    develop:\n      watch:\n        - action: sync\n          path: ../backend\n          target: /app\n        - action: rebuild\n          path: ../backend/go.mod\n\n  frontend:\n    <<: *common\n    build:\n      context: ..\n      dockerfile: deploy/docker/frontend/Dockerfile.dev\n    volumes:\n      - ../frontend:/app\n      - /app/node_modules\n      - /app/.next\n    ports:\n      - \"3000:3000\"\n    env_file:\n      - .env.dev\n    develop:\n      watch:\n        - action: sync\n          path: ../frontend\n          target: /app\n          ignore:\n            - node_modules/\n            - .next/\n        - action: rebuild\n          path: ../frontend/package.json\n\n  db:\n    <<: *common\n    build:\n      context: ..\n      dockerfile: deploy/docker/db/Dockerfile\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - db_data:/var/lib/postgresql/data\n    env_file:\n      - .env.dev\n    command:\n      [\n        \"postgres\",\n        \"-c\",\n        \"log_statement=all\",\n        \"-c\",\n        \"log_destination=stderr\",\n        \"-c\",\n        \"shared_preload_libraries=pg_stat_statements\",\n      ]\n\n  nginx:\n    <<: *common\n    build:\n      context: ..\n      dockerfile: deploy/docker/nginx/Dockerfile\n    ports:\n      - \"80:80\"\n    depends_on:\n      - frontend\n      - backend\n\nvolumes:\n  db_data:\n    driver: local\n  go_mod_cache:\n    driver: local\n  pnpm_cache:\n    driver: local\n\nnetworks:\n  app-network:\n    driver: bridge\n```\n\n#### ✅ 特徴\n\n- `develop.watch` によりコード変更をリアルタイム反映\n- `backend` は Air によるホットリロード対応\n- `frontend` は Turbopack の dev モードで起動\n- Nginx 経由で `http://localhost` から全体をアクセス可能\n\n---\n\n### 6.3 本番環境（docker-compose.prod.yml）\n\n本番環境では、**最適化ビルド済みコンテナ**を使用し、\nすべてのアプリケーションを軽量・堅牢に実行します。\n\n```yaml\nversion: \"3.9\"\n\nx-common: &common\n  restart: unless-stopped\n  networks:\n    - app-network\n\nservices:\n  backend:\n    <<: *common\n    build:\n      context: ..\n      dockerfile: deploy/docker/backend/Dockerfile.prod\n    ports:\n      - \"8080:8080\"\n    env_file:\n      - .env.prod\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    depends_on:\n      db:\n        condition: service_healthy\n\n  frontend:\n    <<: *common\n    build:\n      context: ..\n      dockerfile: deploy/docker/frontend/Dockerfile.prod\n    ports:\n      - \"3000:3000\"\n    env_file:\n      - .env.prod\n    depends_on:\n      backend:\n        condition: service_healthy\n\n  db:\n    <<: *common\n    build:\n      context: ..\n      dockerfile: deploy/docker/db/Dockerfile\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - db_data:/var/lib/postgresql/data\n    env_file:\n      - .env.prod\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    command:\n      [\n        \"postgres\",\n        \"-c\",\n        \"shared_preload_libraries=pg_stat_statements\",\n        \"-c\",\n        \"max_connections=200\",\n        \"-c\",\n        \"shared_buffers=256MB\",\n        \"-c\",\n        \"effective_cache_size=1GB\",\n        \"-c\",\n        \"work_mem=4MB\",\n        \"-c\",\n        \"maintenance_work_mem=64MB\",\n        \"-c\",\n        \"checkpoint_completion_target=0.7\",\n        \"-c\",\n        \"wal_buffers=16MB\",\n        \"-c\",\n        \"default_statistics_target=100\",\n      ]\n\n  nginx:\n    <<: *common\n    build:\n      context: ..\n      dockerfile: deploy/docker/nginx/Dockerfile\n    ports:\n      - \"80:80\"\n    depends_on:\n      frontend:\n        condition: service_started\n      backend:\n        condition: service_healthy\n\nvolumes:\n  db_data:\n    driver: local\n\nnetworks:\n  app-network:\n    driver: bridge\n```\n\n#### 特徴\n\n- `builder` → `runner` のマルチステージで極限まで軽量化\n- `healthcheck` により自動依存解決（DB→API→Front）\n- Nginx がフロントエンドとAPIのリバースプロキシを統一管理\n\n---\n\n### 6.4 Nginxの設定\n\n`deploy/docker/nginx/default.conf` では、\nフロントエンドとバックエンドを1つのドメインで扱うようルーティングしています。\n\n```nginx\nserver {\n    listen 80;\n\n    # Frontend requests\n    location / {\n        proxy_pass http://frontend:3000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n\n    # Backend API requests\n    location /api/ {\n        proxy_pass http://backend:8080/;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n```\n\nこれにより、ブラウザからは `/api/...` と叩くだけで内部的に `backend:8080` に転送されます。\n\n---\n\n### 6.5 Makefileによる起動コマンド\n\n開発と本番を簡単に切り替えられるよう、Makefileで統一コマンドを提供します。\n\n```makefile\n# ==========================\n# Development\n# ==========================\n.PHONY: dev-up dev-down\ndev-up:\n @echo \"[Start] Development Environment\"\n docker compose -f deploy/docker-compose.dev.yml --env-file deploy/.env.dev up --build\n\ndev-down:\n @echo \"[Stop] Development Environment\"\n docker compose -f deploy/docker-compose.dev.yml down -v\n\n# ==========================\n# Production\n# ==========================\n.PHONY: prod-up prod-down\nprod-up:\n @echo \"[Start] Production Environment\"\n docker compose -f deploy/docker-compose.prod.yml --env-file deploy/.env.prod up --build -d\n\nprod-down:\n @echo \"[Stop] Production Environment\"\n docker compose -f deploy/docker-compose.prod.yml down -v\n```\n\nこれで以下のように使えます：\n\n```bash\nmake dev-up     # 開発環境起動\nmake dev-down   # 開発環境停止\nmake prod-up    # 本番起動（デタッチモード）\nmake prod-down  # 本番停止\n```\n\n---\n\n### 6.6 APIクライアント生成も含めた統合ワークフロー\n\nMakefileを拡張し、Swagger・OpenAPI・Orvalの生成も一気に実行できます。\n\n```makefile\n.PHONY: gen-all\ngen-all:\n @echo \"[Pipeline] Generating Swagger, OpenAPI v3, and API client\"\n make gen-swagger-v2\n make gen-openapi-v3\n make gen-client\n```\n\nこれにより、**バックエンドの変更 → OpenAPI更新 → フロント同期** まで\nすべてワンコマンドで完了します。\n\n---\n\n### 6.7 起動確認\n\n| URL                                                                                  | 内容                                  |\n| ------------------------------------------------------------------------------------ | ------------------------------------- |\n| [http://localhost](http://localhost)                                                 | フロントエンド（Next.js + Nginx）     |\n| [http://localhost/api/tests](http://localhost/api/tests)                             | Go API (Fiber) の確認用エンドポイント |\n| [http://localhost:8080/swagger/index.html](http://localhost:8080/swagger/index.html) | Swagger UI                            |\n| [http://localhost:3000](http://localhost:3000)                                       | Next.jsの直接アクセス                 |\n\n開発中は `http://localhost` だけで両方にアクセスでき、本番でもNginxが同様に統合します。\n\n---\n\n### まとめ\n\n| 項目             | 内容                                        |\n| ---------------- | ------------------------------------------- |\n| **開発環境**     | ソースコード同期・ホットリロード付き構成    |\n| **本番環境**     | 軽量ビルド済みマルチステージ構成            |\n| **通信統合**     | Nginxによる `/api` リバースプロキシ         |\n| **Makefile操作** | `make dev-up` / `make prod-up` で統一       |\n| **自動生成統合** | `make gen-all` でSwagger→OpenAPI→Client一括 |\n\n---\n\n## 7. トラブルシューティング\n\nここまで構築した自動生成パイプラインは強力ですが、\n実際に運用していると以下のような問題に遭遇することがあります。\n\n- SwaggerやOpenAPIの生成がうまくいかない\n- Orvalの型生成でエラーが出る\n- Docker間の通信ができない\n- 本番ビルドでAPIが404になる\n\nこの章では、それぞれの原因と解決策をまとめます。\n\n---\n\n### 7.1 Swaggo（Swagger生成）でのトラブル\n\n#### ❌ エラー例（Swagger生成）\n\n```bash\nError: failed to parse packages analyzing cmd/server/main.go: cannot find module for path ...\n```\n\n#### 💡 原因（7.1.1）\n\n`swag init` 実行時にモジュールの依存関係を解決できていないか、`go.mod` が正しいディレクトリ構造にない。\n\n#### ✅ 対処法\n\n1. backendディレクトリ内で依存を再取得\n\n   ```bash\n   cd backend\n   go mod tidy\n   ```\n\n2. `main.go` の `@Router` / `@Summary` などのコメントに誤字がないか確認\n3. Docker経由で動かす場合、Makefileの `-w /app` が正しいか確認\n\n   ```makefile\n   docker run --rm -v $(PWD)/backend:/app -w /app golang:1.25-alpine ...\n   ```\n\n#### 🛡 再発防止策\n\n- `backend` 以下のみにGoコードを配置する\n- `swag init -g cmd/server/main.go --parseDependency` を必ず指定する\n\n---\n\n### 7.2 OpenAPI Generatorでの変換失敗\n\n#### ❌ エラー例（OpenAPI変換）\n\n```bash\nError: Could not resolve reference: '#/definitions/TestResponse'\n```\n\n#### 💡 原因\n\nSwagger v2 の `definitions` が正しく生成されていないか、コメントで型を正しく指定していない。\n\n#### ✅ 対処法\n\n1. `@Success 200 {object} TestResponse` のように構造体名を明示的に指定\n2. Swaggerファイルを手動で開き、`definitions:` ブロックに `TestResponse` が含まれているか確認\n3. 不要なファイルを削除して再生成\n\n   ```bash\n   rm -rf backend/docs\n   make gen-swagger-v2\n   make gen-openapi-v3\n   ```\n\n#### 🛡 再発防止策\n\n- `swag fmt` をMakefileで常に実行してコメント整形\n- `@Param`, `@Success`, `@Failure` は正確に書く\n\n---\n\n### 7.3 Orvalでの型生成エラー\n\n#### ❌ エラー例（Orval）\n\n```bash\nError: Cannot find module '../backend/docs/v3/openapi.yaml'\n```\n\n#### 💡 原因\n\n`openapi.yaml` の出力パスが異なるか、`frontend/orval.config.ts` の `input` が相対パスでずれている。\n\n#### ✅ 対処法\n\n1. Orval設定で正しい相対パスを指定\n\n   ```ts\n   input: \"../backend/docs/v3/openapi.yaml\",\n   ```\n\n2. 一度生成物を削除して再実行\n\n   ```bash\n   make gen-client\n   ```\n\n#### 🛡 再発防止策\n\n- `backend/docs/v3` を `.gitignore` から除外し、他の開発者と共有\n- OpenAPI出力先は固定ディレクトリに統一\n\n---\n\n### 7.4 Dockerコンテナ間で通信できない\n\n#### ❌ 症状\n\n- `axios` が `ECONNREFUSED` を返す\n- `GET /api/tests` がタイムアウトする\n\n#### 💡 原因\n\n- `baseURL` がホスト向け (`localhost`) になっている\n- コンテナ名で通信していない\n\n#### ✅ 対処法\n\n`frontend/src/api/customAxios.ts` の設定を確認：\n\n```ts\nconst instance = axios.create({\n  baseURL: typeof window === \"undefined\" ? \"http://backend:8080\" : \"/api\",\n});\n```\n\nDocker Composeでは、`backend` がネットワーク名なので `backend:8080` にする必要があります。\n\n#### 🛡 再発防止策\n\n- `localhost` ではなくサービス名でアクセス\n- `nginx` 経由に統一（`/api/` → `backend:8080/`）\n\n---\n\n### 7.5 Next.jsのビルド失敗（pnpm関連）\n\n#### ❌ エラー例（Next.js）\n\n```bash\nError: Cannot find module 'next'\n```\n\n#### 💡 原因\n\n`node_modules` がDockerコンテナ内にのみ存在し、ホスト側のVSCode補完が効いていない。\n\n#### ✅ 対処法\n\n1. ホストにも依存を入れる\n\n   ```bash\n   cd frontend\n   pnpm install\n   ```\n\n2. `.vscode/settings.json` にTypeScript SDKを明示指定\n\n   ```json\n   {\n     \"typescript.tsdk\": \"frontend/node_modules/typescript/lib\"\n   }\n   ```\n\n#### 🛡 再発防止策\n\n- `node_modules` はホストに保持 or VSCode設定で補完を有効化\n- Composeのvolumeマウントで `- /app/node_modules` を適切に扱う\n\n---\n\n### 7.6 Nginx経由の404エラー\n\n#### ❌ 症状\n\nブラウザで `http://localhost/api/tests` にアクセスすると\n「404 Not Found」が返る。\n\n#### 💡 原因\n\n- `default.conf` の `location /api/` に末尾スラッシュ (`/`) がない\n- プロキシパスが `http://backend:8080` で終わっていない\n\n#### ✅ 修正例\n\n```nginx\nlocation /api/ {\n    proxy_pass http://backend:8080/;  # ← スラッシュ必須\n}\n```\n\n#### 🛡 再発防止策\n\n- `proxy_pass` の末尾スラッシュは常に確認\n- `nginx -t` で構文チェックしてから再起動\n\n---\n\n### 7.7 本番ビルド後に `server.js` が見つからない\n\n#### ❌ エラー例（server.js）\n\n```bash\nError: Cannot find module '/app/server.js'\n```\n\n#### 💡 原因\n\nNext.js 13以降で `output: \"standalone\"` 設定がされていないか、\n`builder` ステージで `server.js` が生成されていない。\n\n#### ✅ 対処法\n\n1. `next.config.js` に以下を追加：\n\n   ```js\n   module.exports = {\n     output: \"standalone\",\n   };\n   ```\n\n2. 再ビルド：\n\n   ```bash\n   docker compose -f deploy/docker-compose.prod.yml build frontend\n   ```\n\n#### 🛡 再発防止策\n\n- `pnpm build` のログで `server.js` が生成されているか確認\n- 本番Dockerfileで `.next/standalone` を必ずコピー\n\n---\n\n### 7.8 DBコンテナが起動しない\n\n#### ❌ エラー例（DB起動）\n\n```bash\ndatabase system is starting up\npg_isready: server not accepting connections\n```\n\n#### 💡 原因\n\n`POSTGRES_USER` / `POSTGRES_PASSWORD` / `POSTGRES_DB` が不整合\nまたはVolumeに古いデータが残っている。\n\n#### ✅ 対処法\n\n```bash\ndocker compose down -v\nmake dev-up\n```\n\n#### 🛡 再発防止策\n\n- `.env.dev` / `.env.prod` のDB設定を明示的に管理\n- Volumeを共有せず、環境ごとに分離する\n\n---\n\n### 7.9 キャッシュが古くて変更が反映されない\n\n#### ❌ 症状\n\nDockerビルド後も古いコードが反映されない。\n\n#### ✅ 対処法\n\n```bash\ndocker compose build --no-cache\n```\n\n#### 🛡 再発防止策\n\n- 開発中は `:latest` タグやキャッシュ共有を避ける\n- `develop.watch` を利用してリアルタイム反映\n\n---\n\n### まとめ：チェックリスト\n\n| 項目        | よくある問題     | 解決策                                     |\n| ----------- | ---------------- | ------------------------------------------ |\n| Swagger生成 | コメント構文ミス | `swag fmt` + `--parseDependency`           |\n| OpenAPI変換 | 型参照エラー     | `@Success {object} TypeName`               |\n| Orval生成   | パスずれ         | `input: \"../backend/docs/v3/openapi.yaml\"` |\n| Docker通信  | ECONNREFUSED     | `baseURL = backend:8080`                   |\n| Nginx設定   | 404エラー        | `proxy_pass` の末尾スラッシュ              |\n| Next.js本番 | `server.js` 不在 | `output: \"standalone\"`                     |\n| DB起動      | 古いVolume       | `docker compose down -v`                   |\n\n---\n\n## 8. まとめと今後の発展\n\nここまでで、**Go（Fiber）× Next.js × OpenAPI** を軸にした\n完全な自動APIクライアント生成パイプラインを構築しました。\n\n---\n\n### 8.1 今回構築した仕組みの全体像\n\n```mermaid\ngraph TD\n    A[\"Go Fiber\"]\n        --> B[\"Swagger v2\"]\n    B --> C[\"OpenAPI v3\"]\n    C --> D[\"Orval\"]\n    D --> E[\"React Query\"]\n```\n\nこれを1本のパイプラインとしてつなぎ、\n**「バックエンドの更新が即フロントに反映される」**仕組みを実現しました。\n\n| ステップ           | 内容                                   | コマンド              |\n| ------------------ | -------------------------------------- | --------------------- |\n| ① Swagger生成      | GoのコメントからAPI仕様生成            | `make gen-swagger-v2` |\n| ② OpenAPI変換      | Swagger → OpenAPI 3.0形式に変換        | `make gen-openapi-v3` |\n| ③ クライアント生成 | Orval + React Queryで型安全なHooks生成 | `make gen-client`     |\n| ④ 開発実行         | Docker Composeで全サービス起動         | `make dev-up`         |\n\nすべてを自動化することで、\n仕様・実装・ドキュメント・通信層を**完全同期**させることができます。\n\n---\n\n### 8.2 この構成のメリット\n\n#### **① 型安全な通信層**\n\nバックエンド変更時に自動で型が更新されるため、\nフロントエンド側でAPIミスマッチを防止できます。\n\n#### **② 即時反映・ホットリロード**\n\nDockerの `develop.watch` + `air` + `Turbopack` により、\n両側の変更をほぼリアルタイムで反映。\n\n#### **③ 開発環境と本番環境の完全分離**\n\n`.env.dev` / `.env.prod` による設定分離と\nマルチステージDockerfileによって、\n**開発の柔軟性**と**本番の軽量性**を両立。\n\n#### **④ CI/CDにも組み込みやすい構成**\n\nMakefileを使った統一的コマンド群により、\nGitHub ActionsなどのCI/CDにも簡単に組み込めます。\n\n---\n\n### 8.3 今後の発展ポイント\n\n今回の構成は基礎として非常に強力ですが、\nより実践的に拡張する余地も多くあります。\n\n#### **① CI/CDとの統合**\n\nGitHub Actionsで `make gen-all` → `make prod-up` の自動化を行えば、\nAPI仕様変更がpushされたタイミングで\n**自動的にOpenAPI更新 → クライアント再生成 → デプロイ**まで実行できます。\n\n#### **② 認証・認可の追加**\n\nSwaggerコメントに以下のような定義を追加すれば、\nJWTやOAuth2のスキーマもOpenAPI経由で自動生成可能です。\n\n```go\n// @securityDefinitions.apikey ApiKeyAuth\n// @in header\n// @name Authorization\n```\n\n→ フロントではOrval生成クライアントにInterceptorを追加して\nトークンを自動付与できるようになります。\n\n#### **③ OpenAPIから型生成の高度化**\n\nOrvalの `transformer` オプションを活用することで、\nレスポンスを自動整形・キャッシュ更新・エラーハンドリングも共通化可能です。\n\n#### **④ モノレポ構成への拡張**\n\nプロジェクトをMonorepo（例: `backend/`, `frontend/`, `shared/`）化し、\n`shared/types` に共通定義を配置すると、\nバックエンドとフロントで型を共有できます。\n\n#### **⑤ gRPC / GraphQL への発展**\n\nREST APIをOpenAPIで運用する基盤が整ったら、\n将来的には gRPC や GraphQL へ移行する際にも\nこの構成をベースにスムーズに拡張できます。\n\n---\n\n### 8.4 最後に\n\nこの一連の仕組みは、\n**「仕様変更に強い開発体験」**を実現するための重要な基盤です。\n\n- Goのコメント → 自動ドキュメント化\n- OpenAPIによる仕様の標準化\n- Orval + React Queryによる型安全通信\n- Docker Composeでの環境再現性\n- Makefileによる開発プロセスの自動化\n\nこれらを組み合わせることで、\n**バックエンドとフロントエンドの乖離を最小化し、チーム全体の速度と品質を最大化**できます。\n\n---\n\n### 今後やるべき一歩\n\n| フェーズ | 内容                                       |\n| -------- | ------------------------------------------ |\n| ✅ 現在  | Swagger → OpenAPI → Orval 自動連携構築     |\n| 🚀 次    | CI/CD自動化・JWT認証連携                   |\n| 🌐 将来  | Monorepo化・gRPCやGraphQL対応・RAG連携など |\n\n---\n\n> 🏁 **この構成は“現代的なフルスタック自動化”のベースライン。**\n> 一度整えば、API開発・型生成・デプロイ・モニタリングまでを\n> 一貫してスケーラブルに運用できるようになります。\n",
    "createdAt": "2025-10-04T15:53:36.990Z",
    "updatedAt": "2025-10-04T15:53:36.991Z"
  },
  {
    "title": "Next.js App routerで，Custom 404 pageにレイアウトを適用させない方法",
    "summary": "地味に苦労した．日本語の記事がなかったのでつくる",
    "tags": [
      "React",
      "Next.js",
      "Web",
      "Webアプリ開発",
      "個人開発"
    ],
    "slug": "Next.js/next-js-app-router-404-layout",
    "folder": "Next.js",
    "content": "\n`Layout.tsx`は配置されているディレクトリの中身に適用される\n\n→ `not-found.tsx`と`page.tsx`とで違うディレクトリにすれば良い．\n\n→ 普通のディレクトリにいれるとルーティングされるので，論理グループを使う\n\n```txt\napp/\n    (default_site)/\n        /page.tsx\n        about/page.tsx\n        contact/page.tsx\n        layout.tsx\n    (error_layout)/\n        layout.tsx\n        not-found.tsx\ncomponents/\nutils/\n```\n\nこのように配置すればいい\n\n参考\n[How to remove the Layout on 404 page](https://github.com/vercel/next.js/discussions/37311)\n",
    "createdAt": "2025-07-21T07:23:48.458Z",
    "updatedAt": "2025-07-21T07:23:48.458Z"
  },
  {
    "title": "Next.jsで開発するときにおすすめのセットアップ手法",
    "summary": "eslintの設定やtailwind等の設定をいじって開発体験を上げる",
    "tags": [
      "Next.js",
      "eslint",
      "vscode",
      "tailwindcss"
    ],
    "slug": "Next.js/next-js-setup-practice",
    "folder": "Next.js",
    "content": "\n# ESLintの設定\n\n## ESLintとは\n\nESlintはJavaScriptやTypeScriptなどに使える静的解析ツールです．any型を許容するのか，アロー関数のみを使うのかなど，多岐に渡って厳密なルールを定義することでコードの一貫性を維持することができます．\n\n## おすすめの設定法\n\n### npmライブラリの追加\n\n`npx create-next-app@latest`し，以下のように設定した場合を想定します\n\n```bash\nWhat is your project named?  xxx\nWould you like to use TypeScript?  Yes\nWould you like to use ESLint?  Yes\nWould you like to use Tailwind CSS?  Yes\nWould you like your code inside a `src/` directory?  No\nWould you like to use App Router? (recommended)  Yes\nWould you like to use Turbopack for `next dev`?  Yes\nWould you like to customize the import alias (`@/*` by default)?  No\n```\n\nこの場合，デフォルトで以下のようなnpmパッケージが取り込まれます．\n\n```json\n  \"dependencies\": {\n    \"react\": \"^18\",\n    \"react-dom\": \"^18\",\n    \"next\": \"14.2.29\"\n  },\n  \"devDependencies\": {\n    \"typescript\": \"^5\",\n    \"@types/node\": \"^20\",\n    \"@types/react\": \"^18\",\n    \"@types/react-dom\": \"^18\",\n    \"postcss\": \"^8\",\n    \"tailwindcss\": \"^3.4.1\",\n    \"eslint\": \"^8\",\n    \"eslint-config-next\": \"14.2.29\"\n  }\n```\n\nここからさらにeslint関連のライブラリを追加していきます．\n| ライブラリ名 | 主な用途・特徴 |\n| ------------------------------------ | ---------------------------------------------------------------- |\n| **@typescript-eslint/eslint-plugin** | TypeScript向けのESLintルール集。型情報を活かした詳細な静的解析が可能になる。 |\n| **@typescript-eslint/parser** | ESLintにTypeScript構文を理解させるためのパーサ。これがないとTSコードにESLintが使えない。 |\n| **@eslint/eslintrc** | `.eslintrc` 設定ファイルの読み込みに使う内部ツール。通常不要だが、高度な設定やバージョン差異の吸収に使うこともある。 |\n| **eslint-plugin-import** | `import` 文の書き方（順序、重複、解決可能性）をチェック・補正するための定番プラグイン。 |\n| **eslint-plugin-import-access** | 特定のディレクトリや層に対するアクセス制限ルールを定義できる。Clean Architectureなどと相性が良い。 |\n| **eslint-plugin-simple-import-sort** | `import`, `export` をアルファベット順や指定順に自動整列してくれるプラグイン。整形の補助に便利。 |\n| **eslint-plugin-unused-imports** | 使用されていない `import` を検出・削除（自動修正対応）してくれる。不要コード削減に有効。 |\n\n```bash\nnpm install -D \\\n  @typescript-eslint/eslint-plugin \\\n  @typescript-eslint/parser \\\n  @eslint/eslintrc \\\n  eslint-plugin-import \\\n  eslint-plugin-import-access \\\n  eslint-plugin-simple-import-sort \\\n  eslint-plugin-unused-imports\n```\n\n## eslint.config.mjsの設定\n\ncreate-next-app時にeslintを追加した場合，自動で`.eslintrc.json`が作成されます．ただしjsonで書く場合柔軟性がなくなるので，代わりにフラット構成(`eslint.config.mjs`)で使うべきです．\n\n```js\n// /eslint.config.mjs\nimport { fixupConfigRules, fixupPluginRules } from \"@eslint/compat\";\nimport { FlatCompat } from \"@eslint/eslintrc\";\nimport js from \"@eslint/js\";\nimport typescriptEslint from \"@typescript-eslint/eslint-plugin\";\nimport tsParser from \"@typescript-eslint/parser\";\nimport importAccess from \"eslint-plugin-import-access/flat-config\";\nimport simpleImportSort from \"eslint-plugin-simple-import-sort\";\nimport unusedImports from \"eslint-plugin-unused-imports\";\nimport path from \"node:path\";\nimport { fileURLToPath } from \"node:url\";\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\n\nconst compat = new FlatCompat({\n  baseDirectory: __dirname,\n  recommendedConfig: js.configs.recommended,\n  allConfig: js.configs.all,\n});\n\nexport default [\n  {\n    ignores: [\"coverage\", \".next\", \"*.config.mjs\", \"components/ui/**/*\"],\n  },\n  ...fixupConfigRules(\n    compat.extends(\n      \"plugin:@typescript-eslint/recommended\",\n      \"next/core-web-vitals\",\n      \"plugin:import/recommended\",\n      \"plugin:import/warnings\",\n    ),\n  ),\n  {\n    plugins: {\n      \"@typescript-eslint\": fixupPluginRules(typescriptEslint),\n      \"simple-import-sort\": simpleImportSort,\n      \"unused-imports\": unusedImports,\n      \"import-access\": importAccess,\n    },\n    languageOptions: {\n      parser: tsParser,\n      ecmaVersion: \"latest\",\n      sourceType: \"module\",\n      parserOptions: {\n        project: \"./tsconfig.json\",\n        tsconfigRootDir: __dirname,\n      },\n    },\n    rules: {\n      \"@typescript-eslint/naming-convention\": [\n        \"error\",\n        {\n          selector: \"variable\",\n          types: [\"array\", \"boolean\", \"number\", \"string\"],\n          format: [\"strictCamelCase\", \"UPPER_CASE\"],\n        },\n        {\n          selector: \"variable\",\n          types: [\"function\"],\n          format: [\"strictCamelCase\", \"StrictPascalCase\"],\n        },\n      ],\n      \"simple-import-sort/imports\": \"error\",\n      \"simple-import-sort/exports\": \"error\",\n      \"import/first\": \"error\",\n      \"import/newline-after-import\": \"error\",\n      \"import/no-duplicates\": \"error\",\n      \"@typescript-eslint/consistent-type-exports\": \"error\",\n      \"import/group-exports\": \"error\",\n      \"unused-imports/no-unused-imports\": \"error\",\n      \"import-access/jsdoc\": [\"error\"],\n      \"no-restricted-imports\": [\n        \"error\",\n        {\n          paths: [\n            \"sonner\",\n            \"next/link\",\n            \"react-icons\",\n            \"lucide-react\",\n            \"zod\",\n            { name: \"@/components/ui/Form\", importNames: [\"Form\"] },\n            {\n              name: \"@next/third-parties/google\",\n              importNames: [\"sendGAEvent\"],\n            },\n          ],\n          patterns: [\"react-icons/*\"],\n        },\n      ],\n      \"no-restricted-syntax\": [\n        \"error\",\n        {\n          selector:\n            \"CallExpression[callee.object.name='Object'][callee.property.name='keys']\",\n          message:\n            \"Do not use Object.keys. Check src/utils/object.ts or add a new utility function.\",\n        },\n      ],\n      \"@typescript-eslint/no-unused-vars\": \"off\",\n      \"@typescript-eslint/no-unnecessary-type-assertion\": \"error\",\n    },\n  },\n  {\n    files: [\n      \"src/**/*.stories.tsx\",\n      \"src/**/*Type.ts\",\n      \"src/types/**\",\n      \"src/features/**/*Repository.ts\",\n      \"src/features/**/*Converter.ts\",\n      \"src/features/**/*Constants.ts\",\n    ],\n    rules: {\n      \"import/group-exports\": \"off\",\n    },\n  },\n  {\n    files: [\"components/icons/**/*.{ts,tsx}\"],\n    rules: {\n      \"no-restricted-imports\": \"off\",\n    },\n  },\n];\n```\n\n### コードの解説\n\n**1. モジュールのインポート部**\n\n```js\nimport { fixupConfigRules, fixupPluginRules } from \"@eslint/compat\";\nimport { FlatCompat } from \"@eslint/eslintrc\";\nimport js from \"@eslint/js\";\nimport typescriptEslint from \"@typescript-eslint/eslint-plugin\";\nimport tsParser from \"@typescript-eslint/parser\";\nimport importAccess from \"eslint-plugin-import-access/flat-config\";\nimport simpleImportSort from \"eslint-plugin-simple-import-sort\";\nimport unusedImports from \"eslint-plugin-unused-imports\";\nimport path from \"node:path\";\nimport { fileURLToPath } from \"node:url\";\n```\n\n| 行                                        | 内容                                                                             |\n| ----------------------------------------- | -------------------------------------------------------------------------------- |\n| `@eslint/compat`                          | `.eslintrc` スタイルの設定（extends 等）をフラット構成用に変換するためのヘルパー |\n| `FlatCompat`                              | ↑の変換を実際に行うクラス。`plugin:xxx/recommended` などを使いたいときに必要     |\n| `@eslint/js`                              | ESLint公式の `recommended` 設定セット（ESLintが提供する基本ルール）              |\n| `@typescript-eslint/*`                    | TypeScriptのルール定義とパーサ。TS対応には必須                                   |\n| `eslint-plugin-import-access/flat-config` | import制限をJSDocに基づいて行うためのプラグイン（※フラット構成対応の入口）       |\n| その他のプラグイン                        | `simple-import-sort`, `unused-imports` → import順や未使用importの整理用          |\n| `path`, `fileURLToPath`                   | `__dirname` をESM形式で取得するための処理（Node.js ESMの都合）                   |\n\n**2. `__dirname` & `FlatCompat` の準備**\n\n```js\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\n\nconst compat = new FlatCompat({\n  baseDirectory: __dirname,\n  recommendedConfig: js.configs.recommended,\n  allConfig: js.configs.all,\n});\n```\n\n| 行                        | 内容                                                                                                                 |\n| ------------------------- | -------------------------------------------------------------------------------------------------------------------- |\n| `__filename`, `__dirname` | CommonJSにないESM形式でのファイルパス取得                                                                            |\n| `FlatCompat(...)`         | `.eslintrc`で書かれたような設定（例: `\"plugin:@typescript-eslint/recommended\"`）をフラット構成でも使えるよう変換する |\n\n**3. エクスポートされる ESLint 設定本体**\n\n```js\nexport default [\n  ...\n];\n```\n\n**4. 無視ファイルの指定**\n\n```js\n{\n  ignores: [\n    \"coverage\",\n    \".next\",\n    \"*.config.mjs\",\n    \"components/ui/**/*\",\n  ],\n},\n```\n\n- ESLintがチェック対象から除外するファイルやフォルダを定義\n- `*.config.mjs`なども解析しないよう除外している（誤検出防止）\n\n**5. 従来の extends をそのまま使う（変換）**\n\n```js\n...fixupConfigRules(\n  compat.extends(\n    \"plugin:@typescript-eslint/recommended\",\n    \"next/core-web-vitals\",\n    \"plugin:import/recommended\",\n    \"plugin:import/warnings\",\n  )\n),\n```\n\n- `compat.extends(...)`：`.eslintrc`スタイルの `\"extends\"` を使えるように変換\n- `fixupConfigRules(...)`：ルールにプラグイン名を正しくプレフィックスしてくれる（例: `\"@typescript-eslint/no-unused-vars\"` に直してくれる）\n\n**6. メイン設定ブロック（ルール、プラグインなど）**\n\n```js\n{\n  plugins: {\n    \"@typescript-eslint\": fixupPluginRules(typescriptEslint),\n    \"simple-import-sort\": simpleImportSort,\n    \"unused-imports\": unusedImports,\n    \"import-access\": importAccess,\n  },\n  ...\n}\n```\n\n| セクション              | 内容                                                                   |\n| ----------------------- | ---------------------------------------------------------------------- |\n| `plugins`               | 使用するプラグインを ESLint に明示的に登録                             |\n| `fixupPluginRules(...)` | `@typescript-eslint` のルールを正しく使える形に整形                    |\n| `languageOptions`       | ECMAScriptやモジュール種別（ESM）、TypeScriptのパーサ情報              |\n| `parserOptions`         | `tsconfig.json` の場所を ESLint に教える（型情報を使いたいときに重要） |\n\n**7. ルール設定（重要）**\n\n```js\nrules: {\n  \"@typescript-eslint/naming-convention\": [...],\n  \"simple-import-sort/imports\": \"error\",\n  \"simple-import-sort/exports\": \"error\",\n  ...\n}\n```\n\n| ルール名                           | 内容                                                                 |\n| ---------------------------------- | -------------------------------------------------------------------- |\n| `naming-convention`                | 変数名の形式を強制（camelCase, PascalCase など）                     |\n| `simple-import-sort/*`             | import/export 文を自動でソート                                       |\n| `unused-imports/no-unused-imports` | 未使用の import をエラーに                                           |\n| `import/first`                     | import文はファイルの先頭に書け                                       |\n| `import/no-duplicates`             | 同じモジュールを複数回 import するな                                 |\n| `import/group-exports`             | export はまとめて書け（バラバラに書かない）                          |\n| `import-access/jsdoc`              | JSDocコメントに従って層間importを制限（例: infra → domain 禁止など） |\n| `no-restricted-imports`            | 特定のモジュールやimport名を禁止（使ってほしくないライブラリなど）   |\n| `no-restricted-syntax`             | 特定の構文（例: `Object.keys`）の使用を禁止し、独自実装を促す        |\n\n**8. 特定ファイルへのルール適用除外**\n\n```js\n{\n  files: [...],\n  rules: {\n    \"import/group-exports\": \"off\",\n  },\n},\n{\n  files: [\"components/icons/**/*.{ts,tsx}\"],\n  rules: {\n    \"no-restricted-imports\": \"off\",\n  },\n},\n```\n\n- 特定のファイルパターン（例: `*.stories.tsx`, `*Type.ts`）にだけルールを変更\n- `group-exports`を無効にすることで、柔軟にexport可能にしている\n\n# tailwindの設定\n\nTailwind CSS は通常の CSS や JS 文法とは違う「ユーティリティクラスを文字列で書くスタイル」なので，エラーチェックや構文チェックができません．そのためこれらの設定をeslintに追加していきます\n\n## npm の追加\n\n```bash\nnpm install -D eslint-plugin-readable-tailwind\n```\n\n## eslint.config.mjsの設定\n\n### import\n\n```js\nimport readableTailwind from \"eslint-plugin-readable-tailwind\";\n```\n\n### `ignores`に追記\n\n```js\n  {\n    ignores: [\n      \"coverage\",\n      \".next\",\n      \"*.config.mjs\",\n      \"tailwind.config.ts\",  // ←追加\n      \"components/ui/**/*\",\n    ],\n  },\n```\n\n### `compat.extends(...)` に追記\n\n```js\n...fixupConfigRules(\n  compat.extends(\n    \"plugin:@typescript-eslint/recommended\",\n    \"plugin:import/recommended\",\n    \"plugin:import/warnings\",\n    \"plugin:tailwindcss/recommended\", // ←追加\n  )\n),\n```\n\n### `plugins`に追加\n\n```js\nplugins: {\n  \"@typescript-eslint\": fixupPluginRules(typescriptEslint),\n  \"simple-import-sort\": simpleImportSort,\n  \"unused-imports\": unusedImports,\n  \"import-access\": importAccess,\n  \"readable-tailwind\": readableTailwind, // ←追加\n},\n```\n\n### Tailwindの `settings`（`cn()` など補完関数を解析させたい場合）\n\n```js\nsettings: {\n  tailwindcss: {\n    callees: [\"cn\", \"cva\"], // `cn()` や `cva()` の中のclass名もチェック対象に\n  },\n},\n```\n\n### `rules`を追加\n\n```js\n      \"tailwindcss/no-custom-classname\": [\n        \"error\",\n        {\n          classRegex:\n            \"^(class(Name)?|textClassName|iconClassName|innerClassName)$\",\n          whitelist: [\"^[A-Z].*\"],\n        },\n      ],\n      \"readable-tailwind/multiline\": [\n        \"warn\",\n        {\n          group: \"newLine\",\n        },\n      ],\n```\n\n- `no-custom-classname`：カスタムクラスの混入を制限\n- `readable-tailwind/multiline`: Tailwindクラスを折り返して可読性を高める（複数行に分ける）\n\n## tailwind.config.tsの設定\n\nなぜかスタイリングされないといった事象が発生した場合，このファイルを確認することをお勧めします．\n\n```ts\n  content: [\n    \"./pages/**/*.{js,ts,jsx,tsx,mdx}\",\n    \"./components/**/*.{js,ts,jsx,tsx,mdx}\",\n    \"./app/**/*.{js,ts,jsx,tsx,mdx}\",\n    \"./features/**/*.{js,ts,jsx,tsx,mdx}\",\n  ],\n```\n\nコンポーネントの場所が設定されていない可能性があります．\n\n# prettierの設定\n\nPrettierはコード整形を自動で揃えるフォーマッタです．eslintも一部はコード整形を行いますが，これはより拡張的です．\n\n## eslint.config.mjsの設定\n\n### ライブラリの追加\n\n```bash\nnpm install -D \\\n  prettier \\\n  prettier-plugin-tailwindcss \\\n  eslint-config-prettier\n```\n\n<blockquote>\n※ eslint-plugin-prettier を使いたい場合は、最後に以下を追加：\n\n```bash\nnpm install -D eslint-plugin-prettier\n```\n\n</blockquote>\n\n| ライブラリ名                  | 役割・説明                                                                                                         |\n| ----------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n| `prettier`                    | コード整形本体。インデントや改行、スペースなどのスタイルを一貫して整える。                                         |\n| `prettier-plugin-tailwindcss` | Tailwindのユーティリティクラスを自動で**推奨順に並べ替える**Prettierプラグイン。                                   |\n| `eslint-config-prettier`      | ESLintの整形系ルールとPrettierのルールが競合しないように、ESLint側の整形ルールを無効化する。                       |\n| `eslint-plugin-prettier`      | Prettierの整形ルール違反を**ESLintの警告として表示する**ためのプラグイン（VSCodeで保存時整形する場合は省略可能）。 |\n\n### `compat.extends(...)` に追記\n\n```js\n...fixupConfigRules(\n  compat.extends(\n    \"plugin:@typescript-eslint/recommended\",\n    \"plugin:import/recommended\",\n    \"plugin:import/warnings\",\n    \"plugin:tailwindcss/recommended\",\n    \"prettier\", // ←追加\n  )\n),\n```\n\n# vscodeの設定\n\nプロジェクトに`.vscode`ディレクトリを配置し，その中にjsonファイルを配置するとvscode専用のプロジェクトごとのエディタ設定を置くことができます．\n\n## 使えるファイル\n\n| ファイル名        | 用途・できること                                               |\n| ----------------- | -------------------------------------------------------------- |\n| `settings.json`   | エディタの動作や拡張機能の設定（保存時整形、インデント幅など） |\n| `extensions.json` | 推奨拡張機能の一覧（プロジェクト参加者に自動で通知される）     |\n| `launch.json`     | デバッガーの設定（Node.jsやChromeのステップ実行など）          |\n| `tasks.json`      | ターミナルで実行するタスクを定義（ビルド・lint・test など）    |\n\n## settings.jsonの設定\n\nここではeslintやprettier関連の設定をし，ファイル保存時に自動で整形が走るようにします．\n\n```json\n{\n  \"editor.formatOnSave\": true,\n  \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll\": \"explicit\",\n    \"source.fixAll.eslint\": \"explicit\",\n    \"source.organizeImports\": \"explicit\"\n  },\n  \"typescript.preferences.importModuleSpecifier\": \"non-relative\",\n  \"typescript.tsdk\": \"node_modules/typescript/lib\",\n  \"tailwindCSS.classAttributes\": [\"class\", \"className\", \".*Class\"],\n  \"tailwindCSS.experimental.classRegex\": [\n    [\"cva\\\\(([^)]*)\\\\)\", \"[\\\"'`]([^\\\"'`]*).*?[\\\"'`]\"],\n    [\"cn\\\\(([^)]*)\\\\)\", \"[\\\"'`]([^\\\"'`]*).*?[\\\"'`]\"],\n    [\"cx\\\\(([^)]*)\\\\)\", \"(?:'|\\\"|`)([^']*)(?:'|\\\"|`)\"]\n  ]\n}\n```\n\n| 設定キー                                            | 内容・説明                                                                              |\n| --------------------------------------------------- | --------------------------------------------------------------------------------------- |\n| `\"editor.formatOnSave\"`                             | ファイル保存時に自動でコード整形（Prettierなどが有効になる）                            |\n| `\"editor.defaultFormatter\"`                         | Prettier拡張機能（`esbenp.prettier-vscode`）を整形エンジンとして使用                    |\n| `\"editor.codeActionsOnSave.source.fixAll\"`          | 明示的に保存したときのみ、すべての問題（Lint等）を一括修正                              |\n| `\"editor.codeActionsOnSave.source.fixAll.eslint\"`   | 明示的に保存したときのみ、ESLintの警告・エラーを自動修正                                |\n| `\"editor.codeActionsOnSave.source.organizeImports\"` | 明示的に保存したときのみ、不要なimport削除＆並び替え                                    |\n| `\"typescript.preferences.importModuleSpecifier\"`    | TypeScriptのimport補完を相対パスではなく絶対パス（非相対）にする                        |\n| `\"typescript.tsdk\"`                                 | VSCodeが使用するTypeScriptバージョンをプロジェクト内の `node_modules/typescript` に固定 |\n| `\"tailwindCSS.classAttributes\"`                     | Tailwindの補完対象となる属性名（`class`, `className`, `iconClassName`など）を指定       |\n| `\"tailwindCSS.experimental.classRegex\"`             | `cn()`, `cva()`, `cx()` のような関数内でもTailwindクラスを認識させる正規表現設定        |\n\n## extensions.jsonの設定\n\nプロジェクトで使うべき VSCode 拡張機能のおすすめ一覧を示し，プロジェクトに適用することができます．\n\n```json\n{\n  \"recommendations\": [\n    \"dbaeumer.vscode-eslint\", // ESLintのエラー表示・自動修正を有効にする拡張\n    \"esbenp.prettier-vscode\", // Prettierで保存時整形をする拡張\n    \"bradlc.vscode-tailwindcss\" // Tailwindクラスの補完・色表示をしてくれる拡張\n  ]\n}\n```\n\n# まとめ\n\n以上のことをすると構文チェックができ，ファイル保存時に自動でフォーマッティングされます．すごく頼もしいです．\n",
    "createdAt": "2025-07-21T07:23:48.458Z",
    "updatedAt": "2025-07-21T07:23:48.458Z"
  },
  {
    "title": "Next.jsとRailsで作るwebアプリ",
    "summary": "Next.jsとRailsでapi開発の勉強をしたのでここにメモしておきます",
    "tags": [
      "Next.js",
      "webアプリ開発",
      "Ruby on Rails",
      "API"
    ],
    "slug": "Next.js/next-rails-tutorial",
    "folder": "Next.js",
    "content": "\n# バックエンド\n\n## railsプロジェクト作成\n\n---\n\n```bash\nrails new blog_api --api -T\n```\n\n`--api`とすることで，viewなどの余計なファイルの作成がされなくなります．また，`-T`とすると，テスト用のファイルが生成されなくなります．\n\n## gemの追加\n\n---\n\n```ruby\n# Gemfile\n  gem 'rack-cors', require: 'rack/cors'\n```\n\nNext.jsアプリのリクエストを受け付ける際にcorsの設定をする必要があるので，`rack-cors`のgemを追加します．その後，`bundle install`することを忘れないようにしましょう\n\n## rack-corsの設定\n\n---\n\nここで許可するオリジンを設定しておきましょう\n\n```ruby\n# config/initializers/cors.rb\nRails.application.config.middleware.insert_before 0, Rack::Cors do\n  allow do\n    origins \"http://localhost:3000\"\n\n    resource \"*\",\n      headers: :any,\n      methods: [:get, :post, :put, :patch, :delete, :options, :head]\n  end\nend\n```\n\n## モデル作成\n\n---\n\nデータベースに登録したいテーブルのモデルを作ります．\n\n```bash\nrails generate model Post title:string content:text\n```\n\nこの場合，dbには`posts`というテーブルが追加されることになります．\n\n### 作成されるファイル\n\n#### **マイグレーションファイル**\n\nデータベースのテーブルを作成するためのファイル．`rails db:migrate`をするとはじめて実行される\n\n```ruby\n# db/migrate/20250209064827_create_posts.rb\nclass CreatePosts < ActiveRecord::Migration[7.2]\n  def change\n    create_table :posts do |t|\n      t.string :title\n      t.text :content\n\n      t.timestamps\n    end\n  end\nend\n```\n\n> モデルは単数形で一文字目が大文字，テーブルは複数形で全て小文字で記述するのが慣習\n\n#### **モデルファイル**\n\nここに記述されたクラスを用いて，コントローラなどでデータベースの操作を行う．バリデーションやアソシエーションなどを記述することも可能\n\n```ruby\n# app/models/post.rb\nclass Post < ApplicationRecord\nend\n```\n\n#### **テストファイル**\n\n今回は`rails new blog_api --api -T`で`-T`オプションを指定しているため，テストファイルは作成されない\n\n#### **シードファイル**\n\nなにも書かれていないが，特にシードデータを追加する必要があれば，`Post.create`を使って初期データを登録することも可能\n\n## マイグレーション\n\n---\n\n```bash\nrails db:migrate\n```\n\n> `db/schema.rb`にデータベースのスキーマが記述される\n\n## コントローラ作成\n\n---\n\nコントローラは，ユーザからのリクエストを受け取り，適切な処理を行い，レスポンスを返す役割を持ちます．それぞれのコントローラはルーティングを設定することによりリクエストが可能になります．\n\n> **MVCモデルとは**\\\n> ソフトウェアアーキテクチャの一つ．アプリケーションの構造をmodel, view, controllerの3つに分けることで，コードの整理や保守性を向上させることができる．\n\n### コントローラ作成\n\n```bash\nrails generate controller Api::v1::Posts index show create update destroy\n```\n\n> コントローラの設定を間違えた場合，`rails destroy controller Api::v1::Posts`で削除できる\n\n#### **作成されるファイル**\n\n##### **コントローラファイル**\n\nコントローラの処理を記述するファイル．`render`メソッドでレスポンスを返す．以下のように記述することで，json形式でデータを返すことができます．\n\n今回は，**投稿一覧**，**特定の投稿**が取得できるコントローラ，投稿内容を**作成**，**編集**，**削除**できるコントローラを作っていきます\n\n```ruby\n# app/controllers/api/v1/posts_controller.rb\nclass Api::V1::PostsController < ApplicationController\n  def index\n    @posts = Post.all\n\n    render json: @posts\n  end\n\n  def show\n    @post = Post.find(params[:id])\n\n    render json: @post\n  end\n\n  def create\n    @post = Post.new(post_params)\n\n    if @post.save\n      render json: @post, status: :created\n    else\n      render json: @post.errors, status: :unprocessable_entity\n    end\n  end\n\n  def update\n    @post = Post.find(params[:id])\n\n    if @post.update(post_params)\n      render json: @post\n    else\n      render json: @post.errors, status: :unprocessable_entity\n    end\n  end\n\n  def destroy\n    @post = Post.find(params[:id])\n\n    @post.destroy\n  end\n\n  private\n\n  def post_params\n    params.require(:post).permit(:title, :content)\n  end\nend\n```\n\n> `@`がついている変数はインスタンス変数．`:`がついている変数はシンボル．文字列の皮をかぶった整数値 \\\n> `status: :unprocessable_entity`は辞書 \\\n> `params` は Rails がリクエストのデータを自動でセットしてくれるオブジェクト\n\n##### **ルーティング**\n\n基本は既に設定されている．`config/routes.rb`で管理をしている\n\n```ruby\n# config/routes.rb\n\nRails.application.routes.draw do\n  namespace :api do\n    namespace :v1 do\n      resources :posts, only: [:index, :show, :create, :update, :destroy]\n    end\n  end\n  # Define your application routes per the DSL in https://guides.rubyonrails.org/routing.html\n\n  # Reveal health status on /up that returns 200 if the app boots with no exceptions, otherwise 500.\n  # Can be used by load balancers and uptime monitors to verify that the app is live.\n  get \"up\" => \"rails/health#show\", as: :rails_health_check\n\n  # Defines the root path route (\"/\")\n  # root \"posts#index\"\nend\n```\n\n> `resources :posts, only: [:index, :show, :create, :update, :destroy]` とすると，これらは暗黙的に以下のルーティングが設定される\n> | HTTPメソッド | パス | コントローラ#アクション | 用途 |\n> | --- | --- | --- | --- |\n> | GET | /posts | posts#index | 一覧表示 |\n> | GET | /posts/:id | posts#show | 詳細表示 |\n> | POST | /posts | posts#create | 作成 |\n> | PUT | /posts/:id | posts#update | 更新 |\n> | DELETE | /posts/:id | posts#destroy | 削除 |\n>\n> これを各コントローラごとに設定することでrestfulなAPIを作成することができる\n\n### テスト\n\npostmanやcurlコマンドを使ってAPIのテストを行う\n\n```bash\ncurl -X POST -H \"Content-Type: application/json\" -d '{\"post\": {\"title\": \"初めての投稿です\", \"content\": \"初めての投稿です\"}}' http://localhost:3000/api/v1/posts\ncurl -X POST -H \"Content-Type: application/json\" -d '{\"post\": {\"title\": \"2つ目の投稿です\", \"content\": \"2つ目の投稿です\"}}' http://localhost:3000/api/v1/posts\n\ncurl http://localhost:3000/api/v1/posts\ncurl http://localhost:3000/api/v1/posts/1\ncurl http://localhost:3000/api/v1/posts/2\n\ncurl -X PUT -H \"Content-Type: application/json\" -d '{\"post\": {\"title\": \"初めての投稿を更新しました\", \"content\": \"初めての投稿を更新しました\"}}' http://localhost:3000/api/v1/posts/1\ncurl -X PUT -H \"Content-Type: application/json\" -d '{\"post\": {\"title\": \"2つ目の投稿を更新しました\", \"content\": \"2つ目の投稿を更新しました\"}}' http://localhost:3000/api/v1/posts/2\n\ncurl -X DELETE http://localhost:3000/api/v1/posts/1\ncurl -X DELETE http://localhost:3000/api/v1/posts/2\n```\n\n## ポート番号の変更\n\n```bash\nrails s -p 3001\n```\n\n> 永続的に変更する場合は`config/puma.rb`を変更する\n\n# フロントエンド\n\nNext.js typescript App router, TailwindCSSを使っていきます．\n\n## プロジェクト作成\n\n---\n\n```bash\nnpx create-next-app blog_client\n```\n\n## 各種コンポーネントの作成\n\n---\n\n### 型定義ファイル\n\nバックエンド開発時に作ったモデルのスキーマと同じにすると良いです．\n\n```typescript\nexport type Post = {\n  id: number;\n  title: string;\n  content: string;\n  created_at: string;\n  updated_at: string;\n};\n```\n\n### 投稿一覧ページ\n\n#### **一覧ページ**\n\n一覧ページでは，`http://localhost:3000/api/v1/posts`にアクセスすることで，すべての投稿を取得します．各投稿には編集ボタンと削除ボタンを用意し，投稿作成ボタンも用意します．\n\n基本的にはSSRで実装していきますが，フォームなどはクライアント側で処理しないといけないので，それらは別途クライアントコンポーネントとして作成していきます．\n\n> **SSRとは**\\\n> サーバサイドレンダリングの意．クライアント側ではなくサーバ側で処理を済ますので負荷がかかりにくくセキュリティ面においても安全．\n\n```tsx\n// app/page.tsx\nimport { Post } from \"@/lib/types\";\nimport Link from \"next/link\";\nimport { DeletePost } from \"./_components/delete-post\";\n\nexport default async function Home() {\n  const res = await fetch(\"http://localhost:3001/api/v1/posts\", {\n    method: \"GET\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n  });\n  const posts: Post[] = await res.json();\n\n  return (\n    <div className=\"container mx-auto p-4 flex flex-col items-center\">\n      <h2 className=\"text-2xl font-bold mb-4\">Rails & Next.js Blog</h2>\n\n      <Link\n        href=\"/create-post\"\n        className=\"text-blue-500 hover:text-blue-700 mb-4\"\n      >\n        Create new Post\n      </Link>\n\n      <div className=\"mt-6 w-full max-w-2xl\">\n        {posts.map((post) => (\n          <div\n            key={post.id}\n            className=\"border border-gray-300 rounded-lg p-4 mb-4 shadow-md\"\n          >\n            <Link\n              href={`posts/${post.id}`}\n              className=\"text-xl font-semibold text-blue-600 hover:text-blue-800\"\n            >\n              {post.title}\n            </Link>\n\n            <p className=\"text-gray-700 mt-2\">{post.content}</p>\n\n            <div className=\"flex justify-end mt-4\">\n              <Link\n                href={`posts/${post.id}/edit-post`}\n                className=\"text-sm text-white bg-blue-500 hover:bg-blue-700 py-1 px-2 rounded mr-2\"\n              >\n                Edit\n              </Link>\n\n              <DeletePost id={post.id} />\n            </div>\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n}\n```\n\n#### **削除コンポーネント**\n\nこちらはonClickをクライアント側で発火させなければならないため，`use client`を追加し，クライアントコンポーネントにします．\n\n```tsx\n// app/_components/delete-post.tsx\n\"use client\";\n\nexport const DeletePost = ({ id }: { id: number }) => {\n  const handleDelete = async (id: number) => {\n    const res = await fetch(`http://localhost:3001/api/v1/posts/${id}`, {\n      method: \"DELETE\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n    });\n\n    if (res.ok) {\n      alert(\"Post deleted\");\n    } else {\n      alert(\"Failed to delete post\");\n    }\n  };\n\n  return (\n    <button\n      onClick={() => handleDelete(id)}\n      className=\"text-sm text-white bg-red-500 hover:bg-red-700 py-1 px-2 rounded\"\n    >\n      Delete\n    </button>\n  );\n};\n```\n\n### 投稿詳細ページ\n\nこちらでは，動的ルーティングを用いてidを取得し，対象の投稿を取得して表示します．\n\n```tsx\n// app/posts/[id]/page.tsx\nimport { Post } from \"@/lib/types\";\nimport Link from \"next/link\";\n\nexport default async function PostPage({\n  params,\n}: {\n  params: Promise<{ id: string }>;\n}) {\n  const { id } = await params;\n  const res = await fetch(`http://localhost:3001/api/v1/posts/${id}`, {\n    method: \"GET\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n  });\n\n  const post: Post = await res.json();\n\n  return (\n    <div className=\"container mx-auto p-4 flex flex-col items-center\">\n      <div className=\"w-full max-w-2xl p-4\">\n        <h1 className=\"text-3xl font-bold mb-4\">{post.title}</h1>\n        <div className=\"text-gray-500 mb-4\">{post.created_at}</div>\n        <p className=\"text-gray-700\">{post.content}</p>\n        <Link href=\"/\" className=\"text-blue-500 hover:text-blue-700\">\n          投稿一覧に戻る\n        </Link>\n      </div>\n    </div>\n  );\n}\n```\n\n### 投稿作成ページ\n\nこちらは，クライアント側がフォームを編集しなければならないので，クライアントコンポーネントにします．\n\n```tsx\n// app/create-post/page.tsx\n\"use client\";\n\nimport Link from \"next/link\";\nimport { redirect } from \"next/navigation\";\n\nexport default function CreatePage() {\n  const handleSubmit = async (e: React.FormEvent<HTMLFormElement>) => {\n    e.preventDefault();\n\n    const formData = new FormData(e.currentTarget);\n    const title = formData.get(\"title\") as string;\n    const content = formData.get(\"content\") as string;\n\n    const res = await fetch(\"http://localhost:3001/api/v1/posts\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify({\n        title: title,\n        content: content,\n      }),\n    });\n\n    if (res.ok) {\n      redirect(\"/\");\n    } else {\n      alert(\"Failed to create post\");\n    }\n  };\n\n  return (\n    <div className=\"container mx-auto p-4 flex flex-col items-center\">\n      <div className=\"w-full max-w-2xl\">\n        <h1 className=\"text-3xl font-bold mb-6\">ブログ新規登録</h1>\n\n        <form className=\"w-full\" onSubmit={handleSubmit}>\n          <div className=\"mb-4\">\n            <label className=\"block text-gray-700 text-sm font-bold mb-2\">\n              タイトル\n            </label>\n            <input\n              name=\"title\"\n              type=\"text\"\n              className=\"shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline\"\n            />\n          </div>\n\n          <div className=\"mb-6\">\n            <label className=\"block text-gray-700 text-sm font-bold mb-2\">\n              本文\n            </label>\n            <textarea\n              name=\"content\"\n              className=\"shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline\"\n            />\n          </div>\n\n          <div className=\"flex items-center justify-between\">\n            <button\n              type=\"submit\"\n              className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded focus:outline-none focus:shadow-outline\"\n            >\n              投稿\n            </button>\n            <Link href=\"/\" className=\"text-blue-500 hover:text-blue-700\">\n              キャンセル\n            </Link>\n          </div>\n        </form>\n      </div>\n    </div>\n  );\n}\n```\n\n### 投稿編集ページ\n\n#### **編集ページ**\n\nこちらは，パラメータを受け取るためにSSRし，編集ができるクライアントコンポーネントを渡しておきます\n\n```tsx\nimport { Post } from \"@/lib/types\";\nimport { EditForm } from \"./_components/form\";\n\nexport default async function EditPage({\n  params,\n}: {\n  params: Promise<{ id: string }>;\n}) {\n  const { id } = await params;\n  const res = await fetch(`http://localhost:3001/api/v1/posts/${id}`, {\n    method: \"GET\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n  });\n\n  const post: Post = await res.json();\n\n  return <EditForm post={post} />;\n}\n```\n\n#### **編集フォーム**\n\n```tsx\n\"use client\";\n\nimport { Post } from \"@/lib/types\";\nimport Link from \"next/link\";\nimport { redirect } from \"next/navigation\";\n\nexport const EditForm = ({ post }: { post: Post }) => {\n  const handleSubmit = async (e: React.FormEvent<HTMLFormElement>) => {\n    e.preventDefault();\n\n    const formData = new FormData(e.currentTarget);\n    const title = formData.get(\"title\") as string;\n    const content = formData.get(\"content\") as string;\n\n    const res = await fetch(`http://localhost:3001/api/v1/posts/${post.id}`, {\n      method: \"PUT\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify({\n        title: title,\n        content: content,\n      }),\n    });\n\n    if (res.ok) {\n      redirect(`/posts/${post.id}`);\n    } else {\n      alert(\"Failed to update post\");\n    }\n  };\n\n  return (\n    <div className=\"container mx-auto p-4 flex flex-col items-center\">\n      <div className=\"w-full max-w-2xl\">\n        <h1 className=\"text-3xl font-bold mb-6\">ブログ編集</h1>\n\n        <form className=\"w-full\" onSubmit={handleSubmit}>\n          <div className=\"mb-4\">\n            <label className=\"block text-gray-700 text-sm font-bold mb-2\">\n              タイトル\n            </label>\n            <input\n              name=\"title\"\n              type=\"text\"\n              className=\"shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline\"\n              defaultValue={post.title}\n            />\n          </div>\n\n          <div className=\"mb-6\">\n            <label className=\"block text-gray-700 text-sm font-bold mb-2\">\n              本文\n            </label>\n            <textarea\n              name=\"content\"\n              className=\"shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline\"\n              defaultValue={post.content}\n            />\n          </div>\n\n          <div className=\"flex items-center justify-between\">\n            <button\n              type=\"submit\"\n              className=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded focus:outline-none focus:shadow-outline\"\n            >\n              更新\n            </button>\n            <Link\n              href={`/posts/${post.id}`}\n              className=\"text-blue-500 hover:text-blue-700\"\n            >\n              キャンセル\n            </Link>\n          </div>\n        </form>\n      </div>\n    </div>\n  );\n};\n```\n",
    "createdAt": "2025-07-21T07:23:48.458Z",
    "updatedAt": "2025-07-21T07:23:48.458Z"
  },
  {
    "title": "PCA解説",
    "summary": "PCAを一からまとめました！",
    "tags": [
      "PCA",
      "AI",
      "Machine Learning"
    ],
    "slug": "Generative-AI/PCA-explanation",
    "folder": "Generative-AI",
    "content": "\n# 教師なし学習とは\n\n---\n\n## 教師あり学習と比較\n\n1. 目的変数がない、入力データそのものに注目\n2. データの中に部分集合を見つけたり、データを変換して別の形式で表現したりすることでデータの解釈性を高める\n3. データに潜むパターンや示唆を見出すために用いる\n4. 教師なし学習モデルはクラスタリング、次元削減に大別できる\n\n## データサイエンスのプロセス\n\nOSEMN (オーサム) Process\n\n![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*eE8DP4biqtaIK3aIy1S2zA.png)\n\n[5 Steps of a Data Science Project Lifecycle](https://towardsdatascience.com/5-steps-of-a-data-science-project-lifecycle-26c50372b492)\n\n### OBTAIN (データの取得)\n\nデータを取得する。データは主にデータベース、`CSV`, `Web API`から取得できる\n\n### SCRUB\n\nデータを解釈するために整理する。\n\nデータには欠損値や、モデルに使用できない型になっているデータが存在する。また、(リレーショナル)データベースでは複数のテーブルが混在しており、データ分析がしにくい。列を分割、あるいは結合する必要がある。\n\npythonでは主に`pandas`を使う。\n\n### EXPLORE (データの探索)\n\nモデルに使うためのデータを探す。**機械なし学習はここで役立つ**。またpythonでは、`matplotlib`を用いてデータの可視化も行う。\n\nここではデータのメタ的な理解が必要。そのための探索、特徴量エンジニアリングを行う。\n\n### MODEL\n\n将来を予測するために**教師あり学習**を用いて機械学習モデルを作る。\n\n### INTERPRET\n\nデータを利用して価値を創出する。(稼ぐ)\n\n# PCAとは\n\n---\n\nPCA: Principal Component Analysis (主成分分析)\n\n## 次元削減\n\nより少ない特徴量でデータを理解するための手法。多変数データを特徴を保ちながら少変数で表現すること。\n\n機械学習において、特徴量は多すぎないほうが良い。データの解釈性を失う恐れがあるし、過学習が起こりやすい。さらに、処理スピードも遅くなる。それらを解決するために「特徴量を減らす=次元削減をする」\n\n## PCA概要\n\n変数間に相関のあるデータに対して有効。代表的な次元削減の手法。\n\n元データの変数から新たな変数を構成する。\nたいていの場合3次元以内に収める\n\n以下のサイトで視覚的に理解できる\n\n[Principal Component Analysis explained visually](https://setosa.io/ev/principal-component-analysis/)\n\n![a](https://newsatcl-pctr.c.yimg.jp/t/amd-img/20200202-00010000-wordleaf-000-8-view.jpg?pri=l&w=640&h=640&exp=10800&fmt=webp)\n\n## アルゴリズム\n\n### やること\n\n主成分における内積の分散が最大となるような主成分軸を見つける→基底変換\n\n→基底を変換したいので変換行列が必要、最適な変換行列を求める\n\n![output.png](output.png)\n\n$$\ni番目のp次元ベクトルx_{i*}が(x_{i1},x_{i2},...,x_{ip})^Tのとき\n$$\n\n$$\nデータXを、\\mathbf X=\\begin{pmatrix}\nx_{11}&x_{12}&...&x_{1p}\\\\\nx_{21}&x_{22}&...&x_{2p}\\\\\n\\vdots&\\vdots&\\ddots&\\vdots&\\\\\nx_{n1}&x_{n2}&...&x_{np}\n\\end{pmatrix},\\quad\n\np次元からq次元に変換する変換行列を\\mathbf w=\\begin{pmatrix}\nw_{11}&w_{12}&...&w_{1q}\\\\\nw_{21}&w_{22}&...&w_{2q}\\\\\n\\vdots&\\vdots&\\ddots&\\vdots&\\\\\nw_{p1}&w_{p2}&...&w_{pq}\n\\end{pmatrix}とする。\n$$\n\n> 変換行列のそれぞれの列は基底ベクトルを表す\n\n$$\nこのとき、圧縮されたデータを\\mathbf Yとすると、\\mathbf Y=\\mathbf X\\mathbf wが成り立つ。次に、射影後のベクトルについて考える。\n$$\n\n$$\n元のデータベクトルx_{i*}を求めたい主成分の方向に射影した結果をy_i、この時の主成分をw=(w_1,w_2,...,w_p)^Tとすると、y_i=w^Tx_{i*}と表せる。\n$$\n\n![](https://math-negi.jp/wp-content/uploads/2021/10/20211028214521.png)\n\n> ベクトルの方向が近ければ近いほど、内積は大きくなる。その分内積の値のズレも大きくなる→その方向における内積の分散の最大値を求めれば主成分が決まるのでは？\n\n$$\nこのとき、分散s^2=\\frac{1}{n}\\sum_{i=1}^n(y_i-\\overline y)^2,\\quad 平均\\overline y=\\frac{1}{n}\\sum_{i=1}^ny_i=w_1\\overline {x_{*1}}+w_2\\overline {x_{*2}}+...+w_p\\overline {x_{*p}}=w^T(\\overline{x_{*1}},\\overline{x_{*2}},...,\\overline{x_{*p}})となるので、\\\\\n\ns^2=\\frac{1}{n}\\sum_{i=1}^n(w^T(x_{i1},x_{i2},...,x_{ip})-w^T(\\overline{x_{*1}},\\overline{x_{*2}},...,\\overline{x_{*p}}))^2\\\\=\n\n\\frac{1}{n}\\sum_{i=1}^n \\left\\{w\n\\begin{pmatrix}\nx_{i1}-\\overline{x_{*1}}\\\\\nx_{i2}-\\overline{x_{*2}}\\\\\n\\vdots\\\\\nx_{ip}-\\overline{x_{*p}}\n\\end{pmatrix}\\right\\}^2=\n\n\\frac{1}{n}\\sum_{i=1}^n w^T\n\\begin{pmatrix}\nx_{i1}-\\overline{x_{*1}}\\\\\nx_{i2}-\\overline{x_{*2}}\\\\\n\\vdots\\\\\nx_{ip}-\\overline{x_{*p}}\n\\end{pmatrix}\n\\begin{pmatrix}\nx_{i1}-\\overline{x_{*1}}\\\\\nx_{i2}-\\overline{x_{*2}}\\\\\n\\vdots\\\\\nx_{ip}-\\overline{x_{*p}}\n\\end{pmatrix}^Tw=\n\n w^T\n\\frac{1}{n}\\sum_{i=1}^n\n\\begin{pmatrix}\nx_{i1}-\\overline{x_{*1}}\\\\\nx_{i2}-\\overline{x_{*2}}\\\\\n\\vdots\\\\\nx_{ip}-\\overline{x_{*p}}\n\\end{pmatrix}\n\\begin{pmatrix}\nx_{i1}-\\overline{x_{*1}}\\\\\nx_{i2}-\\overline{x_{*2}}\\\\\n\\vdots\\\\\nx_{ip}-\\overline{x_{*p}}\n\\end{pmatrix}^Tw\n\n=w^TSw\\\\\n\n※共分散行列S=\\begin{pmatrix}\ns_{11}&s_{12}&...&s_{1p}\\\\\ns_{21}&s_{22}&...&s_{2p}\\\\\n\\vdots&\\vdots&\\ddots&\\vdots&\\\\\ns_{p1}&s_{p2}&...&s_{pp}\n\\end{pmatrix},\\quad s_{jk}=\\frac{1}{n}\\sum_{i=1}^n(x_{ij}-\\overline{x_{*j}})(x_{ik}-\\overline{x_{*k}})\n$$\n\n$$\nここでs^2=w^TSw\\quad (w^Tw=1)が最大値を取るときのwをラグランジュの未定乗数法で求める。\\\\\nf(w)=s^2=w^TSw,\\quad 制約：g(w)=w^Tw-1=0\\quad のもとで、ラグランジュ関数はF(w,\\lambda)=f(w)+\\lambda g(w)となる。\\\\(wはいくらでも大きくできてしまうので制約が必要)\n$$\n\n[ラグランジュの未定乗数法と例題 | 高校数学の美しい物語](https://manabitimes.jp/math/879)\n\n$$\ns^2が最大化するとき \\frac{\\partial}{\\partial w}F(w,\\lambda)=2Sw-2\\lambda w=0より、Sw=\\lambda w\n$$\n\n$$\nSw=\\lambda wは共分散行列の固有方程式を表している。ちなみに両辺にw^Tをかけると、w^TSw=w^T\\lambda w,\\quad 式変形していくと仮定よりw^TSw=\\lambda w^Tw=\\lambda=s^2\n$$\n\n$$\nしたがって固有値\\lambdaは分散そのものを表す。\\\\また、それぞれに対する固有ベクトルwは変換後の基底=主成分であり、求めたい変換行列\\mathbf wは\\begin{pmatrix}w_1&w_2&...&w_q\\end{pmatrix}となる。\n$$\n\n## 寄付率\n\n各成分ごとに計算される固有値を固有値の総和で割ると、主成分の重要度の割合で表現することができる。この時の割合を寄付率といい、各主成分がデータをどれぐらい説明しているかを表現している。\n\n$$\n第k主成分の寄付率=\\frac{\\lambda_k}{\\sum_{i=1}^n\\lambda_i}\n$$\n\n# pythonで実装してみる\n\n---\n\n## データを作る\n\n次に示すプログラムは、`RandomState`オブジェクトを使って、2変数のデータセットを生成し、各変数について標準化したものをプロットしたものである。\n\n```py\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\n# RandomStateオブジェクトを作成\nsample = np.random.RandomState(1)\n\n#２つの乱数を生成\nX = np.dot(sample.rand(2, 2), sample.randn(2, 200)).T\n\n# 標準化 (平均0, 分散1にする)\nsc = StandardScaler()\nX_std = sc.fit_transform(X)\n\n# 相関係数の算出とグラフ化\nprint('相関係数{:.3f}:'.format(sp.stats.pearsonr(X_std[:, 0], X_std[:, 1])[0]))\nplt.scatter(X_std[:, 0], X_std[:, 1])\n```\n\n## 主成分分析の実行\n\n```py\n# インポート\nfrom sklearn.decomposition import PCA\n\n# 主成分分析\npca = PCA(n_components=2) # 2次元に圧縮\npca.fit(X_std)\n```\n\n## 学習結果の確認\n\n### `components_`属性\n\n変換行列(固有ベクトル)を出力する\n\n```py\nprint(pca.components_)\n```\n\n### `explained_variance_`属性\n\n分散(固有値)を出力する\n\n```py\nprint('各主成分の分散:{}'.format(pca.explained_variance_))\n```\n\n## 結果を図示する\n\n```py\n# パラメータ設定\narrowprops=dict(arrowstyle='->',\n                linewidth=2,\n                shrinkA=0, shrinkB=0)\n\n# 矢印を描くための関数\ndef draw_vector(v0, v1): # v0: 先端, v1: 終端\n    plt.gca().annotate('', v1, v0, arrowprops=arrowprops)\n\n# 元のデータをプロット\nplt.scatter(X_std[:, 0], X_std[:, 1], alpha=0.2)\n\n# 主成分分析の2軸を矢印で表示する\nfor length, vector in zip(pca.explained_variance_, pca.components_): # zip(): forループの中で複数のリストを同時に取り出す\n    v = vector * 3 * np.sqrt(length)\n    draw_vector(pca.mean_, pca.mean_ + v) # 重心を起点とする\n\nplt.axis('equal')\n```\n\n# PCAを用いた乳がん患者予測\n\n---\n\n## ライブラリインポート\n\n```py\n# 乳がんデータを読み込むためのインポート\nfrom sklearn.datasets import load_breast_cancer\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\n```\n\n## 乳がんデータの取得\n\n```py\n# 乳がんデータの取得\ncancer = load_breast_cancer()\ncancer\n```\n\n## pandas dataframeで整理\n\n```py\ndf = pd.DataFrame(cancer.data, columns=cancer.feature_names)\ndf[\"target\"] = cancer.target\ndf\n```\n\n欠損値などはありませんでした。\n\n## 説明変数と目的変数の関係をヒストグラムにしてみる\n\n### データをmalignant (悪性)かbenign (良性)に分けるためのフィルター処理\n\n```py\nmalignant = df[df[\"target\"] == 0]\nbenign = df[df[\"target\"] == 1]\n```\n\n### 30個のヒストグラムを作る\n\n```py\n#　malignant（悪性）がブルー、benign（良性）がオレンジのヒストグラム\n# 各図は、各々の説明変数（mean radiusなど）と目的変数との関係を示したヒストグラム\nfig, axes = plt.subplots(6,5,figsize=(20,20))\nax = axes.ravel()\nfor i, column in enumerate(df.columns[:-1]):\n    _,bins = np.histogram(df[column], bins=50)\n    ax[i].hist(malignant[column], bins, alpha=.5)\n    ax[i].hist(benign[column], bins, alpha=.5)\n    ax[i].set_title(column)\n    ax[i].set_yticks(())\n\n# ラベルの設定\nax[0].set_ylabel('Count')\nax[0].legend(['malignant','benign'],loc='best')\nfig.tight_layout()\n```\n\nしかし特徴的なデータは見当たらないので、主成分分析を用いて次元削減を行ってみる\n\n## PCAで次元削減\n\n```py\n# 標準化\nsc = StandardScaler()\nX_std = sc.fit_transform(cancer.data)\n\n# 主成分分析\npca = PCA(n_components=2)\npca.fit(X_std)\nX_pca = pca.transform(X_std)\n\n# 表示\nprint('X_pca shape:{}'.format(X_pca.shape))\nprint('Explained variance ratio:{}'.format(pca.explained_variance_ratio_))\n```\n\nX_pcaは569行2列に変換された→569個の二次元ベクトルの集合\n\n## 圧縮データの可視化\n\n### DF作成\n\n```py\n# 列にラベルをつける、1つ目が第1主成分、2つ目が第2主成分\nX_pca = pd.DataFrame(X_pca, columns=['pc1','pc2'])\n\n# 上のデータに、目的変数（cancer.target）を紐づける、横に結合\nX_pca = pd.concat([X_pca, pd.DataFrame(cancer.target, columns=['target'])], axis=1)\n\n# 悪性、良性を分ける\npca_malignant = X_pca[X_pca['target']==0]\npca_benign = X_pca[X_pca['target']==1]\n```\n\n### 可視化\n\n```py\n# 悪性をプロット\nax = pca_malignant.plot.scatter(x='pc1', y='pc2', color='red', label='malignant');\n\n# 良性をプロット\npca_benign.plot.scatter(x='pc1', y='pc2', color='blue', label='benign', ax=ax);\n\n# おおよその境界線\nx = np.arange(-5, 9)\ny = 1.7 * x - 0.8\nax.plot(x, y, color=\"black\")\n```\n\n境界線は`SVM`を使うとより最適化できるかも\n\n# 補足\n\n---\n\n## 主成分の選び方\n\n累計寄付率を求めてみると、次元が大きくなるほど値は変化しなくなる。なくなるぐらいの次元がベスト。逆に次元が大きくなるほど累計寄付率が大きく変わる場合、それは相関関係があるとは言えない。PCRを使ってもあまり意味がない。\n\n## 注意点\n\n### 解釈の難しさ\n\n主成分分析を用いて得られる結果は、統計的な指標や数値情報である。しかし、見つかった主成分が具体的にどのような意味を持つのかは、分析者の解釈に委ねられ、直感的には理解しづらい場合がある。その理由は、主成分自体が元のデータと直接の関連を持たないためである。\n\n### 正規性の仮定\n\n主成分分析は、データが正規分布に従っているという仮定の元に成り立っている分析手法である。正規分布とは、平均値の周りにデータが集中し、左右対称の釣鐘状にデータが広がるような分布をさす。正規性の仮定を満たさないデータに主成分分析を適用すると、主成分の方向や寄与率が歪められる可能性がある。\n\n### 外れ値の影響\n\n外れ値は通常のデータパターンから大きく逸脱した値であり、分析結果に悪影響を及ぼす可能性がある。**主成分分析はデータの分散を最大化する方向を求める手法である**。そのため、外れ値が分散に大きく影響すると、主成分の方向や寄与率が歪められてしまう。これにより、分析結果が歪んだり、軸の解釈が困難になってしまう問題が発生する。\n",
    "createdAt": "2025-07-21T07:23:48.457Z",
    "updatedAt": "2025-07-21T07:23:48.457Z"
  },
  {
    "title": "Python × Docker × uvで再現性のある環境構築を実現する",
    "summary": "Python開発でよく問題になる .venv と Docker の関係を整理し、uv sync を使って安全かつ再現性のある環境を構築する方法を解説します。",
    "tags": [
      "Python",
      "Docker",
      "uv",
      "開発環境",
      "再現性"
    ],
    "slug": "docker/uv-venv",
    "folder": "docker",
    "content": "\n## 🧭 1. はじめに\n\nPython で開発していると、**`.venv` の扱いに迷う**ことってありませんか？\n特に Docker と組み合わせたとき、\n「ローカルの `.venv` を使うべきか？」「コンテナ内で作るべきか？」\nといった問題に一度はぶつかると思います。\n\n一見どちらでも動くように見えますが、実際には **ビルドの再現性が大きく崩れる**ポイントです。\nホスト（macOSなど）とコンテナ（Linux）では Python のバイナリ依存関係が異なるため、\n同じ `.venv` を共有してしまうと「ImportError」「libが見つからない」などの微妙な不具合を生みます。\n\n---\n\nこの問題は Node.js ではあまり起こりません。\n`node_modules` は OS に依存しない JavaScript のパッケージ群であり、\n`npm install` や `pnpm install` は常に 0 から再現的に構築される設計です。\n一方、Python の `.venv` は **ホストのPython実行環境を基盤に構築される**ため、\n環境をまたいで使うとその前提が崩れてしまいます。\n\n---\n\nこの記事では、この問題を根本から整理しながら、\n\n- Docker と `.venv` の構造的な関係\n- `uv sync --frozen` を使った再現性のある構築方法\n- `.dockerignore` による最小・安全な解決策\n\nを順に紹介します。\n\n---\n\n次章ではまず、**Dockerとvenvの構造的な衝突**について掘り下げます。\n「なぜNode.jsでは動くのにPythonでは壊れるのか？」\nこの疑問を整理することで、環境構築の理解が一段深まります。\n\n---\n\n## 2. Docker と venv の構造的な問題\n\nPython のプロジェクトでは、依存関係を分離するために **`venv`（仮想環境）** を使うのが一般的です。\n一方、Docker も「環境の隔離」を目的とする仕組みであるため、**`venv` と Docker が重複して環境を管理しようとする** 状況がよく起こります。\n\nこの章では、なぜ `.venv` が Docker と相性が悪いのかを構造的に整理します。\n\n---\n\n### 🔹 COPY と Volume の違い\n\nまず前提として、**`COPY` はビルド時にホストのファイルをコンテナイメージへコピー**し、\n**`volume`（ボリューム）は実行時にホストや匿名領域をコンテナへマウント**する仕組みです。\n\n```dockerfile\n# COPY：ビルド時にホスト → イメージ\nCOPY backend/ .\n\n# volumes：実行時にホスト or 匿名領域 → コンテナ\nvolumes:\n  - ../backend:/app\n  - /app/__pycache__\n```\n\nつまり、ビルド時点で `.venv` がホストに存在すると、\n**`COPY` によってそのままイメージ内部に取り込まれてしまう** というのが本質的な問題です。\n\n---\n\n### 🔹 匿名ボリュームとバインドマウントの違い\n\n- **バインドマウント**：`../backend:/app` のように、ホスト側ディレクトリを直接コンテナに同期。\n  → 開発時には便利だが、ホストの `.venv` など OS 依存ファイルまで引きずり込む可能性がある。\n\n- **匿名ボリューム**：`/app/.venv` のように、名前のない一時領域をDockerが自動生成。\n  → コンテナごとに分離されるため、ホストとの直接同期は行われない。\n\n一見すると匿名ボリュームのほうが安全そうですが、\n実際には **「ビルド時点ですでに .venv が COPY されている」** ため、\nランタイムで匿名ボリュームを使っても `.venv` の混入を防げないのです。\n\n---\n\n### 🔹 なぜ .venv をマウントすると危険なのか\n\n`.venv` は OS やアーキテクチャに依存するネイティブバイナリを含みます。\nたとえば macOS 上で作成された仮想環境を Linux コンテナにマウントすると、\nリンク先の `.so`（共有ライブラリ）が対応しておらず、次のようなエラーが発生します。\n\n```bash\nImportError: /app/.venv/lib/python3.13/site-packages/psycopg2/_psycopg.so: ELF load command address/offset not properly aligned\n```\n\nこのように、**ホストとコンテナの `.venv` が混ざると再現性を失う**ため、\nDocker 環境では `.venv` をコピー・マウントしないのが原則です。\n\n---\n\n### 🔹 .dockerignore が果たす本当の役割\n\nこの問題を根本から防ぐには、**ビルドコンテキストに `.venv` を含めない**ことです。\nDockerfile の設計や volume 設定をどれだけ工夫しても、\nホスト側から `.venv` が送信されれば問題は発生します。\n\nそこで使うのが `.dockerignore`：\n\n```bash\n# .dockerignore\nbackend/.venv\n```\n\nこうしておくと、`docker build` 時に `.venv` が **送信対象から完全に除外** され、\nイメージに混入するリスクをゼロにできます。\nこれが最もシンプルで確実な対策です。\n\n---\n\n✅ **まとめ**\n\n- `COPY` はビルド時点で `.venv` を持ち込む可能性がある\n- 匿名ボリュームは実行時の同期防止には有効だが、ビルド時点では無力\n- `.venv` は OS 依存のため、マウントすると再現性を失う\n- `.dockerignore` に追加しておくのが最も確実な防御策\n\n---\n\n## 3. uv の仕組みを理解する\n\n`uv` は、Python の依存関係を**宣言的に・再現性高く**管理するための次世代ツールです。\n`pip` や `pipenv` と異なり、`uv` は **pyproject.toml と uv.lock** をもとに、\n依存環境を即時に同期（sync）する仕組みを持っています。\n\n---\n\n### 🔹 uv sync の動作 — 0 ベースか、差分か\n\n`uv sync` コマンドは、プロジェクトディレクトリに `.venv` が存在するかどうかで挙動が変わります。\n\n| 状況                      | 動作                                                                                   | 結果                            |\n| ------------------------- | -------------------------------------------------------------------------------------- | ------------------------------- |\n| `.venv` が **存在しない** | 新しい仮想環境を作成し、`uv.lock` に記載されたすべてのパッケージをクリーンインストール | ✅ **完全再現（0ベース）**      |\n| `.venv` が **存在する**   | 既存の環境を再利用しつつ、`uv.lock` と差分を取って更新                                 | ⚠️ **整合性が崩れる可能性あり** |\n\nつまり、`.venv` をホストからコピーしてしまうと、\n`uv sync` は「すでに存在する環境を更新するだけ」と判断し、\n古いバイナリや OS 依存ライブラリがそのまま残る可能性があります。\n\nこのため、Docker の中では「**.venvを含めず、常に0からsyncする**」のが再現性の鍵です。\n\n---\n\n### 🔹 pyproject.toml と uv.lock の関係\n\n`uv` の依存管理構造は、Node.js のパッケージ管理と非常に似ています。\n\n| Python (uv)      | Node.js (pnpm/npm/yarn)                | 役割                           |\n| ---------------- | -------------------------------------- | ------------------------------ |\n| `pyproject.toml` | `package.json`                         | 依存関係の宣言（人が編集する） |\n| `uv.lock`        | `pnpm-lock.yaml` / `package-lock.json` | 依存関係の固定（マシンが生成） |\n\nつまり `uv.lock` が存在すれば、`.venv` がなくても\n**同一バージョン・同一依存構成の環境を100%再現**できます。\n\n```bash\n# 完全再現構築（Dockerfile内などで）\nuv sync --frozen\n```\n\n`--frozen` は、「`uv.lock` に記載されていない変更を一切許可しない」オプションです。\nこれにより、CI/CD や Docker ビルド時に開発環境との差異を防げます。\n\n---\n\n### 🔹 なぜ uv なら .venv を捨ててもいいのか\n\n従来の `pip install -r requirements.txt` では、\n依存関係の解決が実行環境ごとに微妙に異なり、\n再現性を保証するのが難しい問題がありました。\n\n`uv` は依存ツリーを完全に固定した状態で `.venv` を生成するため、\n**ビルドするたびに同じ環境が再現される**よう設計されています。\nそのため、`.venv` を Docker に含める必要はまったくありません。\n\n---\n\n### ✅ まとめ\n\n- `.venv` がない場合は **0ベースでクリーン構築**\n- `.venv` がある場合は **差分同期** となり再現性を損なう可能性あり\n- `pyproject.toml` ＋ `uv.lock` があれば、環境を完全に再現可能\n- `uv sync --frozen` は CI/CD や Docker での再現性確保に必須\n\n---\n\n了解。ここは「理論から実装へ」つなぐ章だね。\n章 3 で「なぜ `.venv` を捨てるのか」が明確になったので、ここでは\n「どうやってそれをDockerで実現するか」を、**段階的に＋実用的に**まとめる👇\n\n---\n\n## 4. 実際の Docker 構成例\n\nここでは、実際に **Python + uv + Docker** を使って\n「ホストと分離された再現性のある環境」を構築する例を紹介します。\n\n---\n\n### 🔹 4.1 最小構成の Dockerfile.dev\n\nまずは最小限の構成から見てみましょう。\n\n```dockerfile\n# ./deploy/backend/Dockerfile.dev\nFROM python:3.13-slim\n\n# Python設定（.pycを作らない・バッファ無効）\nENV PYTHONDONTWRITEBYTECODE=1 \\\n    PYTHONUNBUFFERED=1\n\nWORKDIR /app\n\n# uvをインストール\nRUN pip install --no-cache-dir uv\n\n# 依存関係の同期（まずpyproject.tomlとuv.lockだけをコピー）\nCOPY backend/pyproject.toml backend/uv.lock* ./\nRUN apt-get update && apt-get install -y --no-install-recommends pkg-config libmariadb-dev libmariadb-dev-compat build-essential \\\n    && rm -rf /var/lib/apt/lists/*\nRUN uv sync --frozen  # ここで.venvが生成される\n\n# アプリ本体をコピー\nCOPY backend/ .\n\nCMD [\"uv\", \"run\", \"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"]\n```\n\n### ✅ 解説\n\n- `COPY backend/pyproject.toml backend/uv.lock* ./`\n  → 依存ファイルだけを先にコピーすることで、コード更新時に依存再インストールを避ける。\n- `uv sync --frozen`\n  → `.venv` が存在しなければ新規作成、あれば差分更新。\n  Docker ビルドでは毎回新しいイメージ上で実行されるため、**常に0ベース構築**。\n- `.dockerignore` に `.venv` を含めておくことで、\n  ホストにある既存 `.venv` が誤ってビルドコンテキストに含まれるのを防ぐ。\n\n---\n\n### 🔹 4.2 .dockerignore の正しい書き方\n\n```bash\n# .dockerignore\nbackend/.venv\nfrontend/node_modules\n.git\n.DS_Store\n```\n\nこれでホスト上の `.venv` をイメージに含めるリスクを完全に排除できます。\n（`.git` を除外しておくのも一般的です。）\n\n---\n\n### 🔹 4.3 docker-compose.dev.yml の volume 設計\n\nフロントエンドの構成と比較して、Python 側でも匿名ボリュームを設定することで\nホストの `.venv` がマウントされないようにできます。\n\n```yaml\nservices:\n  backend:\n    build:\n      context: ..\n      dockerfile: deploy/backend/Dockerfile.dev\n    volumes:\n      - ../backend:/app\n      - /app/__pycache__ # キャッシュ汚染防止\n      - /app/.venv # ← 匿名ボリュームでホストと切り離す\n    env_file:\n      - .env.dev\n    ports:\n      - \"8000:8000\"\n```\n\n> 💡 ここで `/app/.venv` を匿名ボリュームにすると、\n> `../backend` のバインドマウントが `.venv` を上書きできなくなり、\n> コンテナ専用の仮想環境が維持されます。\n\n---\n\n### 🔹 4.4 COPY 順序のベストプラクティス\n\nDockerfile の COPY 順序はキャッシュ効率と再現性に直結します。\n\n| ステップ | 内容                                 | 理由                         |\n| -------- | ------------------------------------ | ---------------------------- |\n| 1️⃣       | `pyproject.toml`, `uv.lock` をコピー | 依存関係キャッシュを有効化   |\n| 2️⃣       | `uv sync --frozen`                   | .venv 構築                   |\n| 3️⃣       | アプリコード全体をコピー             | コード更新のみで再ビルド可能 |\n\nこの順序を守ることで、`pip install` に比べて圧倒的に速いビルドが実現できます。\n\n---\n\n### ✅ まとめ\n\n- `.venv` は **ビルド時に uv が作るもの**、ホストからコピーしない\n- `.dockerignore` でホストの `.venv` を除外しておくのが最も確実\n- 匿名ボリューム `/app/.venv` を使うと、ホストとの衝突を完全に防げる\n- COPY 順序を整理すればキャッシュ効率も良くなる\n\n---\n\n## 5. よくある誤解とアンチパターン\n\nPython × Docker の環境構築で `.venv` を扱う際、実務で頻発する誤解を整理します。\nどれも一見「動いてるように見える」ため厄介ですが、再現性やチーム開発で問題を引き起こす典型例です。\n\n---\n\n### 🧩 誤解①：「匿名ボリュームにすれば安全でしょ？」\n\n匿名ボリュームを指定すれば、確かに実行時にホストの `.venv` がマウントされるのを防げます。\nしかし、**Dockerfile 内で `COPY backend/ .` をしている場合、ビルド時点で `.venv` が含まれてしまう** ため意味がありません。\nこれは匿名ボリュームが “コンテナ起動時” に適用される仕組みだからです。\n\n👉 **解決策:**\n`.dockerignore` に `backend/.venv` を追加し、**ビルドコンテキスト**から除外する。\n\n---\n\n### 🧩 誤解②：「uv sync すれば上書きされるでしょ？」\n\n`uv sync` は依存関係を同期するコマンドですが、**0ベースで再構築するわけではありません。**\n既存の `.venv` がある場合、その環境を「更新」してしまうため、**ホストとコンテナで異なる依存関係が混ざる可能性**があります。\n\n👉 **解決策:**\n`.venv` はホストとコンテナで共有しない。\n常に `.dockerignore` で除外し、`uv sync --frozen` で lock ファイルをもとにクリーン構築。\n\n---\n\n### 🧩 誤解③：「ホストの .venv を共有すれば速い」\n\n確かにビルドや起動は速くなりますが、**OS依存バイナリ（例：C拡張）**が入っているため危険です。\nmacOS 上で作った `.venv` を Linux コンテナにマウントすると、\n「インポートエラー」や「共有ライブラリが見つからない」などの不具合が発生します。\n\n👉 **解決策:**\nホストとコンテナは別の `.venv` を持つのが原則。\nパッケージの再現性は `uv.lock` に任せる。\n\n---\n\n### 🧩 誤解④：「Node.js では動いてるから同じでしょ？」\n\nNode.js の `node_modules` はプラットフォーム依存が少なく、**`pnpm install` は常に0ベースで構築**されます。\n一方で Python の `.venv` は OS・アーキテクチャ依存であり、**ホスト環境をコピーすると破綻します。**\n\n👉 **解決策:**\nNode.js と Python の環境再現モデルは異なる。\nPythonでは「.venvは排除・再構築」、Nodeでは「node_modulesを匿名ボリュームで再生成」。\n\n---\n\n### 🧩 誤解⑤：「.dockerignore いらないでしょ？」\n\n`.dockerignore` を使わなくても動くように見えるケースがありますが、\n**動く ≠ 再現性が保証されている** ではありません。\nホストの不要ファイル（`.venv`, `__pycache__`, `.DS_Store`など）はビルドキャッシュを汚染し、\n別マシンで同じDockerfileを使っても同一の環境にならないリスクがあります。\n\n👉 **解決策:**\n`.gitignore` とは別に、**Docker専用の除外ルール**を必ず設定する。\n特に `.venv`, `.mypy_cache`, `.pytest_cache` などは必須除外項目。\n\n---\n\n### ✅ まとめ\n\n| 誤解                  | 問題点             | 解決策                 |\n| --------------------- | ------------------ | ---------------------- |\n| 匿名ボリュームでOK    | ビルド時に混入     | `.dockerignore` で除外 |\n| uv syncで上書きされる | 差分更新される     | `uv sync --frozen`     |\n| ホストの.venv共有     | OS非互換           | 分離・再構築           |\n| Node.jsと同じ構成     | 動作モデルが異なる | Python専用設計         |\n| .dockerignore不要     | 再現性低下         | 必ず設定               |\n\n---\n\nいい締めにいこう。\nこの章は “技術的な結論” だけじゃなく、**考え方の指針**として終われると読後感が強く残る。\n以下のようにまとめるのがベスト👇\n\n---\n\n## 7. まとめ\n\n今回扱ったのは、単なる `.venv` の除外設定ではなく、\n**「Python × Docker における環境再現性の本質」** です。\n\n---\n\n### 🧩 問題の本質\n\n- `.venv` には **OS依存のバイナリやシンボリックリンク** が含まれるため、\n  ホストとコンテナで共有すると **環境の整合性が壊れる**。\n- `uv sync` は既存の `.venv` を部分的に更新する仕組みのため、\n  **クリーンな状態から構築しない限り完全再現にはならない**。\n\n---\n\n### 🧰 解決策の要点\n\n| 層           | 方針                                      | 理由                         |\n| ------------ | ----------------------------------------- | ---------------------------- |\n| **ビルド時** | `.dockerignore` に `backend/.venv` を追加 | ホストの `.venv` 混入を防止  |\n| **実行時**   | 匿名ボリュームで `.venv` を切り離す       | マウント衝突を防止           |\n| **環境再現** | `uv sync --frozen`                        | `uv.lock` に基づいて完全同期 |\n| **開発効率** | VSCodeではローカル`.venv`を利用           | Lintや補完はローカル完結でOK |\n\n---\n\n### 💡 学べる教訓\n\n1. **「動く」ことより「再現できる」ことが重要。**\n   チーム開発やCI/CDでは、同じDockerfileから同じ環境が再現できることが最優先。\n\n2. **PythonはNode.jsよりも環境差の影響が大きい。**\n   Nodeでは依存が純粋にJavaScriptで完結するが、\n   Pythonはネイティブ依存（C, glibc, etc.）を多く含むため慎重な分離が必要。\n\n3. **`.dockerignore` は“安全弁”であり、再現性の最後の砦。**\n   「動くからいい」ではなく「他の環境でも確実に動くか」で判断する。\n\n---\n\n### 🚀 結論\n\n> `.venv` はコンテナに含めない。\n> `uv.lock` と `uv sync --frozen` で再現する。\n> `.dockerignore` は必ず設定する。\n\nこれが、**Python × Docker × uv の最小構成で再現性を担保する最もシンプルな解** です。\n\n了解 ✅\n以下は、TechBlog v2 用にそのままコピペできる **Markdown フッター** 形式の完成版です。\nすべて一次情報の英語原文＋日本語訳＋公式リンク付きです。\n\n---\n\n## 📚 参考文献・ソース\n\n### 🧩 **uv 関連（Astral Docs）**\n\n> “If the project virtual environment (`.venv`) does not exist, it will be created.”\n> “Update the project's environment.”\n> “Syncing ensures that all project dependencies are installed and up-to-date with the lockfile.”\n> （`.venv` が存在しない場合は新規作成され、存在する場合は更新される。ロックファイルに基づき依存関係を最新化する。）\n>\n> — [Astral Docs: uv – Projects / uv sync](https://docs.astral.sh/uv/reference/commands/#uv-sync)\n\n---\n\n### 🐳 **Docker × Python 環境設計**\n\n> “Avoid copying virtual environments from your local machine into Docker images.”\n> （ローカルの仮想環境を Docker イメージにコピーしないこと。）\n>\n> — [Docker Official Docs – Language Guide (Python)](https://docs.docker.com/language/python/build-images/)\n\n> “To exclude files not relevant to the build, without restructuring your source repository, use a `.dockerignore` file.”\n> （ビルドに不要なファイルを除外するには `.dockerignore` を使用する。）\n>\n> — [Docker Docs – `.dockerignore`](https://docs.docker.com/engine/reference/builder/#dockerignore-file)\n\n---\n\n### 🐍 **Python 公式 – venv の移植性について**\n\n> “Because of this, environments are inherently non-portable, in the general case.”\n> （このため仮想環境は本質的にポータブルではない。）\n>\n> — [Python Docs – venv (3.13)](https://docs.python.org/3/library/venv.html)\n\n---\n\n### 💽 **Docker – Volume と Bind Mount の違い**\n\n> “When you use a bind mount, a file or directory on the host machine is mounted from the host into a container.”\n> （バインドマウントではホスト上のファイル／ディレクトリをそのままコンテナへマウントする。）\n>\n> “While bind mounts are dependent on the directory structure and OS of the host machine, volumes are completely managed by Docker.”\n> （バインドマウントはホストのディレクトリ構造や OS に依存するが、ボリュームは Docker によって完全に管理される。）\n>\n> — [Docker Docs – Use bind mounts or volumes](https://docs.docker.com/storage/volumes/)\n\n---\n\n### 🧱 **Node.js Lockfile の再現性**\n\n> “It describes the exact tree that was generated, such that subsequent installs are able to generate identical trees, regardless of intermediate dependency updates.”\n> （`package-lock.json` は生成された依存ツリーを厳密に記述し、後のインストールで同一ツリーを再現できるようにする。）\n>\n> — [npm Docs – About package-lock.json](https://docs.npmjs.com/cli/v9/configuring-npm/package-lock-json)\n\n> “Commit the lockfile (`pnpm-lock.yaml`) for faster installs and consistent installations.”\n> （`pnpm-lock.yaml` をコミットすることで、より高速かつ一貫したインストールが可能になる。）\n>\n> — [pnpm Docs – Lockfile](https://pnpm.io/lockfile)\n",
    "createdAt": "2025-10-05T08:13:59.482Z",
    "updatedAt": "2025-10-05T09:40:49.504Z"
  },
  {
    "title": "Radix UIのdropdown menuを開くとscrollbarが消えてスタイルが変わるときの対処法",
    "summary": "記事がなかったので作る",
    "tags": [
      "Next.js",
      "Web",
      "Webアプリ開発",
      "shadcn/ui",
      "CSS"
    ],
    "slug": "Next.js/redix-dropdown-error",
    "folder": "Next.js",
    "content": "\nRadix UIのdropdown menuを開くときに，スクロールバーが消えてスタイルが変わってしまうことがあった．見栄えが悪いので修正しようとしたが記事がなく，修正に手間取ったのでここに修正方法を記す．\n\n該当のコードは以下の通り．\n\n```tsx\n\"use client\";\nimport { Moon, Sun } from \"lucide-react\";\nimport { useTheme } from \"next-themes\";\n\nimport { Button } from \"@/components/ui/button\";\nimport {\n  DropdownMenu,\n  DropdownMenuContent,\n  DropdownMenuItem,\n  DropdownMenuTrigger,\n} from \"@/components/ui/dropdown-menu\";\n\nexport const ThemeToggle = ({ children }: { children: React.ReactNode }) => {\n  const { setTheme } = useTheme();\n\n  return (\n    <>\n      {children}\n\n      <DropdownMenu>\n        <DropdownMenuTrigger asChild>\n          <Button\n            variant=\"outline\"\n            size=\"icon\"\n            className=\"\n              fixed bottom-8 right-8 \n              dark:text-gray-800 text-gray-200\n              hover:dark:text-gray-700 hover:text-gray-200\n              dark:bg-white bg-black\n              hover:dark:bg-gray-100 hover:bg-gray-950\n              dark:border-white border-black\n            \"\n          >\n            <Sun className=\"h-[1.2rem] w-[1.2rem] rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0\" />\n            <Moon className=\"absolute h-[1.2rem] w-[1.2rem] rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100\" />\n            <span className=\"sr-only\">Toggle theme</span>\n          </Button>\n        </DropdownMenuTrigger>\n        <DropdownMenuContent\n          align=\"end\"\n          className=\"\n            dark:text-gray-800 text-gray-200\n            hover:dark:text-gray-700 hover:text-gray-200\n            dark:bg-white bg-black\n            hover:dark:bg-gray-100 hover:bg-gray-950\n            border-none\n          \"\n        >\n          <DropdownMenuItem\n            className=\"dark:hover:bg-gray-300 dark:hover:text-black\"\n            onClick={() => setTheme(\"light\")}\n          >\n            Light\n          </DropdownMenuItem>\n          <DropdownMenuItem\n            className=\"dark:hover:bg-gray-300 dark:hover:text-black\"\n            onClick={() => setTheme(\"dark\")}\n          >\n            Dark\n          </DropdownMenuItem>\n          <DropdownMenuItem\n            className=\"dark:hover:bg-gray-300 dark:hover:text-black\"\n            onClick={() => setTheme(\"system\")}\n          >\n            System\n          </DropdownMenuItem>\n        </DropdownMenuContent>\n      </DropdownMenu>\n    </>\n  );\n};\n```\n\nボタン要素が`fixed`だからおかしくなったのかなとは思うが`fixed`は使わざるを得ない．ちなみにレスポンシブでは同様のバグは発生しなかった．もちろんスクロールバーが出ない状態でも発生はしない．\n\n修正方法は以下の通り．`grobals.css`にこれを追加するだけ．\n\n```css\nbody[data-scroll-locked][data-scroll-locked] {\n  overflow: auto !important;\n  margin-right: 0 !important;\n}\n```\n\n`data-scroll-locked`属性が2回付与された`body`要素に対して適用している．おそらくJSによってdata-scroll-lockedをbodyに付与することでスクロールを無効化しており，dropdown menuにその機能があったのではないかと推測している．\n\n`[data-scroll-locked][data-scroll-locked]`のように2回付与された場合しか適用できなかった．\n\nそしてこの時に`overflow: auto !important;`と`margin-right: 0 !important;`を指定している．\n\n前者は要素がオーバーフローをしたときにスクロールバーを表示させるようにしているが，`!important`によってそれを優先的に適用させている．\n\nこのときになぜかbodyに`margin-right: 16px !important`が付与されるため，後者のように指定することでそれを無効化している．\n\n参考\n[shadcn/radix ui scrollbar removal bug](https://www.reddit.com/r/reactjs/comments/1fjcwkh/shadcnradix_ui_scrollbar_removal_bug/?rdt=60694)\n",
    "createdAt": "2025-07-21T07:23:48.458Z",
    "updatedAt": "2025-07-21T07:23:48.458Z"
  },
  {
    "title": "Ruby on RailsでPostgreSQLに接続する",
    "summary": "忘れたとき用のメモ",
    "tags": [
      "Ruby on Rails",
      "PostgreSQL"
    ],
    "slug": "ruby/ror-psql",
    "folder": "ruby",
    "content": "\n# プロジェクトを作る\n\n```bash\nrails new new_app -d postgresql\n```\n\n> api開発の場合は`--api`オプションをつける\n\n`rails db:create`を忘れずに\n\n## Gemfileの編集\n\ndbに入るためのパスワードを安全に設定するために，`dotenv-rails`を入れておく\n\n```ruby\n# Gemfile\ngroup :development, :test do\n  # See https://guides.rubyonrails.org/debugging_rails_applications.html#debugging-with-the-debug-gem\n  gem \"debug\", platforms: %i[ mri mswin mswin64 mingw x64_mingw ], require: \"debug/prelude\"\n\n  # Static analysis for security vulnerabilities [https://brakemanscanner.org/]\n  gem \"brakeman\", require: false\n\n  # Omakase Ruby styling [https://github.com/rails/rubocop-rails-omakase/]\n  gem \"rubocop-rails-omakase\", require: false\n\n  gem 'dotenv-rails'\nend\n```\n\n# db設定ファイルの編集\n\n```yml\n# config/database.yml\ndefault: &default\n  adapter: postgresql\n  encoding: unicode\n  pool: <%= ENV.fetch(\"RAILS_MAX_THREADS\") { 5 } %>\n\ndevelopment:\n  <<: *default\n  database: sticky_backend_development\n\n  username: postgres\n\n  password: <%= ENV['DATABASE_PASSWORD'] %>\n\ntest:\n  <<: *default\n  database: sticky_backend_test\n  username: postgres\n  password: <%= ENV['DATABASE_PASSWORD'] %>\n\nproduction:\n  <<: *default\n  database: sticky_backend_production\n  username: postgres\n  password: <%= ENV['DATABASE_PASSWORD'] %>\n```\n\n> .envファイルに`DATABASE_PASSWORD`を設定する\n\n> 最後に`rails db:create && rails db:migrate`を忘れずに！\n",
    "createdAt": "2025-07-21T07:23:48.459Z",
    "updatedAt": "2025-07-21T07:23:48.459Z"
  },
  {
    "title": "shadcn/uiでdarkmodeに切り替えるときのHydration errorを解決する方法",
    "summary": "参考にした記事をただ紹介するだけ",
    "tags": [
      "Next.js",
      "Web",
      "Webアプリ開発",
      "個人開発",
      "shadcn/ui"
    ],
    "slug": "Next.js/shadcn-darkmode-hydration",
    "folder": "Next.js",
    "content": "\n`theme-provider.tsx`を\n\n```tsx\n\"use client\";\n\nimport { ThemeProvider as NextThemeProvider } from \"next-themes\";\nimport { type ThemeProviderProps } from \"next-themes/dist/types\";\nimport { useEffect, useState } from \"react\";\n\nexport const ThemeProvider = ({ children, ...props }: ThemeProviderProps) => {\n  const [mounted, setMounted] = useState<boolean>(false);\n  useEffect(() => {\n    setMounted(true);\n    return () => setMounted(false);\n  }, []);\n  return (\n    mounted && <NextThemeProvider {...props}>{children}</NextThemeProvider>\n  );\n};\n```\n\nのようにすればよいらしい．このようにしたら治った．\n\n参考\n[DarkMode切替時でのHydration errorの対応策](https://zenn.dev/dk_/articles/dd9b0426e58f7d)\n",
    "createdAt": "2025-07-21T07:23:48.458Z",
    "updatedAt": "2025-07-21T07:23:48.458Z"
  },
  {
    "title": "The Basics of Neural Networks",
    "summary": "I explain neural networks without using confusing metaphors.",
    "tags": [
      "python",
      "Machine Learning",
      "Deep Learning",
      "Algorithm",
      "Neural Network"
    ],
    "slug": "Deep-Learning/NN-basics",
    "folder": "Deep-Learning",
    "content": "\n# Neural Networks\n\n---\n\nA neural network is similar to a function. However, it uses high-dimensional input values to output desired data. It can approximate very complex functions. A disadvantage is that it requires \"learning\" and lacks interpretability in its computation process.\n\n## Structure\n\n![Neural Network Structure](https://www.tel.co.jp/museum/magazine/communication/160229_report01_02/img/img_report01_03.jpg)\n\n### Input Layer\n\n$$\n\\mathbf x=[x_1,x_2,...,x_n]\\in\\mathbb R^n\n$$\n\n### Hidden Layers\n\n$$\n\\mathbf h_i=f_i(\\mathbf W_i\\mathbf h_{i-1}+\\mathbf b_i)\\quad\n\\left\\{\n\\begin{aligned}\nf_i&:\\mathbb R^{m_{i-1}}\\to\\mathbb R^{m_i}\\quad(\\text{activation function})\\\\\n\\mathbf W_i&\\in\\mathbb R^{m_i\\times m_{i-1}}\\quad(\\text{weight vector})\\\\\n\\mathbf h_i,\\mathbf b_i&\\in\\mathbb R^{m_i}\\quad(\\text{output and bias vector of layer } i)\n\\end{aligned}\n\\right.\n$$\n\n### Output Layer\n\n$$\n\\mathbf y=f_{out}(\\mathbf W_{out}\\mathbf h_{last}+\\mathbf b_{out})\n$$\n\n### Overall Function\n\n$$\n\\hat{\\mathbf y}=f_{NN}(x;\\theta)=f_{out}\\circ f_n\\circ f_{n-1}\\circ...\\circ f_1(\\mathbf W_1\\mathbf x+\\mathbf b_1)\n$$\n\nHere, \\( \\theta \\) represents the parameters, including \\( f \\), \\( W \\), \\( h \\), and \\( b \\).\n\n## Activation Functions\n\nActivation functions introduce non-linearity.\n\n### ReLU (Rectified Linear Unit)\n\n$$\nf(x)=\\max(0,x)\n$$\n\n### Sigmoid\n\n$$\nf(x)=\\frac{1}{1+\\exp(-x)}\n$$\n\n### Tanh\n\n$$\nf(x)=\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\n$$\n\n### SoftPlus\n\nThe integral of the sigmoid function:\n\n$$\nf(x)=\\log(1+\\exp(x))\n$$\n\n## Learning Process\n\n### Forward Propagation\n\nThe calculation process from input to output:\n\n$$\n\\hat{\\mathbf y}=f_{NN}(x;\\theta)=f_{out}\\circ f_n\\circ f_{n-1}\\circ...\\circ f_1(\\mathbf W_1\\mathbf x+\\mathbf b_1)\n$$\n\n### Loss Function Calculation\n\nThe process of calculating the error using a loss function based on the output and target data. Examples include Mean Squared Error (MSE) and Cross-Entropy Loss.\n\n$$\n{\\cal L}=Loss(\\mathbf y,\\hat{\\mathbf y})\n$$\n\n### Backpropagation\n\nThe process of updating parameters based on the error using gradient descent.\n\n$$\n\\mathbf W_i\\leftarrow\\mathbf W_i-\\eta\\frac{\\partial{\\cal L}}{\\partial\\mathbf W_i},\\quad\\mathbf b_i\\leftarrow\\mathbf b_i-\\eta\\frac{\\partial{\\cal L}}{\\partial\\mathbf b_i}\\quad\n\\left\\{\n\\begin{aligned}\n&\\frac{\\partial{\\cal L}}{\\partial\\mathbf W_i}=\\frac{\\partial{\\cal L}}{\\partial\\hat{\\mathbf y}}\\cdot\\frac{\\partial\\hat{\\mathbf y}}{\\partial\\mathbf h_i}\\cdot\\frac{\\partial\\mathbf h_i}{\\partial\\mathbf W_i}\\\\\n&\\frac{\\partial{\\cal L}}{\\partial\\mathbf b_i}=\\frac{\\partial{\\cal L}}{\\partial\\hat{\\mathbf y}}\\cdot\\frac{\\partial\\hat{\\mathbf y}}{\\partial\\mathbf h_i}\\cdot\\frac{\\partial\\mathbf h_i}{\\partial\\mathbf b_i}\n\\end{aligned}\n\\right.\n$$\n\nThis process ensures the gradients guide the parameters toward lower error values. It allows for efficient updates, especially when far from the minimum.\n\n> 💡 The reason \\( f'(x)=0 \\) is not directly computed is that it is computationally difficult for computers. Instead, gradient descent is used since it is easier to compute the derivative numerically.\n\n[Why Use Gradient Descent in Machine Learning](https://www.tomotaku.com/machine-learning-gradient-descent/)\n\n## Optimization Algorithms\n\n### Standard Gradient Descent\n\n$$\n\\theta_{t+1}=\\theta_t-\\eta\\nabla_\\theta{\\cal L}(\\theta_t)\n\\left\\{\n\\begin{aligned}\n\\theta_t:&\\text{parameters at time } t\\\\\n\\eta:&\\text{learning rate}\\\\\n\\nabla_\\theta{\\cal L}(\\theta_t):&\\text{gradient of the loss function at time } t\n\\end{aligned}\n\\right.\n$$\n\nStop when $||\\nabla_\\theta{\\cal}(\\theta_t)||<\\epsilon$, or use another stopping criterion.\n\n### Adam\n\nAdam is more suited to deep learning, as it converges faster than standard gradient descent.\n\n1. Compute the first moment: the moving average of the gradients (using exponential smoothing).\n\n   $$\n   m_t=\\beta_1m_{t-1}+(1-\\beta_1)\\nabla_\\theta{\\cal L}(\\theta_t)\n   $$\n\n2. Compute the second moment: the moving average of the squared gradients.\n\n   $$\n   v_t=\\beta_2v_{t-1}+(1-\\beta_2)(\\nabla_\\theta{\\cal L}(\\theta_t))^2\n   $$\n\n3. Bias correction:\n\n   $$\n   \\hat m_t=\\frac{m_t}{1-\\beta_1^t},~\\hat v_t=\\frac{v_t}{1-\\beta_2^t}\n   $$\n\n4. Update parameters:\n\n   $$\n   \\theta_{t+1}=\\theta_t-\\eta\\frac{\\hat m_t}{\\sqrt{\\hat v_t}+\\epsilon}\n   $$\n",
    "createdAt": "2025-07-21T07:23:48.457Z",
    "updatedAt": "2025-07-21T07:23:48.457Z"
  },
  {
    "title": "Understanding XGBoost",
    "summary": "I explained XGBoost in a university lecture!",
    "tags": [
      "AI",
      "Machine Learning",
      "Mathematics",
      "Explanation"
    ],
    "slug": "Machine-Learning/understanding-XGBoost",
    "folder": "Machine-Learning",
    "content": "\n# Introduction to XGBoost\n\n## Overview of XGBoost (eXtreme Gradient Boosting)\n\n- An ensemble learning method combining boosting and decision trees.\n- **Boosting**: A technique that iteratively creates weak models (weak learners), with each subsequent learner correcting the errors of the previous one, thereby improving performance.\n- Shallow decision trees are created, each of which performs well only on a portion of the data. Boosting improves their overall performance.\n- Although sensitive to parameter tuning, XGBoost can outperform Random Forest when configured correctly.\n- Despite the term \"regression tree,\" it can be used for both regression and classification tasks.\n\n---\n\n## Review: Decision Trees\n\nA method that learns conditional branching, often illustrated by games like Akinator.\n\n### Prerequisite Knowledge\n\n#### Information\n\nThe less frequent (rarer) an event, the greater its \"information content\":\n\n$$\ni(x) = -\\log_2 p(x)\n$$\n\n#### Impurity\n\n- **Entropy (Average Information Content)**  \n  A measure of randomness or disorder. It uses the expected value of information content based on occurrence probabilities:\n\n  $$\n  I_H(t) = -\\sum_{i=1}^c p(i|t) \\log_2 p(i|t) \\quad \\left(p(i|t) = \\frac{n_i}{N}: \\text{Probability of class } i \\text{ at node } t\\right)\n  $$\n\n- **Gini Impurity**  \n  Borrowed from econometrics:\n\n  $$\n  I_G(t) = 1 - \\sum_{i=1}^c p(i|t)^2\n  $$\n\n  A higher value indicates more mixed classes, i.e., **higher impurity** → poor classification. Other metrics like misclassification rate can also be used.\n\n#### Gain\n\nThe difference in impurity between nodes before and after splitting. Higher gain indicates a greater reduction in impurity.\n\n##### Decision Tree Learning Using Gain\n\n1. For each feature, consider the midpoints of adjacent data points as threshold candidates.\n2. Compute the impurity after splitting at each candidate threshold.\n3. Split at the threshold that reduces impurity the most.\n4. Repeat recursively.\n5. Stop when a node contains too few data points or further splitting is not possible.\n\n$$\n\\Delta I_H(t) = I_H(t_B) - \\sum_{i=1}^b w_i I_{H_i}(t_{A_i})\n$$\n\n$$\n\\left(I_H(t_B): \\text{Impurity before branching, } \\sum_{i=1}^b w_i I_H(t_{A_i}): \\text{Weighted average impurity after branching}\\right)\n$$\n\n---\n\n# Ensemble Methods for Improved Generalization Performance\n\n**Ensemble Methods** combine multiple machine learning models to achieve better predictive performance than any single model.\n\nBy integrating predictions from different models, ensemble methods compensate for individual weaknesses, improving overall predictive accuracy and generalization performance.\n\n### Generalization Performance\n\nIndicates a model's ability to make accurate predictions on unseen data, not just the training data.\n\n#### Overfitting\n\n- A phenomenon where the model performs well on training data but poorly on test data.\n- Occurs when the model \"memorizes\" the training data, becoming unable to generalize to new data.\n- Analogous to scoring high on regular tests but poorly on mock or entrance exams.\n\n#### Weak Learners\n\nModels with low predictive accuracy that are prone to overfitting, such as shallow decision trees.\n\nFor example, if a model is trained to identify cats as animals with pointy ears, it might fail to recognize cats with rounded ears.\n\n#### Strong Learners\n\nModels with higher predictive accuracy than weak learners. Boosting transforms weak learners into a single strong learner system.\n\nFor instance, to identify cats, a weak learner that predicts based on pointy ears can be combined with another that identifies eye shape. By refining predictions iteratively, the overall system improves accuracy.\n\n---\n\n## Bagging\n\nAn ensemble technique designed to address overfitting. Multiple weak learners are created, and their predictions are aggregated using majority voting (for classification) or averaging (for regression) to enhance generalization performance.\n\n### Examples\n\n- RandomForest\n- BaggingClassifier/Regressor\n\n---\n\n## Boosting\n\n- Combines multiple weak learners.\n- Adjusts the weights of data points so that subsequent models focus more on previously misclassified points.\n- Each model reduces errors iteratively.\n\n### Examples of Boosting Models\n\n#### AdaBoost\n\nA general boosting method. Repeatedly creates weak learners, emphasizing misclassified points by adjusting their weights. Final predictions are made using a weighted majority vote of all weak learners.\n\n#### GBDT (Gradient Boosting Decision Tree)\n\nMinimizes the error between predicted values and true labels iteratively, gradually transforming weak learners into strong learners. The final model's output is the combined prediction of all learners.\n\n#### XGBoost (eXtreme Gradient Boosting)\n\nAn enhanced version of GBDT with features like regularization and parallel computation for improved performance.\n\n# Ensemble Methods Usage Guide\n\n| Ensemble Method | Model Examples              | Use Cases                                                                                                  | Priority                                             |\n| :-------------- | :-------------------------- | :--------------------------------------------------------------------------------------------------------- | :--------------------------------------------------- |\n| Bagging         | RandomForest                | When avoiding overfitting and at the initial stage of a project where useful features are not well-defined | First choice for bagging                             |\n|                 | BaggingClassifier/Regressor |                                                                                                            | For non-decision-tree models                         |\n| Boosting        | XGBoost, GradientBoosting   | When aiming for high accuracy, typically after EDA reveals useful features                                 | Often the first choice due to overfitting prevention |\n|                 | AdaBoost                    |                                                                                                            | For non-decision-tree models                         |\n| No Ensemble     | Single Model                | When interpretability of results is critical                                                               |                                                      |\n\n# Theory Behind XGBoost\n\n## AdaBoost\n\nA drawback of decision trees is that they can overfit or underfit if tree size is incorrectly chosen, making them a sensitive model.\n\n- **Idea**: Instead of building the entire tree at once, why not incrementally grow it?\n- Use a combination of weak learners.\n- Assign higher weights to misclassified data and lower weights to correctly classified data after each iteration.\n- Combine all nodes to create a robust tree.\n\n**Reference**: [Ensembles (4): AdaBoost](https://www.youtube.com/watch?v=ix6IvwbVpw0)\n\n## Gradient Boosting Decision Trees (GBDT)\n\n### Issues with AdaBoost\n\n1. Assigning high weights to misclassified data can also amplify noise, potentially causing overfitting.\n2. Simply adjusting weights without leveraging a loss function does not explicitly solve a minimization problem, which may not be optimal.\n\n### GBDT's Approach\n\nGBDT explicitly defines a loss function and solves its minimization problem.\n\n#### Key Concepts\n\n- **Loss Function**: Measures prediction error (e.g., Mean Squared Error or Cross-Entropy Loss).\n  $$\n  \\mathcal{L}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y})^2\n  $$\n- **Gradient Descent**: Optimizes model parameters by minimizing the loss.\n  $$\n  \\theta^* = \\arg\\min_{\\theta} \\mathcal{L}(y, f_{\\theta}(\\mathbf{x})) \\equiv \\theta - \\eta \\frac{\\partial \\mathcal{L}(y, f_\\theta(\\mathbf{x}))}{\\partial \\theta}\n  $$\n\n#### Procedure\n\n1. Initialize predictions with a constant that minimizes the loss:\n   $$\n   F_0(\\mathbf{x}) = \\arg\\min_{\\hat{y}_0} \\sum_{i=1}^n \\mathcal{L}(y_i, \\hat{y}_0)\n   $$\n   For MSE:\n   $$\n   \\hat{y}_0 = \\frac{1}{n} \\sum_{i=1}^n y_i\n   $$\n2. Iteratively improve predictions:\n   - Compute residuals (errors):\n     $$\n     \\tilde{y}_0 = -\\frac{\\partial \\mathcal{L}(y, F_0(\\mathbf{x}))}{\\partial F_0(\\mathbf{x})}\n     $$\n   - Train a weak learner (e.g., decision tree) to predict residuals.\n   - Update predictions with optimal step size:\n     $$\n     F_1(\\mathbf{x}) = F_0(\\mathbf{x}) + \\rho_0 h_{\\theta_0}(\\mathbf{x})\n     $$\n\nThe process minimizes the overall loss function:\n\n$$\n\\mathcal{L} = \\sum_{i=1}^n \\mathcal{L}(y_i, F_k)\n$$\n\n## XGBoost\n\nXGBoost enhances GBDT by incorporating second-order derivatives (Hessian) and regularization terms.\n\n### Regularization\n\nIntroduces regularization to control model complexity:\n\n$$\n\\mathcal{L}^{(t)} = \\sum_{i=1}^n l(y_i, \\hat{y}_i^{(t-1)} + f_k(\\mathbf{x}_i)) + \\Omega(f_t)\n$$\n\n$$\n\\Omega(f_t) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^T w_j^2\n$$\n\nWhere:\n\n- \\( T \\): Number of leaves\n- \\( w_j \\): Leaf weight\n- \\( \\gamma, \\lambda \\): Hyperparameters\n\n### Taylor Approximation\n\nUses second-order Taylor expansion to approximate the loss function:\n\n$$\n\\mathcal{L}^{(t)} \\approx \\sum_{i=1}^n \\left[ g_i f_t(\\mathbf{x}_i) + \\frac{1}{2} h_i f_t^2(\\mathbf{x}_i) \\right] + \\Omega(f_t)\n$$\n\nWhere:\n\n- \\( g_i = \\frac{\\partial l(y_i, \\hat{y}^{(t-1)})}{\\partial \\hat{y}^{(t-1)}} \\) (gradient)\n- \\( h_i = \\frac{\\partial^2 l(y_i, \\hat{y}^{(t-1)})}{\\partial \\hat{y}^{(t-1)^2}} \\) (Hessian)\n\n### Optimal Solution\n\nOptimal weight for a leaf:\n\n$$\nw_j^* = -\\frac{\\sum_{i \\in I_j} g_i}{\\sum_{i \\in I_j} h_i + \\lambda}\n$$\n\nOptimal loss:\n\n$$\n\\mathcal{L}^{(t)}(w_j^*) = -\\frac{1}{2} \\sum_{j=1}^T \\frac{\\left(\\sum_{i \\in I_j} g_i\\right)^2}{\\sum_{i \\in I_j} (h_i + \\lambda)} + \\gamma T\n$$\n\n### Tree Construction\n\nLeaf gain is calculated as:\n\n$$\n\\text{Gain} = \\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{G^2}{H + \\lambda} - \\gamma\n$$\n\n### Final Algorithm\n\n1. **Greedy Method**:\n   - Scan all split points to find the best one. High accuracy but computationally expensive.\n2. **Approximate Method**:\n   - Use candidate split points to reduce computation cost at the expense of accuracy.\n\n## Simplified XGBoost: LightGBM\n\nLightGBM is a faster, simpler alternative to XGBoost, offering high generalization performance. While not available in Exploratory, it is widely supported in Python and often serves as the default choice.\n",
    "createdAt": "2025-07-21T07:23:48.457Z",
    "updatedAt": "2025-07-21T07:23:48.457Z"
  },
  {
    "title": "Welcome!",
    "summary": "Let me introduce myself and this site!",
    "tags": [
      "profile",
      "about",
      "self"
    ],
    "slug": "index",
    "folder": ".",
    "content": "\n# 👋 Introduction\n\nHay! I'm Marte, a univ student.\n\nI study computer science, especially I'm into web development and machine learning (AI) like deep learning, generative model and so on.\n\nSo, I gonna think out loud what I am studying about!\n\n# 🧠 Developer Skill Map (Mindmap Style)\n\nA visual breakdown of my current skills, tools, projects, and learning focus as a full-stack developer.\n\n```mermaid\nmindmap\n  root((🧑‍💻 Me as Developer))\n    Skills\n      Programming Languages\n        ::icon(fa fa-code)\n        TypeScript\n        Python\n        Go\n        Ruby\n        C\n      Frontend\n        ::icon(fa fa-laptop)\n        Next.js\n        Nuxt.js\n        React\n        Vue.js\n        Tailwind CSS\n        HTML/CSS\n      Backend\n        ::icon(fa fa-server)\n        Django\n        Ruby on Rails\n        REST APIs\n        WebSocket\n        Fiber\n      Database\n        ::icon(fa fa-database)\n        PostgreSQL\n        MySQL\n        SQLite\n        Redis\n        Elasticsearch\n    Tools & Tech\n      ::icon(fa fa-tools)\n      Development\n        Git / GitHub\n        Docker\n        VS Code\n        Vim / Neovim\n        Nginx\n      Cloud & DevOps\n        AWS\n        Vercel\n        GitHub Actions\n        CI/CD\n    Projects\n      ::icon(fa fa-rocket)\n      Major Works\n        Portfolio Site\n        TechBlog v1\n        TechBlog v2\n        長期インターンのプロダクト\n        学生団体公式サイト\n    Activities\n      ::icon(fa fa-users)\n      教育活動\n        STEP (中学生向けプログラミング)\n        大学内DX支援（社会人向け）\n    Learning\n      ::icon(fa fa-graduation-cap)\n      Currently Studying\n        深層学習\n        Go + PostgreSQL設計\n        OAuth & 認証・認可\n        API設計（REST / WebSocket）\n      Future Goals\n        テックリード\n        AI/ML応用\n        生成AIツール開発\n        クラウドアーキテクチャ\n```\n\n# 🕰️ My Developer Journey (GitGraph Style)\n\nA chronological map of my developer journey, from entering CS to my current goals and practical experience.\n\n```mermaid\ngitGraph\n    commit id: \"🎓 CS学部入学 (2023)\"\n    branch learning\n    checkout learning\n    commit id: \"💻 C/Pythonでアルゴリズム学習\"\n    commit id: \"🧠 CS学部での学びスタート\"\n    commit id: \"🌐 Web開発学習 (Next.js, Django, Docker)\"\n    branch projects\n    checkout projects\n    commit id: \"📦 ポートフォリオ作成\"\n    checkout learning\n    commit id: \"🧪 TOEIC 730・データサイエンス編入 (2024/4)\"\n    commit id: \"🧬 深層学習・生成AI講座 修了\"\n    branch activity\n    checkout activity\n    commit id: \"🧑‍🏫 中学生向けプログラミング教育 (STEP)\"\n    commit id: \"🏢 DX支援活動（大学）\"\n    checkout projects\n    commit id: \"🌐 学生団体公式サイト v1 (Next.js + Tailwind)\"\n    commit id: \"📘 TechBlog v1 (Next.js + Django)\"\n    checkout learning\n    commit id: \"✅ 基本情報技術者合格\"\n    checkout projects\n    commit id: \"📦 在庫管理フロント開発\"\n    commit id: \"👥 ユーザー管理システム (Django + Tailwind)\"\n    branch career\n    checkout career\n    commit id: \"💼 長期インターン開始 (2025/2〜)\"\n    commit id: \"🛠️ 実務開発：Next, Nuxt, Rails, Docker, AWS, Elastic\"\n    checkout projects\n    commit id: \"🛠️ 学生団体公式サイト v2 (Go + PSQL)\"\n    commit id: \"📝 TechBlog v2作成中\"\n    checkout learning\n    merge activity\n    checkout projects\n    merge learning\n    checkout career\n    merge projects\n    branch future\n    checkout future\n    commit id: \"🎯 テックリード志望\"\n    commit id: \"🧑‍💻 技術ブログ・発信\"\n    checkout career\n    merge future\n```\n\n# 🔗 Links\n\n- [Github](https://github.com/keu-5)\n- [Qiita](https://qiita.com/keu5)\n",
    "createdAt": "2025-07-21T07:23:48.459Z",
    "updatedAt": "2025-07-21T07:23:48.459Z"
  },
  {
    "title": "ブースのアルゴリズムをC++で実装してみた",
    "summary": "二進数の掛け算はハードウェア内でどのように行われているのかを確認しました",
    "tags": [
      "C++",
      "ブースのアルゴリズム",
      "Algorithm"
    ],
    "slug": "algorithm/booth-cpp",
    "folder": "algorithm",
    "content": "\nブースのアルゴリズム実装した記事が見つからない上にChatGPTに聞いても的外れなコードしか出来上がらないので自分で作ってみました．\n\n# ブースのアルゴリズムとは？\n\n符号付き二進数の乗算を効率的に行う手法です．加算器作ったならもちろん乗算器も作りたくなるよね？でも加算を何度もする乗算は計算に時間がかかってしまうので，ブースのアルゴリズムが編み出されました．\n\n## アルゴリズムの概要\n\nアルゴリズムは以下の通りです．\n\n1. 被乗数と乗数を二の補数表現で用意します．(今回は4bit分用意してみます)\n2. 被乗数については，符号を変えたものも用意しておきます．(もちろん補数表現を使用しますが，わかりやすいように以降は「-被乗数」とします)\n3. $A$を「被乗数 + 00000」,$S$を「-被乗数 + 00000」とします．\n4. $P_0$を「0000 + 乗数 + 0」とします．\n5. 漸化的に$P_n$を求めていきます．4bit同士の演算の場合，$P_4$まで求めます．\n   - $P_{n}$の末尾2bitが「00」あるいは「11」の場合，$P_{n}$を算術右シフトしたものを$P_n$とする\n   - 末尾が「01」の場合，$P_{n}$に$A$を加算したうえで右シフトしたものを$P_{n+1}$とする\n   - 末尾が「10」の場合，$P_{n}$に$S$を加算したうえで右シフトしたものを$P_{n+1}$とする\n6. $P_4$の上位8桁が解となります．\n\n詳しくは[シフト演算とは？論理シフトと算術シフトの違いを調べよう！](https://itmanabi.com/shift-operation/)を参考にすると良いです．\n\n# C++による実装\n\n別にCでも書けるんですけど，練習したいのでC++で書きます．\n\n## ライブラリのインポートや定数など\n\n```cpp\n#include <iostream>\n#include <vector>\n\nconstexpr int BIT_SIZE = 4;\nconstexpr int TABLE_SIZE = 2 * BIT_SIZE + 1;\n\nusing namespace std;\n```\n\n## BoothAlgorithmクラスの構築\n\n必要な変数は\n\n1. 被乗数\n1. -被乗数\n1. $P_0$\n\nで，必要な関数は，\n\n1. 整数を二進数に変換する関数\n1. 算術右シフトさせる関数\n1. 二進数加算させる関数\n1. $P_{n+1}$を求める関数\n1. 配列を表示させる関数\n1. 再帰的に$P$を求める関数\n\nです．\n\n### メンバ変数\n\nまずは必要なメンバ変数を用意します．先ほどと同様に$A$は被乗数，$S$は-被乗数，$P_0$を乗数とします．\n\n```cpp\nclass BoothAlgorithm {\n  public:\n  private:\n   vector<int> A, S, P_0, Result;\n```\n\n### 整数を二進数に変換する関数to_binary\n\n` binary[bit_size - 1 - i] = (x >> i) & 1;`とすることで，10進数の値を2進数にしたときにi桁目の値を対応する配列に格納していきます．\n\n```cpp\n    vector<int> to_binary(int x, int bit_size) {\n      vector<int> binary(bit_size, 0);\n\n      for (int i = 0; i < bit_size; i++) {\n          binary[bit_size - 1 - i] = (x >> i) & 1;\n      }\n\n      return binary;\n    }\n```\n\n### 算術シフトさせる関数right_shift\n\n算術シフトですので最上位ビットの処理に気をつけます．\n\n```cpp\n    void right_shift(vector<int>& vec) {\n      for (int i = vec.size() - 1; i > 0; --i) {\n        vec[i] = vec[i - 1];\n      }\n      vec[0] = vec[0] == 1 ? 1 : 0;\n    }\n```\n\n### 二進数加算させる関数add_vectors\n\n単純に要素ごとに加算させると，10進数として計算してしまうため，二進数としての繰り上がりを考慮する必要があります．\n\n```cpp\n    vector<int> add_vectors(const vector<int>& vec1, const vector<int>& vec2) {\n      vector<int> result(vec1.size());\n      int carry = 0;\n\n      for (size_t i = vec1.size(); i-- > 0;) {\n        int sum = vec1[i] + vec2[i] + carry;\n        result[i] = sum % 2;\n        carry = sum / 2;\n      }\n\n      return result;\n    }\n```\n\n### $P_{n+1}$を求める関数conditional_shift\n\n- $P_{n}$の末尾2bitが「00」あるいは「11」の場合，$P_{n}$を算術右シフトしたものを$P_n$とする\n- 末尾が「01」の場合，$P_{n}$に$A$を加算したうえで右シフトしたものを$P_{n+1}$とする\n- 末尾が「10」の場合，$P_{n}$に$S$を加算したうえで右シフトしたものを$P_{n+1}$とする\n\nという条件をもとにシフトさせる関数を作ります．\n\n```cpp\n    vector<int> conditional_shift(const vector<int>& A, const vector<int>& S, const vector<int>& P) {\n      vector<int> result = P;\n\n      if (P[TABLE_SIZE - 2] == P[TABLE_SIZE - 1]) {\n        right_shift(result);\n      } else if (P[TABLE_SIZE - 2] == 0) {\n        result = add_vectors(result, A);\n\n        right_shift(result);\n      } else {\n        result = add_vectors(result, S);\n\n        right_shift(result);\n      }\n\n      return result;\n    }\n```\n\n### 配列を表示させる関数\n\nあるとわかりやすいね\n\n```cpp\n    void print_array(const vector<int>& arr) {\n      for (int i = 0; i < arr.size(); i++) {\n        cout << arr[i] << \" \";\n      }\n      cout << endl;\n    }\n```\n\n### 再帰的に$P$を求める関数\n\n先ほど作った`conditional_shift()`を使って$P_1\\sim P_4$まで再帰的に計算させます．\n\n```cpp\n    vector<int> booth_algorithm(vector<int>& A, vector<int>& S, vector<int>& P, int count = BIT_SIZE) {\n      if (count > 0) {\n        P = conditional_shift(A, S, P);\n\n        cout << \"P_\" << BIT_SIZE - count + 1 << \": \";\n        print_array(P);\n\n        return booth_algorithm(A, S, P, count - 1);\n      } else {\n        vector<int> Result(TABLE_SIZE - 1, 0);\n\n        for (int i = 0; i < TABLE_SIZE - 1; i++) {\n          Result[i] = P[i];\n        }\n\n        return Result;\n      }\n    }\n```\n\n### コンストラクタなど\n\nコンストラクタでは，整数x, yを受け取り，2進数に変換しつつ適切な形式に変換して，各メンバ変数に代入していきます．また実行のために関数runを用意します．\n\n```cpp\n  public:\n    BoothAlgorithm(int x, int y) {\n      A.resize(TABLE_SIZE, 0);\n      S.resize(TABLE_SIZE, 0);\n      P_0.resize(TABLE_SIZE, 0);\n      Result.resize(TABLE_SIZE - 1, 0);\n\n      vector<int> binary_x = to_binary(x, BIT_SIZE);\n      vector<int> binary_minus_x = to_binary(-x, BIT_SIZE);\n      vector<int> binary_y = to_binary(y, BIT_SIZE);\n\n      for (int i = 0; i < BIT_SIZE; i++) {\n        A[i] = binary_x[i];\n        S[i] = binary_minus_x[i];\n        P_0[i + BIT_SIZE] = binary_y[i];\n      }\n    }\n\n    void run() {\n      cout << \"P_0: \";\n      print_array(P_0);\n\n      Result = booth_algorithm(A, S, P_0);\n\n      cout << \"Result: \";\n      print_array(Result);\n    }\n```\n\n## main関数\n\nあとはmain関数を書けば完成です．\n\n```cpp\nint main() {\n  int x, y;\n  cin >> x >> y;\n\n  BoothAlgorithm booth(x, y);\n  booth.run();\n\n  return 0;\n}\n```\n\n# 実際に実行してみる\n\n```zsh\n❯ cpp booth.cpp\n-6 5\nP_0: 0 0 0 0 0 1 0 1 0\nP_1: 0 0 1 1 0 0 1 0 1\nP_2: 1 1 1 0 1 0 0 1 0\nP_3: 0 0 1 0 0 1 0 0 1\nP_4: 1 1 1 0 0 0 1 0 0\nResult: 1 1 1 0 0 0 1 0\n\n❯ cpp booth.cpp\n5 -6\nP_0: 0 0 0 0 1 0 1 0 0\nP_1: 0 0 0 0 0 1 0 1 0\nP_2: 1 1 0 1 1 0 1 0 1\nP_3: 0 0 0 1 0 1 0 1 0\nP_4: 1 1 1 0 0 0 1 0 1\nResult: 1 1 1 0 0 0 1 0\n\n❯ cpp booth.cpp\n4 -3\nP_0: 0 0 0 0 1 1 0 1 0\nP_1: 1 1 1 0 0 1 1 0 1\nP_2: 0 0 0 1 0 0 1 1 0\nP_3: 1 1 1 0 1 0 0 1 1\nP_4: 1 1 1 1 0 1 0 0 1\nResult: 1 1 1 1 0 1 0 0\n```\n\n実際に実行してみると上記のようになります．例えば，$5\\times -6$という演算をブースのアルゴリズムで解いた場合，$P_4=(11100010)_2=(-30)_{10}$のように，確かに正しく計算できています．\n\nまた，$-6\\times 5$でも同じような結果となっており，乗法の交換律も成り立っています．\n\n$4\\times -3$も同様に正しく計算できています．\n\n# コードの全体像\n\n最後にコードの全体像を貼っておきます．\n\n```cpp\n#include <iostream>\n#include <vector>\n\nconstexpr int BIT_SIZE = 4;\nconstexpr int TABLE_SIZE = 2 * BIT_SIZE + 1;\n\nusing namespace std;\n\nclass BoothAlgorithm {\n  public:\n    BoothAlgorithm(int x, int y) {\n      A.resize(TABLE_SIZE, 0);\n      S.resize(TABLE_SIZE, 0);\n      P_0.resize(TABLE_SIZE, 0);\n      Result.resize(TABLE_SIZE - 1, 0);\n\n      vector<int> binary_x = to_binary(x, BIT_SIZE);\n      vector<int> binary_minus_x = to_binary(-x, BIT_SIZE);\n      vector<int> binary_y = to_binary(y, BIT_SIZE);\n\n      for (int i = 0; i < BIT_SIZE; i++) {\n        A[i] = binary_x[i];\n        S[i] = binary_minus_x[i];\n        P_0[i + BIT_SIZE] = binary_y[i];\n      }\n    }\n\n    void run() {\n      cout << \"P_0: \";\n      print_array(P_0);\n\n      Result = booth_algorithm(A, S, P_0);\n\n      cout << \"Result: \";\n      print_array(Result);\n    }\n\n  private:\n    vector<int> A, S, P_0, Result;\n\n    void right_shift(vector<int>& vec) {\n      for (int i = vec.size() - 1; i > 0; --i) {\n        vec[i] = vec[i - 1];\n      }\n      vec[0] = vec[0] == 1 ? 1 : 0;\n    }\n\n    vector<int> add_vectors(const vector<int>& vec1, const vector<int>& vec2) {\n      vector<int> result(vec1.size());\n      int carry = 0;\n\n      for (size_t i = vec1.size(); i-- > 0;) {\n        int sum = vec1[i] + vec2[i] + carry;\n        result[i] = sum % 2;\n        carry = sum / 2;\n      }\n\n      return result;\n    }\n\n    vector<int> to_binary(int x, int bit_size) {\n      vector<int> binary(bit_size, 0);\n\n      for (int i = 0; i < bit_size; i++) {\n          binary[bit_size - 1 - i] = (x >> i) & 1;\n      }\n\n      return binary;\n    }\n\n    vector<int> conditional_shift(const vector<int>& A, const vector<int>& S, const vector<int>& P) {\n      vector<int> result = P;\n\n      if (P[TABLE_SIZE - 2] == P[TABLE_SIZE - 1]) {\n        right_shift(result);\n      } else if (P[TABLE_SIZE - 2] == 0) {\n        result = add_vectors(result, A);\n\n        right_shift(result);\n      } else {\n        result = add_vectors(result, S);\n\n        right_shift(result);\n      }\n\n      return result;\n    }\n\n    void print_array(const vector<int>& arr) {\n      for (int i = 0; i < arr.size(); i++) {\n        cout << arr[i] << \" \";\n      }\n      cout << endl;\n    }\n\n    vector<int> booth_algorithm(vector<int>& A, vector<int>& S, vector<int>& P, int count = BIT_SIZE) {\n      if (count > 0) {\n        P = conditional_shift(A, S, P);\n\n        cout << \"P_\" << BIT_SIZE - count + 1 << \": \";\n        print_array(P);\n\n        return booth_algorithm(A, S, P, count - 1);\n      } else {\n        vector<int> Result(TABLE_SIZE - 1, 0);\n\n        for (int i = 0; i < TABLE_SIZE - 1; i++) {\n          Result[i] = P[i];\n        }\n\n        return Result;\n      }\n    }\n};\n\nint main() {\n  int x, y;\n  cin >> x >> y;\n\n  BoothAlgorithm booth(x, y);\n  booth.run();\n\n  return 0;\n}\n```\n",
    "createdAt": "2025-07-21T07:23:48.458Z",
    "updatedAt": "2025-07-21T07:23:48.458Z"
  }
]